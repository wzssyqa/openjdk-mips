//
// Copyright (c) 2003, 2013, Oracle and/or its affiliates. All rights reserved.
// Copyright (c) 2015, 2016, Loongson Technology. All rights reserved.
// DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
//
// This code is free software; you can redistribute it and/or modify it
// under the terms of the GNU General Public License version 2 only, as
// published by the Free Software Foundation.
//
// This code is distributed in the hope that it will be useful, but WITHOUT
// ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
// FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
// version 2 for more details (a copy is included in the LICENSE file that
// accompanied this code).
//
// You should have received a copy of the GNU General Public License version
// 2 along with this work; if not, write to the Free Software Foundation,
// Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
//
// Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
// or visit www.oracle.com if you need additional information or have any
// questions.
//
//

// GodSon3 Architecture Description File

//----------REGISTER DEFINITION BLOCK------------------------------------------
// This information is used by the matcher and the register allocator to
// describe individual registers and classes of registers within the target
// archtecture.

// format:
// reg_def name (call convention, c-call convention, ideal type, encoding);
// 		call convention : 
//			NS  = No-Save
//			SOC = Save-On-Call
//			SOE = Save-On-Entry
//			AS  = Always-Save
//		ideal type :
//			see opto/opcodes.hpp for more info
// reg_class name (reg, ...);
// alloc_class name (reg, ...); 
register %{

// General Registers
// Integer Registers
	reg_def R0	    ( NS,  NS, 	Op_RegI,  0, VMRegImpl::Bad());
	reg_def AT		( NS,  NS, 	Op_RegI,  1, AT->as_VMReg());
	reg_def AT_H    ( NS,  NS,  Op_RegI,  1, AT->as_VMReg()->next());
	reg_def V0		(SOC, SOC,	Op_RegI,  2, V0->as_VMReg());
	reg_def V0_H	(SOC, SOC,	Op_RegI,  2, V0->as_VMReg()->next());
	reg_def V1		(SOC, SOC,	Op_RegI,  3, V1->as_VMReg());
	reg_def V1_H	(SOC, SOC,	Op_RegI,  3, V1->as_VMReg()->next());
	reg_def A0		(SOC, SOC,	Op_RegI,  4, A0->as_VMReg());
	reg_def A0_H	(SOC, SOC,	Op_RegI,  4, A0->as_VMReg()->next());
	reg_def A1		(SOC, SOC,	Op_RegI,  5, A1->as_VMReg());
	reg_def A1_H	(SOC, SOC,	Op_RegI,  5, A1->as_VMReg()->next());
	reg_def A2		(SOC, SOC,	Op_RegI,  6, A2->as_VMReg());
	reg_def A2_H	(SOC, SOC,	Op_RegI,  6, A2->as_VMReg()->next());
	reg_def A3		(SOC, SOC,	Op_RegI,  7, A3->as_VMReg());
	reg_def A3_H	(SOC, SOC,	Op_RegI,  7, A3->as_VMReg()->next());
	reg_def A4		(SOC, SOC,	Op_RegI,  8, A4->as_VMReg());
	reg_def A4_H	(SOC, SOC,	Op_RegI,  8, A4->as_VMReg()->next());
	reg_def A5		(SOC, SOC,	Op_RegI,  9, A5->as_VMReg());
	reg_def A5_H	(SOC, SOC,	Op_RegI,  9, A5->as_VMReg()->next());
	reg_def A6		(SOC, SOC,	Op_RegI,  10, A6->as_VMReg());
	reg_def A6_H	(SOC, SOC,	Op_RegI,  10, A6->as_VMReg()->next());
	reg_def A7		(SOC, SOC,	Op_RegI,  11, A7->as_VMReg());
	reg_def A7_H	(SOC, SOC,	Op_RegI,  11, A7->as_VMReg()->next());
	reg_def T0		(SOC, SOC,	Op_RegI,  12, T0->as_VMReg());
	reg_def T0_H	(SOC, SOC,	Op_RegI,  12, T0->as_VMReg()->next());
	reg_def T1		(SOC, SOC,	Op_RegI,  13, T1->as_VMReg());
	reg_def T1_H	(SOC, SOC,	Op_RegI,  13, T1->as_VMReg()->next());
	reg_def T2		(SOC, SOC,	Op_RegI,  14, T2->as_VMReg());
	reg_def T2_H	(SOC, SOC,	Op_RegI,  14, T2->as_VMReg()->next());
	reg_def T3		(SOC, SOC,	Op_RegI,  15, T3->as_VMReg());
	reg_def T3_H	(SOC, SOC,	Op_RegI,  15, T3->as_VMReg()->next());
	reg_def S0		(SOC, SOE,	Op_RegI,  16, S0->as_VMReg());
	reg_def S0_H	(SOC, SOE,	Op_RegI,  16, S0->as_VMReg()->next());
	reg_def S1		(SOC, SOE,	Op_RegI,  17, S1->as_VMReg());
	reg_def S1_H	(SOC, SOE,	Op_RegI,  17, S1->as_VMReg()->next());
	reg_def S2		(SOC, SOE,	Op_RegI,  18, S2->as_VMReg());
	reg_def S2_H	(SOC, SOE,	Op_RegI,  18, S2->as_VMReg()->next());
	reg_def S3		(SOC, SOE,	Op_RegI,  19, S3->as_VMReg());
	reg_def S3_H	(SOC, SOE,	Op_RegI,  19, S3->as_VMReg()->next());
	reg_def S4		(SOC, SOE,	Op_RegI,  20, S4->as_VMReg());
	reg_def S4_H	(SOC, SOE,	Op_RegI,  20, S4->as_VMReg()->next());
	reg_def S5		(SOC, SOE,	Op_RegI,  21, S5->as_VMReg());
	reg_def S6		(SOC, SOE,	Op_RegI,  22, S6->as_VMReg());
	reg_def S7		(SOC, SOE,	Op_RegI,  23, S7->as_VMReg());
	reg_def T8		(SOC, SOC,	Op_RegI,  24, T8->as_VMReg());
	reg_def T9		(SOC, SOC,	Op_RegI,  25, T9->as_VMReg());

// Special Registers
	reg_def K0		( NS,  NS,	Op_RegI, 26, K0->as_VMReg());
	reg_def K1		( NS,  NS,	Op_RegI, 27, K1->as_VMReg());
	reg_def GP		( NS,  NS,	Op_RegI, 28, GP->as_VMReg());
	reg_def GP_H	( NS,  NS,	Op_RegI, 28, GP->as_VMReg()->next());
	reg_def SP		( NS,  NS,	Op_RegI, 29, SP->as_VMReg());
	reg_def SP_H	( NS,  NS,	Op_RegI, 29, SP->as_VMReg()->next());
	reg_def FP		( NS,  NS,	Op_RegI, 30, FP->as_VMReg());
	reg_def FP_H	( NS,  NS,	Op_RegI, 30, FP->as_VMReg()->next());
	reg_def RA		( NS,  NS,	Op_RegI, 31, RA->as_VMReg());
	reg_def RA_H	( NS,  NS,	Op_RegI, 31, RA->as_VMReg()->next());

// Floating registers. 
reg_def F0          ( SOC, SOC, Op_RegF, 0, F0->as_VMReg());
reg_def F0_H        ( SOC, SOC, Op_RegF, 0, F0->as_VMReg()->next());
reg_def F1          ( SOC, SOC, Op_RegF, 1, F1->as_VMReg());
reg_def F1_H        ( SOC, SOC, Op_RegF, 1, F1->as_VMReg()->next());
reg_def F2          ( SOC, SOC, Op_RegF, 2, F2->as_VMReg());
reg_def F2_H        ( SOC, SOC, Op_RegF, 2, F2->as_VMReg()->next());
reg_def F3          ( SOC, SOC, Op_RegF, 3, F3->as_VMReg());
reg_def F3_H        ( SOC, SOC, Op_RegF, 3, F3->as_VMReg()->next());
reg_def F4          ( SOC, SOC, Op_RegF, 4, F4->as_VMReg());
reg_def F4_H        ( SOC, SOC, Op_RegF, 4, F4->as_VMReg()->next());
reg_def F5          ( SOC, SOC, Op_RegF, 5, F5->as_VMReg());
reg_def F5_H        ( SOC, SOC, Op_RegF, 5, F5->as_VMReg()->next());
reg_def F6          ( SOC, SOC, Op_RegF, 6, F6->as_VMReg());
reg_def F6_H        ( SOC, SOC, Op_RegF, 6, F6->as_VMReg()->next());
reg_def F7          ( SOC, SOC, Op_RegF, 7, F7->as_VMReg());
reg_def F7_H        ( SOC, SOC, Op_RegF, 7, F7->as_VMReg()->next());
reg_def F8          ( SOC, SOC, Op_RegF, 8, F8->as_VMReg());
reg_def F8_H        ( SOC, SOC, Op_RegF, 8, F8->as_VMReg()->next());
reg_def F9          ( SOC, SOC, Op_RegF, 9, F9->as_VMReg());
reg_def F9_H        ( SOC, SOC, Op_RegF, 9, F9->as_VMReg()->next());
reg_def F10         ( SOC, SOC, Op_RegF, 10, F10->as_VMReg());
reg_def F10_H       ( SOC, SOC, Op_RegF, 10, F10->as_VMReg()->next());
reg_def F11         ( SOC, SOC, Op_RegF, 11, F11->as_VMReg());
reg_def F11_H       ( SOC, SOC, Op_RegF, 11, F11->as_VMReg()->next());
reg_def F12         ( SOC, SOC, Op_RegF, 12, F12->as_VMReg());
reg_def F12_H       ( SOC, SOC, Op_RegF, 12, F12->as_VMReg()->next());
reg_def F13         ( SOC, SOC, Op_RegF, 13, F13->as_VMReg());
reg_def F13_H       ( SOC, SOC, Op_RegF, 13, F13->as_VMReg()->next());
reg_def F14         ( SOC, SOC, Op_RegF, 14, F14->as_VMReg());
reg_def F14_H       ( SOC, SOC, Op_RegF, 14, F14->as_VMReg()->next());
reg_def F15         ( SOC, SOC, Op_RegF, 15, F15->as_VMReg());
reg_def F15_H       ( SOC, SOC, Op_RegF, 15, F15->as_VMReg()->next());
reg_def F16         ( SOC, SOC, Op_RegF, 16, F16->as_VMReg());
reg_def F16_H       ( SOC, SOC, Op_RegF, 16, F16->as_VMReg()->next());
reg_def F17         ( SOC, SOC, Op_RegF, 17, F17->as_VMReg());
reg_def F17_H       ( SOC, SOC, Op_RegF, 17, F17->as_VMReg()->next());
reg_def F18         ( SOC, SOC, Op_RegF, 18, F18->as_VMReg());
reg_def F18_H       ( SOC, SOC, Op_RegF, 18, F18->as_VMReg()->next());
reg_def F19         ( SOC, SOC, Op_RegF, 19, F19->as_VMReg());
reg_def F19_H       ( SOC, SOC, Op_RegF, 19, F19->as_VMReg()->next());
reg_def F20         ( SOC, SOC, Op_RegF, 20, F20->as_VMReg());
reg_def F20_H       ( SOC, SOC, Op_RegF, 20, F20->as_VMReg()->next());
reg_def F21         ( SOC, SOC, Op_RegF, 21, F21->as_VMReg());
reg_def F21_H       ( SOC, SOC, Op_RegF, 21, F21->as_VMReg()->next());
reg_def F22         ( SOC, SOC, Op_RegF, 22, F22->as_VMReg());
reg_def F22_H       ( SOC, SOC, Op_RegF, 22, F22->as_VMReg()->next());
reg_def F23         ( SOC, SOC, Op_RegF, 23, F23->as_VMReg());
reg_def F23_H       ( SOC, SOC, Op_RegF, 23, F23->as_VMReg()->next());
reg_def F24         ( SOC, SOC, Op_RegF, 24, F24->as_VMReg());
reg_def F24_H       ( SOC, SOC, Op_RegF, 24, F24->as_VMReg()->next());
reg_def F25         ( SOC, SOC, Op_RegF, 25, F25->as_VMReg());
reg_def F25_H       ( SOC, SOC, Op_RegF, 25, F25->as_VMReg()->next());
reg_def F26         ( SOC, SOC, Op_RegF, 26, F26->as_VMReg());
reg_def F26_H       ( SOC, SOC, Op_RegF, 26, F26->as_VMReg()->next());
reg_def F27         ( SOC, SOC, Op_RegF, 27, F27->as_VMReg());
reg_def F27_H       ( SOC, SOC, Op_RegF, 27, F27->as_VMReg()->next());
reg_def F28         ( SOC, SOC, Op_RegF, 28, F28->as_VMReg());
reg_def F28_H       ( SOC, SOC, Op_RegF, 28, F28->as_VMReg()->next());
reg_def F29         ( SOC, SOC, Op_RegF, 29, F29->as_VMReg());
reg_def F29_H       ( SOC, SOC, Op_RegF, 29, F29->as_VMReg()->next());
reg_def F30         ( SOC, SOC, Op_RegF, 30, F30->as_VMReg());
reg_def F30_H       ( SOC, SOC, Op_RegF, 30, F30->as_VMReg()->next());
reg_def F31         ( SOC, SOC, Op_RegF, 31, F31->as_VMReg());
reg_def F31_H       ( SOC, SOC, Op_RegF, 31, F31->as_VMReg()->next());


// ----------------------------
// Special Registers
// Condition Codes Flag Registers
reg_def MIPS_FLAG (SOC, SOC,  Op_RegFlags, 1, as_Register(1)->as_VMReg());
//S6 is used for get_thread(S6)
//S5 is uesd for heapbase of compressed oop
alloc_class chunk0(  S0, S0_H,
                     S1, S1_H,
                     S2, S2_H,
                     S3, S3_H,
                     S4, S4_H,
                     T0, T0_H,
                     T1, T1_H,
                     T2, T2_H,
                     T3, T3_H,
                     V0, V0_H,
                     V1, V1_H,
                     A0, A0_H,
                     A1, A1_H,
                     A2, A2_H,
                     A3, A3_H,
                     A4, A4_H,
                     A5, A5_H,
                     A6, A6_H,
                     A7, A7_H,
                     RA, RA_H,
                     SP, SP_H,
                     FP, FP_H,
                     GP, GP_H );

alloc_class chunk1(  F0, F0_H,
                     F1, F1_H,
                     F2, F2_H,
                     F3, F3_H,
                     F4, F4_H,
                     F5, F5_H,
                     F6, F6_H,
                     F7, F7_H,
                     F8, F8_H,
                     F9, F9_H,
                     F10, F10_H,
                     F11, F11_H,
                     F12, F12_H,
                     F13, F13_H,
                     F14, F14_H,
                     F15, F15_H,
                     F16, F16_H,
                     F17, F17_H,
                     F18, F18_H,
                     F19, F19_H,
                     F20, F20_H,
                     F21, F21_H,
                     F22, F22_H,
                     F23, F23_H,
                     F24, F24_H,
                     F25, F25_H,
                     F26, F26_H,
                     F27, F27_H,
                     F28, F28_H,
                     F29, F29_H,
                     F30, F30_H,
                     F31, F31_H);

alloc_class chunk2(MIPS_FLAG);

// Class for all registers
reg_class any_reg( T0, T0_H,
                   T1, T1_H,
                   T2, T2_H,
                   T3, T3_H,
                   A4, A4_H,
                   A5, A5_H,
                   A6, A6_H,
                   A7, A7_H, 
                   S0, S0_H,
                   S1, S1_H,
                   S2, S2_H,
                   S3, S3_H,
                   S4, S4_H,
                   V0, V0_H,
                   V1, V1_H
	         );

// Class for general registers
reg_class g_reg( T0, T0_H,
                 T1, T1_H,
                 T2, T2_H,
                 T3, T3_H,
                 A4, A4_H,
                 A5, A5_H,
                 A6, A6_H,
                 A7, A7_H, 
                 S0, S0_H,
                 S1, S1_H,
                 S2, S2_H,
                 S3, S3_H,
                 S4, S4_H,
                 V0, V0_H,
                 V1, V1_H,
                 A0, A0_H,
                 A1, A1_H,
                 A2, A2_H,
                 A3, A3_H );

reg_class s_reg( S0, S1, S2, S3, S4 );
reg_class s0_reg( S0 );
reg_class s1_reg( S1 );
reg_class s2_reg( S2 );
reg_class s3_reg( S3 );
reg_class s4_reg( S4 );

reg_class t_reg( T0, T1, T2, T3);
reg_class t0_reg( T0 );
reg_class t1_reg( T1 );
reg_class t2_reg( T2 );
reg_class t3_reg( T3 );

reg_class a0_reg( A0 );
reg_class a1_reg( A1 );
reg_class a2_reg( A2 );
reg_class a3_reg( A3 );
reg_class a4_reg( A4 );
reg_class a5_reg( A5 );
reg_class a6_reg( A6 );
reg_class a7_reg( A7 );

reg_class mips_flags(MIPS_FLAG);

// Class of registers that can appear in an address with no offset.
// EBP and ESP require an extra instruction byte for zero offset.
// Used in fast-unlock
//reg_class p_reg(EDX, EDI, ESI, EBX);
reg_class p_reg( T0, T0_H,
                 T1, T1_H,
                 T2, T2_H,
                 T3, T3_H,

                 A0, A0_H,
                 A1, A1_H,
                 A2, A2_H,
                 A3, A3_H,
                 A4, A4_H,
                 A5, A5_H,
                 A6, A6_H,
                 A7, A7_H,

                 S0, S0_H,
                 S1, S1_H,
                 S2, S2_H,
                 S3, S3_H,
                 S4, S4_H);
reg_class int_reg( T0, T1, T2, T3, S0, S1, S2, S3, S4, V0, V1, A0, A1, A2, A3, A4, A6, A7 );
reg_class sp_reg( SP, SP_H );
reg_class fp_reg( FP, FP_H );


reg_class long_reg( 
                    T0, T0_H,
                    T1, T1_H,
                    T2, T2_H,
                    T3, T3_H,

                    A0, A0_H,
                    A1, A1_H,
                    A2, A2_H,
                    A3, A3_H,
                    A4, A4_H,
                    A5, A5_H,
                    A6, A6_H,
                    A7, A7_H,

                    S0, S0_H,
                    S1, S1_H,
                    S2, S2_H,
                    S3, S3_H,
                    S4, S4_H);

reg_class v0_long_reg( V0, V0_H );
reg_class v1_long_reg( V1, V1_H );
reg_class a0_long_reg( A0, A0_H );
reg_class a1_long_reg( A1, A1_H );
reg_class a2_long_reg( A2, A2_H );
reg_class a3_long_reg( A3, A3_H );
reg_class a4_long_reg( A4, A4_H );
reg_class a5_long_reg( A5, A5_H );
reg_class a6_long_reg( A6, A6_H );
reg_class a7_long_reg( A7, A7_H );
reg_class t0_long_reg( T0, T0_H );
reg_class t1_long_reg( T1, T1_H );
reg_class t2_long_reg( T2, T2_H );
reg_class t3_long_reg( T3, T3_H );
reg_class s0_long_reg( S0, S0_H );
reg_class s1_long_reg( S1, S1_H );
reg_class s2_long_reg( S2, S2_H );
reg_class s3_long_reg( S3, S3_H );
reg_class s4_long_reg( S4, S4_H );

// Floating point registers.
// 2012/8/23 Fu: F30/F31 are used as temporary registers in D2I
reg_class flt_reg( F0, F1, F2, F3, F4, F5, F6, F7, F8, F9, F10, F11, F12, F13, F14, F15, F16, F17 F18, F19, F20, F21, F22, F23, F24, F25, F26, F27, F28);
reg_class dbl_reg( F0, F0_H,
                   F1, F1_H,
                   F2, F2_H,
                   F3, F3_H,
                   F4, F4_H,
                   F5, F5_H,
                   F6, F6_H,
                   F7, F7_H,
                   F8, F8_H,
                   F9, F9_H,
                   F10, F10_H, 
                   F11, F11_H, 
                   F12, F12_H, 
                   F13, F13_H, 
                   F14, F14_H, 
                   F15, F15_H, 
                   F16, F16_H, 
                   F17, F17_H, 
                   F18, F18_H, 
                   F19, F19_H, 
                   F20, F20_H, 
                   F21, F21_H, 
                   F22, F22_H, 
                   F23, F23_H, 
                   F24, F24_H, 
                   F25, F25_H, 
                   F26, F26_H, 
                   F27, F27_H, 
                   F28, F28_H, 
                   F29, F29_H);

reg_class flt_arg0( F12 );
reg_class dbl_arg0( F12, F12_H );
reg_class dbl_arg1( F14, F14_H );

%} 

//----------DEFINITION BLOCK---------------------------------------------------
// Define name --> value mappings to inform the ADLC of an integer valued name
// Current support includes integer values in the range [0, 0x7FFFFFFF]
// Format:
//        int_def  <name>         ( <int_value>, <expression>);
// Generated Code in ad_<arch>.hpp
//        #define  <name>   (<expression>)
//        // value == <int_value>
// Generated code in ad_<arch>.cpp adlc_verification()
//        assert( <name> == <int_value>, "Expect (<expression>) to equal <int_value>");
//
definitions %{
	int_def DEFAULT_COST      (    100,     100);
	int_def HUGE_COST         (1000000, 1000000);

	// Memory refs are twice as expensive as run-of-the-mill.
	int_def MEMORY_REF_COST   (    200, DEFAULT_COST * 2);

	// Branches are even more expensive.
	int_def BRANCH_COST       (    300, DEFAULT_COST * 3);
	// we use jr instruction to construct call, so more expensive
	// by yjl 2/28/2006
	int_def CALL_COST         (    500, DEFAULT_COST * 5);
/*
        int_def EQUAL             (   1, 1  );
        int_def NOT_EQUAL         (   2, 2  );
        int_def GREATER           (   3, 3  );
        int_def GREATER_EQUAL     (   4, 4  );
        int_def LESS              (   5, 5  );
        int_def LESS_EQUAL        (   6, 6  );
*/
%}
						


//----------SOURCE BLOCK-------------------------------------------------------
// This is a block of C++ code which provides values, functions, and
// definitions necessary in the rest of the architecture description

source_hpp %{
// Header information of the source block.
// Method declarations/definitions which are used outside
// the ad-scope can conveniently be defined here.
//
// To keep related declarations/definitions/uses close together,
// we switch between source %{ }% and source_hpp %{ }% freely as needed.

class CallStubImpl {
 
  //--------------------------------------------------------------
  //---<  Used for optimization in Compile::shorten_branches  >---
  //--------------------------------------------------------------

 public:
  // Size of call trampoline stub.
  static uint size_call_trampoline() {
    return 0; // no call trampolines on this platform
  }
  
  // number of relocations needed by a call trampoline stub
  static uint reloc_call_trampoline() { 
    return 0; // no call trampolines on this platform
  }
};

class HandlerImpl {

 public:

  static int emit_exception_handler(CodeBuffer &cbuf);
  static int emit_deopt_handler(CodeBuffer& cbuf);

  static uint size_exception_handler() {
    // NativeCall instruction size is the same as NativeJump.
    // exception handler starts out as jump and can be patched to
    // a call be deoptimization.  (4932387)
    // Note that this value is also credited (in output.cpp) to
    // the size of the code section.
//    return NativeJump::instruction_size;
    int size = NativeCall::instruction_size;
    return round_to(size, 16);
  }

#ifdef _LP64
  static uint size_deopt_handler() {
    int size = NativeCall::instruction_size;
    return round_to(size, 16);
  }
#else
  static uint size_deopt_handler() {
    // NativeCall instruction size is the same as NativeJump.
    // exception handler starts out as jump and can be patched to
    // a call be deoptimization.  (4932387)
    // Note that this value is also credited (in output.cpp) to
    // the size of the code section.
    return 5 + NativeJump::instruction_size; // pushl(); jmp;
  }
#endif
};

%} // end source_hpp

source %{

#define   NO_INDEX    0
#define   RELOC_IMM64    Assembler::imm_operand
#define   RELOC_DISP32   Assembler::disp32_operand

 
#define __ _masm.


// Emit exception handler code.
// Stuff framesize into a register and call a VM stub routine.
int HandlerImpl::emit_exception_handler(CodeBuffer& cbuf) {
/*
  // Note that the code buffer's insts_mark is always relative to insts.
  // That's why we must use the macroassembler to generate a handler.
  MacroAssembler _masm(&cbuf);
  address base = __ start_a_stub(size_exception_handler());
  if (base == NULL)  return 0;  // CodeBuffer::expand failed
  int offset = __ offset();
  __ jump(RuntimeAddress(OptoRuntime::exception_blob()->entry_point()));
  assert(__ offset() - offset <= (int) size_exception_handler(), "overflow");
  __ end_a_stub();
  return offset;
*/
  // Note that the code buffer's insts_mark is always relative to insts.
  // That's why we must use the macroassembler to generate a handler.
  MacroAssembler _masm(&cbuf);
  address base =
  __ start_a_stub(size_exception_handler());
  if (base == NULL)  return 0;  // CodeBuffer::expand failed
  int offset = __ offset();

  __ block_comment("; emit_exception_handler");

  /* 2012/9/25 FIXME Jin: According to X86, we should use direct jumpt.
 *    *  However, this will trigger an assert after the 40th method:
 *       *
 *          *        39   b   java.lang.Throwable::<init> (25 bytes)
 *             *       ---   ns  java.lang.Throwable::fillInStackTrace
 *                *        40  !b   java.net.URLClassLoader::findClass (29 bytes)
 *                   *       /vm/opto/runtime.cpp, 900 , assert(caller.is_compiled_frame(),"must be")
 *                      *        40   made not entrant  (2)  java.net.URLClassLoader::findClass (29 bytes)
 *                         *
 *                            *  If we change from JR to JALR, the assert will disappear, but WebClient will
 *                               *  fail  after the 403th method with unknown reason.
 *                                  */
  __ li48(T9, (long)OptoRuntime::exception_blob()->entry_point());
  __ jr(T9);
  __ delayed()->nop();
  __ align(16);
  assert(__ offset() - offset <= (int) size_exception_handler(), "overflow");
  __ end_a_stub();
  return offset;
}

// Emit deopt handler code.
int HandlerImpl::emit_deopt_handler(CodeBuffer& cbuf) {
/*
  // Note that the code buffer's insts_mark is always relative to insts.
  // That's why we must use the macroassembler to generate a handler.
  MacroAssembler _masm(&cbuf);
  address base = __ start_a_stub(size_deopt_handler());
  if (base == NULL)  return 0;  // CodeBuffer::expand failed
  int offset = __ offset();

#ifdef _LP64
  address the_pc = (address) __ pc();
  Label next;
  // push a "the_pc" on the stack without destroying any registers
  // as they all may be live.

  // push address of "next"
  __ call(next, relocInfo::none); // reloc none is fine since it is a disp32
  __ bind(next);
  // adjust it so it matches "the_pc"
  __ subptr(Address(rsp, 0), __ offset() - offset);
#else
  InternalAddress here(__ pc());
  __ pushptr(here.addr());
#endif

  __ jump(RuntimeAddress(SharedRuntime::deopt_blob()->unpack()));
  assert(__ offset() - offset <= (int) size_deopt_handler(), "overflow");
  __ end_a_stub();
  return offset;
*/
  // Note that the code buffer's insts_mark is always relative to insts.
  // That's why we must use the macroassembler to generate a handler.
  MacroAssembler _masm(&cbuf);
  address base =
  __ start_a_stub(size_deopt_handler());

  // FIXME
  if (base == NULL)  return 0;  // CodeBuffer::expand failed
  int offset = __ offset();

  __ block_comment("; emit_deopt_handler");

  cbuf.set_insts_mark();
  __ relocate(relocInfo::runtime_call_type);

  __ li48(T9, (long)SharedRuntime::deopt_blob()->unpack());
  __ jalr(T9);
  __ delayed()->nop();
  __ align(16);
  assert(__ offset() - offset <= (int) size_deopt_handler(), "overflow");
  __ end_a_stub();
  return offset;
}


const bool Matcher::match_rule_supported(int opcode) {
  if (!has_match_rule(opcode))
    return false;
/*
  switch (opcode) {
    case Op_PopCountI:
    case Op_PopCountL:
      if (!UsePopCountInstruction)
        return false;
    break;
    case Op_MulVI:
      if ((UseSSE < 4) && (UseAVX < 1)) // only with SSE4_1 or AVX
        return false;
    break;
    case Op_CompareAndSwapL:
#ifdef _LP64
    case Op_CompareAndSwapP:
#endif
      if (!VM_Version::supports_cx8())
        return false;
    break;
  }
*/
  return true;  // Per default match rules are supported.
}

//FIXME
// emit call stub, compiled java to interpreter
void emit_java_to_interp(CodeBuffer &cbuf ) {
  // Stub is fixed up when the corresponding call is converted from calling
  // compiled code to calling interpreted code.
  // mov rbx,0
  // jmp -1

  address mark = cbuf.insts_mark();  // get mark within main instrs section

  // Note that the code buffer's insts_mark is always relative to insts.
  // That's why we must use the macroassembler to generate a stub.
  MacroAssembler _masm(&cbuf);

  address base =
  __ start_a_stub(Compile::MAX_stubs_size);
  if (base == NULL)  return;  // CodeBuffer::expand failed
  // static stub relocation stores the instruction address of the call

  __ relocate(static_stub_Relocation::spec(mark), 0);

  /* 2012/10/29 Jin: Rmethod contains methodOop, it should be relocated for GC */
/*
  int oop_index = __ oop_recorder()->allocate_index(NULL);
  RelocationHolder rspec = oop_Relocation::spec(oop_index);
  __ relocate(rspec);
*/

  // static stub relocation also tags the methodOop in the code-stream.
  __ li48(S3, (long)0);
  // This is recognized as unresolved by relocs/nativeInst/ic code

  __ relocate(relocInfo::runtime_call_type);

  cbuf.set_insts_mark();
  address call_pc = (address)-1;
  __ li48(AT, (long)call_pc);
  __ jr(AT);
  __ nop();
  __ align(16);
  __ end_a_stub();
  // Update current stubs pointer and restore code_end.
}

// size of call stub, compiled java to interpretor
uint size_java_to_interp() {
  int size = 4 * 4 + NativeCall::instruction_size; // sizeof(li48) + NativeCall::instruction_size
  return round_to(size, 16);
}

// relocation entries for call stub, compiled java to interpreter
uint reloc_java_to_interp() {
  return 16;  //  in emit_java_to_interp +  in Java_Static_Call
}

bool Matcher::is_short_branch_offset(int rule, int br_size, int offset) {
 if( Assembler::is_simm16(offset) ) return true;
 else 
 {
    assert(false, "Not implemented yet !" );
    Unimplemented();
 }
}


// No additional cost for CMOVL.
const int Matcher::long_cmove_cost() { return 0; }

// No CMOVF/CMOVD with SSE2
const int Matcher::float_cmove_cost() { return ConditionalMoveLimit; }

// Does the CPU require late expand (see block.cpp for description of late expand)?
const bool Matcher::require_postalloc_expand = false;

// Do we need to mask the count passed to shift instructions or does
// the cpu only look at the lower 5/6 bits anyway?
const bool Matcher::need_masked_shift_count = false;

bool Matcher::narrow_oop_use_complex_address() {
  assert(UseCompressedOops, "only for compressed oops code");
  return (LogMinObjAlignmentInBytes <= 3);
}

bool Matcher::narrow_klass_use_complex_address() {
  assert(UseCompressedClassPointers, "only for compressed klass code");
  return (LogKlassAlignmentInBytes <= 3);
}

// This is UltraSparc specific, true just means we have fast l2f conversion
const bool Matcher::convL2FSupported(void) {
  return true;
}



// Max vector size in bytes. 0 if not supported.
const int Matcher::vector_width_in_bytes(BasicType bt) {
 // return UseSSE >= 2 ? 8 : 0;
  return 0;
}

// Register for MODI projection of divmodI
RegMask Matcher::modI_proj_mask() {
  return P_REG_mask();
}

// Register for DIVL projection of divmodL
RegMask Matcher::divL_proj_mask() {
  ShouldNotReachHere();
  return RegMask();
}

int Matcher::regnum_to_fpu_offset(int regnum) {
  return regnum - 32; // The FP registers are in the second chunk
}


const bool Matcher::isSimpleConstant64(jlong value) {
  // Will one (StoreL ConL) be cheaper than two (StoreI ConI)?.
  return false;
}

// Register for DIVI projection of divmodI
RegMask Matcher::divI_proj_mask() {
  return P_REG_mask();
}

// Limits on vector size (number of elements) loaded into vector.
const int Matcher::max_vector_size(const BasicType bt) {
	return vector_width_in_bytes(bt)/type2aelembytes(bt);
}
const int Matcher::min_vector_size(const BasicType bt) {
	int max_size = max_vector_size(bt);
	// Min size which can be loaded into vector is 4 bytes.
	int size = (type2aelembytes(bt) == 1) ? 4 : 2;
	return MIN2(size,max_size);
}

// Vector ideal reg
const int Matcher::vector_ideal_reg(int size) {
  return 0;
}

// Only lowest bits of xmm reg are used for vector shift count.
const int Matcher::vector_shift_count_ideal_reg(int size) {
  return Op_VecS;
}

// x86 supports misaligned vectors store/load.
const bool Matcher::misaligned_vectors_ok() {
  return !AlignVector; // can be changed by flag
}

// Return whether or not this register is ever used as an argument.  This
// function is used on startup to build the trampoline stubs in generateOptoStub.
// Registers not mentioned will be killed by the VM call in the trampoline, and
// arguments in those registers not be available to the callee.
bool Matcher::can_be_java_arg( int reg ) {
  /* Refer to: [sharedRuntime_mips_64.cpp] SharedRuntime::java_calling_convention() */
  if (    reg == T0_num || reg == T0_H_num
	   || reg == A0_num || reg == A0_H_num 
       || reg == A1_num || reg == A1_H_num 
       || reg == A2_num || reg == A2_H_num 
       || reg == A3_num || reg == A3_H_num 
       || reg == A4_num || reg == A4_H_num 
       || reg == A5_num || reg == A5_H_num 
       || reg == A6_num || reg == A6_H_num 
       || reg == A7_num || reg == A7_H_num )
    return true;

  if (reg >= F12_num && reg <= F19_num)
    return true;

  return false;
}

bool Matcher::is_spillable_arg( int reg ) {
  return can_be_java_arg(reg);
}

//TODO: in MIPS i donot know LEE
bool Matcher::use_asm_for_ldiv_by_con( jlong divisor ) {
  // In 64 bit mode a code which use multiply when
  // devisor is constant is faster than hardware
  // DIV instruction (it uses MulHiL).
  return false;
}

// Register for MODL projection of divmodL
RegMask Matcher::modL_proj_mask() {
  ShouldNotReachHere();
  return RegMask();
}

const RegMask Matcher::method_handle_invoke_SP_save_mask() {
  return FP_REG_mask();
}

// x86 AES instructions are compatible with SunJCE expanded
// keys, hence we do not need to pass the original key to stubs
const bool Matcher::pass_original_key_for_aes() {
  return false;
}

// The address of the call instruction needs to be 16-byte aligned to
// ensure that it does not span a cache line so that it can be patched.

int CallStaticJavaDirectNode::compute_padding(int current_offset) const {
  //lui
  //ori
  //dsll
  //ori

  //jalr
  //nop

  return round_to(current_offset, alignment_required()) - current_offset;
}

// The address of the call instruction needs to be 16-byte aligned to
// ensure that it does not span a cache line so that it can be patched.
int CallDynamicJavaDirectNode::compute_padding(int current_offset) const {
  //li64   <--- skip

  //lui
  //ori
  //dsll
  //ori

  //jalr
  //nop

  current_offset += 4 * 6; // skip li64 
  return round_to(current_offset, alignment_required()) - current_offset;
}

int CallLeafNoFPDirectNode::compute_padding(int current_offset) const {
  //lui
  //ori
  //dsll
  //ori

  //jalr
  //nop

  return round_to(current_offset, alignment_required()) - current_offset;
}

int CallLeafDirectNode::compute_padding(int current_offset) const {
  //lui
  //ori
  //dsll
  //ori

  //jalr
  //nop

  return round_to(current_offset, alignment_required()) - current_offset;
}

int CallRuntimeDirectNode::compute_padding(int current_offset) const {
  //lui
  //ori
  //dsll
  //ori

  //jalr
  //nop

  return round_to(current_offset, alignment_required()) - current_offset;
}

// If CPU can load and store mis-aligned doubles directly then no fixup is
// needed.  Else we split the double into 2 integer pieces and move it
// piece-by-piece.  Only happens when passing doubles into C code as the
// Java calling convention forces doubles to be aligned.
const bool Matcher::misaligned_doubles_ok = false;
// Do floats take an entire double register or just half?
//const bool Matcher::float_in_double = true;
bool Matcher::float_in_double() { return false; }
// Do ints take an entire long register or just half?
const bool Matcher::int_in_long = false;
// Threshold size for cleararray.
const int Matcher::init_array_short_size = 8 * BytesPerLong;
// Is it better to copy float constants, or load them directly from memory?
// Intel can load a float constant from a direct address, requiring no
// extra registers.  Most RISCs will have to materialize an address into a
// register first, so they would do better to copy the constant from stack.
const bool Matcher::rematerialize_float_constants = false;
// Advertise here if the CPU requires explicit rounding operations
// to implement the UseStrictFP mode.
const bool Matcher::strict_fp_requires_explicit_rounding = false;
// The ecx parameter to rep stos for the ClearArray node is in dwords.
const bool Matcher::init_array_count_is_in_bytes = false;
// Should the Matcher clone shifts on addressing modes, expecting them to
// be subsumed into complex addressing expressions or compute them into
// registers?  True for Intel but false for most RISCs
const bool Matcher::clone_shift_expressions = false;



// Indicate if the safepoint node needs the polling page as an input.
// Since x86 does have absolute addressing, it doesn't.
bool SafePointNode::needs_polling_address_input() {
  return false;
}

// !!!!! Special hack to get all type of calls to specify the byte offset
//       from the start of the call to the point where the return address
//       will point.
int MachCallStaticJavaNode::ret_addr_offset() {
  assert(NativeCall::instruction_size == 24, "in MachCallStaticJavaNode::ret_addr_offset");
  //The value ought to be 16 bytes.
  //lui
  //ori
  //dsll
  //ori
  //jalr
  //nop
  return NativeCall::instruction_size; 
}

int MachCallDynamicJavaNode::ret_addr_offset() {
  /* 2012/9/10 Jin: must be kept in sync with Java_Dynamic_Call */

 // return NativeCall::instruction_size; 
  assert(NativeCall::instruction_size == 24, "in MachCallDynamicJavaNode::ret_addr_offset");
  //The value ought to be 4 + 16 bytes.
  //lui IC_Klass,
  //ori IC_Klass,
  //dsll IC_Klass
  //ori IC_Klass
  //lui T9
  //ori T9
  //dsll T9
  //ori T9
  //jalr T9
  //nop
  return 6 * 4 + NativeCall::instruction_size; 

}

/*
// EMIT_OPCODE()
void emit_opcode(CodeBuffer &cbuf, int code) {
  *(cbuf.code_end()) = (unsigned char)code;
  cbuf.set_code_end(cbuf.code_end() + 1);
}
*/

void emit_d32_reloc(CodeBuffer &cbuf, int d32, relocInfo::relocType reloc,
        int format) {
  cbuf.relocate(cbuf.insts_mark(), reloc, format);
  cbuf.insts()->emit_int32(d32);
}

//=============================================================================

// Figure out which register class each belongs in: rc_int, rc_float, rc_stack
enum RC { rc_bad, rc_int, rc_float, rc_stack };
static enum RC rc_class( OptoReg::Name reg ) {
  if( !OptoReg::is_valid(reg)  ) return rc_bad;
  if (OptoReg::is_stack(reg)) return rc_stack;
  VMReg r = OptoReg::as_VMReg(reg);
  if (r->is_Register()) return rc_int;
  assert(r->is_FloatRegister(), "must be");
  return rc_float;
}

uint MachSpillCopyNode::implementation( CodeBuffer *cbuf, PhaseRegAlloc *ra_, bool do_size, outputStream* st ) const {
  // Get registers to move
  OptoReg::Name src_second = ra_->get_reg_second(in(1));
  OptoReg::Name src_first = ra_->get_reg_first(in(1));
  OptoReg::Name dst_second = ra_->get_reg_second(this );
  OptoReg::Name dst_first = ra_->get_reg_first(this );

  enum RC src_second_rc = rc_class(src_second);
  enum RC src_first_rc = rc_class(src_first);
  enum RC dst_second_rc = rc_class(dst_second);
  enum RC dst_first_rc = rc_class(dst_first);

  assert(OptoReg::is_valid(src_first) && OptoReg::is_valid(dst_first), "must move at least 1 register" );

  // Generate spill code!
  int size = 0;

  if( src_first == dst_first && src_second == dst_second )
    return 0;            // Self copy, no move

  if (src_first_rc == rc_stack) {
    // mem ->
    if (dst_first_rc == rc_stack) {
      // mem -> mem
      assert(src_second != dst_first, "overlap");
      if ((src_first & 1) == 0 && src_first + 1 == src_second &&
          (dst_first & 1) == 0 && dst_first + 1 == dst_second) {
        // 64-bit
        int src_offset = ra_->reg2offset(src_first);
        int dst_offset = ra_->reg2offset(dst_first);
        if (cbuf) {
          MacroAssembler _masm(cbuf);
          __ ld(AT, Address(SP, src_offset));
          __ sd(AT, Address(SP, dst_offset));
#ifndef PRODUCT
        } else {
			if(!do_size){
				if (size != 0) st->print("\n\t");
				st->print("ld    AT, [SP + #%d]\t# 64-bit mem-mem spill 1\n\t"
						  "sd    AT, [SP + #%d]",
						  src_offset, dst_offset);
			}
#endif
        }
		size += 8;
      } else {
        // 32-bit
        assert(!((src_first & 1) == 0 && src_first + 1 == src_second), "no transform");
        assert(!((dst_first & 1) == 0 && dst_first + 1 == dst_second), "no transform");
        // No pushl/popl, so:
        int src_offset = ra_->reg2offset(src_first);
        int dst_offset = ra_->reg2offset(dst_first);
        if (cbuf) {
          MacroAssembler _masm(cbuf);
          __ lw(AT, Address(SP, src_offset));
          __ sw(AT, Address(SP, dst_offset));
#ifndef PRODUCT
        } else {
			if(!do_size){
				if (size != 0) st->print("\n\t");
				st->print("lw    AT, [SP + #%d] spill 2\n\t"
						  "sw    AT, [SP + #%d]\n\t",
						  src_offset, dst_offset);
			}
#endif
        }
		size += 8;
      }
      return size;
    } else if (dst_first_rc == rc_int) {
      // mem -> gpr
      if ((src_first & 1) == 0 && src_first + 1 == src_second &&
          (dst_first & 1) == 0 && dst_first + 1 == dst_second) {
        // 64-bit
        int offset = ra_->reg2offset(src_first);
        if (cbuf) {
          MacroAssembler _masm(cbuf);
          __ ld(as_Register(Matcher::_regEncode[dst_first]), Address(SP, offset));
#ifndef PRODUCT
        } else {
			if(!do_size){
				if (size != 0) st->print("\n\t");
				st->print("ld    %s, [SP + #%d]\t# spill 3",
						  Matcher::regName[dst_first],
						  offset);
			}
#endif
        }
		size += 4;
      } else {
        // 32-bit
        assert(!((src_first & 1) == 0 && src_first + 1 == src_second), "no transform");
        assert(!((dst_first & 1) == 0 && dst_first + 1 == dst_second), "no transform");
        int offset = ra_->reg2offset(src_first);
        if (cbuf) {
          MacroAssembler _masm(cbuf);
          if (this->ideal_reg() == Op_RegI)
            __ lw(as_Register(Matcher::_regEncode[dst_first]), Address(SP, offset));
          else
            __ lwu(as_Register(Matcher::_regEncode[dst_first]), Address(SP, offset));
#ifndef PRODUCT
        } else {
			if(!do_size){
				if (size != 0) st->print("\n\t");
          if (this->ideal_reg() == Op_RegI)
				st->print("lw    %s, [SP + #%d]\t# spill 4",
						   Matcher::regName[dst_first],
						   offset);
		  else
				st->print("lwu    %s, [SP + #%d]\t# spill 5",
						   Matcher::regName[dst_first],
						   offset);
			}
#endif
        }
		size += 4;
      }
      return size;
    } else if (dst_first_rc == rc_float) {
      // mem-> xmm
      if ((src_first & 1) == 0 && src_first + 1 == src_second &&
          (dst_first & 1) == 0 && dst_first + 1 == dst_second) {
        // 64-bit
        int offset = ra_->reg2offset(src_first);
        if (cbuf) {
          MacroAssembler _masm(cbuf);
          __ ldc1( as_FloatRegister(Matcher::_regEncode[dst_first]), Address(SP, offset));
#ifndef PRODUCT
        } else {
			if(!do_size){
				if (size != 0) st->print("\n\t");
				st->print("ldc1  %s, [SP + #%d]\t# spill 6",
						  Matcher::regName[dst_first],
						  offset);
			}
#endif
        }
		size += 4;
      } else {
        // 32-bit
        assert(!((src_first & 1) == 0 && src_first + 1 == src_second), "no transform");
        assert(!((dst_first & 1) == 0 && dst_first + 1 == dst_second), "no transform");
        int offset = ra_->reg2offset(src_first);
        if (cbuf) {
          MacroAssembler _masm(cbuf);
          __ lwc1( as_FloatRegister(Matcher::_regEncode[dst_first]), Address(SP, offset));
#ifndef PRODUCT
        } else {
			if(!do_size){
				if (size != 0) st->print("\n\t");
				st->print("lwc1   %s, [SP + #%d]\t# spill 7",
						  Matcher::regName[dst_first],
						  offset);
			}
#endif
        }
		size += 4;
      }
      return size;
    }
  } else if (src_first_rc == rc_int) {
    // gpr ->
    if (dst_first_rc == rc_stack) {
      // gpr -> mem
      if ((src_first & 1) == 0 && src_first + 1 == src_second &&
          (dst_first & 1) == 0 && dst_first + 1 == dst_second) {
        // 64-bit
        int offset = ra_->reg2offset(dst_first);
        if (cbuf) {
          MacroAssembler _masm(cbuf);
          __ sd(as_Register(Matcher::_regEncode[src_first]), Address(SP, offset));
#ifndef PRODUCT
        } else {
			if(!do_size){
				if (size != 0) st->print("\n\t");
				st->print("sd    %s, [SP + #%d] # spill 8",
						  Matcher::regName[src_first],
						  offset);
			}
#endif
        }
		size += 4;
      } else {
        // 32-bit
        assert(!((src_first & 1) == 0 && src_first + 1 == src_second), "no transform");
        assert(!((dst_first & 1) == 0 && dst_first + 1 == dst_second), "no transform");
        int offset = ra_->reg2offset(dst_first);
        if (cbuf) {
          MacroAssembler _masm(cbuf);
          __ sw(as_Register(Matcher::_regEncode[src_first]), Address(SP, offset));
#ifndef PRODUCT
        } else {
			if(!do_size){
				if (size != 0) st->print("\n\t");
				st->print("sw    [SP + #%d], %s\t# spill 9",
						offset,
						Matcher::regName[src_first]);
			}
#endif
        }
		size += 4;
      }
      return size;
    } else if (dst_first_rc == rc_int) {
      // gpr -> gpr
      if ((src_first & 1) == 0 && src_first + 1 == src_second &&
          (dst_first & 1) == 0 && dst_first + 1 == dst_second) {
        // 64-bit
        if (cbuf) {
          MacroAssembler _masm(cbuf);
          __ move(as_Register(Matcher::_regEncode[dst_first]),
                  as_Register(Matcher::_regEncode[src_first]));
#ifndef PRODUCT
        } else {
			if(!do_size){
				if (size != 0) st->print("\n\t");
				st->print("move(64bit)    %s, %s\t# spill 10",
						  Matcher::regName[dst_first],
						  Matcher::regName[src_first]);
			}
#endif
        }
		size += 4;
        return size;
      } else {
        // 32-bit
        assert(!((src_first & 1) == 0 && src_first + 1 == src_second), "no transform");
        assert(!((dst_first & 1) == 0 && dst_first + 1 == dst_second), "no transform");
        if (cbuf) {
          MacroAssembler _masm(cbuf);
          if (this->ideal_reg() == Op_RegI)
              __ move_u32(as_Register(Matcher::_regEncode[dst_first]), as_Register(Matcher::_regEncode[src_first]));
          else
              __ daddu(as_Register(Matcher::_regEncode[dst_first]), as_Register(Matcher::_regEncode[src_first]), R0);

#ifndef PRODUCT
        } else {
			if(!do_size){
				if (size != 0) st->print("\n\t");
				st->print("move(32-bit)    %s, %s\t# spill 11",
						  Matcher::regName[dst_first],
						  Matcher::regName[src_first]);
			}
#endif
        }
		size += 4;	
        return size;
      }
    } else if (dst_first_rc == rc_float) {
      // gpr -> xmm
      if ((src_first & 1) == 0 && src_first + 1 == src_second &&
          (dst_first & 1) == 0 && dst_first + 1 == dst_second) {
        // 64-bit
        if (cbuf) {
          MacroAssembler _masm(cbuf);
          __ dmtc1(as_Register(Matcher::_regEncode[src_first]), as_FloatRegister(Matcher::_regEncode[dst_first]));
#ifndef PRODUCT
        } else {
			if(!do_size){
				if (size != 0) st->print("\n\t");
				st->print("dmtc1   %s, %s\t# spill 12",
						  Matcher::regName[dst_first],
						  Matcher::regName[src_first]);
			}
#endif
        }
		size += 4;
      } else {
        // 32-bit
        assert(!((src_first & 1) == 0 && src_first + 1 == src_second), "no transform");
        assert(!((dst_first & 1) == 0 && dst_first + 1 == dst_second), "no transform");
        if (cbuf) {
          MacroAssembler _masm(cbuf);
          __ mtc1( as_Register(Matcher::_regEncode[src_first]), as_FloatRegister(Matcher::_regEncode[dst_first]) );
#ifndef PRODUCT
        } else {
			if(!do_size){
				if (size != 0) st->print("\n\t");
				st->print("mtc1   %s, %s\t# spill 13",
						  Matcher::regName[dst_first],
						  Matcher::regName[src_first]);
			}
#endif
        }
		size += 4;
      }
      return size;
    }
  } else if (src_first_rc == rc_float) {
    // xmm ->
    if (dst_first_rc == rc_stack) {
      // xmm -> mem
      if ((src_first & 1) == 0 && src_first + 1 == src_second &&
          (dst_first & 1) == 0 && dst_first + 1 == dst_second) {
        // 64-bit
        int offset = ra_->reg2offset(dst_first);
        if (cbuf) {
          MacroAssembler _masm(cbuf);
          __ sdc1( as_FloatRegister(Matcher::_regEncode[src_first]), Address(SP, offset) );
#ifndef PRODUCT
        } else {
			if(!do_size){
				if (size != 0) st->print("\n\t");
				st->print("sdc1   %s, [SP + #%d]\t# spill 14",
						  Matcher::regName[src_first],
						  offset);
			}
#endif
        }
		size += 4;
      } else {
        // 32-bit
        assert(!((src_first & 1) == 0 && src_first + 1 == src_second), "no transform");
        assert(!((dst_first & 1) == 0 && dst_first + 1 == dst_second), "no transform");
        int offset = ra_->reg2offset(dst_first);
        if (cbuf) {
          MacroAssembler _masm(cbuf);
          __ swc1(as_FloatRegister(Matcher::_regEncode[src_first]), Address(SP, offset));
#ifndef PRODUCT
        } else {
			if(!do_size){
				if (size != 0) st->print("\n\t");
				st->print("swc1   %s, [SP + #%d]\t# spill 15",
						Matcher::regName[src_first],
						offset);
			}
#endif
        }
		size += 4;
      }
      return size;
    } else if (dst_first_rc == rc_int) {
      // xmm -> gpr
      if ((src_first & 1) == 0 && src_first + 1 == src_second &&
          (dst_first & 1) == 0 && dst_first + 1 == dst_second) {
        // 64-bit
        if (cbuf) {
          MacroAssembler _masm(cbuf);
          __ dmfc1( as_Register(Matcher::_regEncode[dst_first]), as_FloatRegister(Matcher::_regEncode[src_first]));
#ifndef PRODUCT
        } else {
			if(!do_size){
				if (size != 0) st->print("\n\t");
				st->print("dmfc1   %s, %s\t# spill 16",
						  Matcher::regName[dst_first],
						  Matcher::regName[src_first]);
			}
#endif
        }
		size += 4;
      } else {
        // 32-bit
        assert(!((src_first & 1) == 0 && src_first + 1 == src_second), "no transform");
        assert(!((dst_first & 1) == 0 && dst_first + 1 == dst_second), "no transform");
        if (cbuf) {
          MacroAssembler _masm(cbuf);
          __ mfc1( as_Register(Matcher::_regEncode[dst_first]), as_FloatRegister(Matcher::_regEncode[src_first]));
#ifndef PRODUCT
        } else {
			if(!do_size){
				if (size != 0) st->print("\n\t");
				st->print("mfc1   %s, %s\t# spill 17",
						  Matcher::regName[dst_first],
						  Matcher::regName[src_first]);
			}
#endif
        }
		size += 4;
      }
      return size;
    } else if (dst_first_rc == rc_float) {
      // xmm -> xmm
      if ((src_first & 1) == 0 && src_first + 1 == src_second &&
          (dst_first & 1) == 0 && dst_first + 1 == dst_second) {
        // 64-bit
        if (cbuf) {
          MacroAssembler _masm(cbuf);
          __ mov_d( as_FloatRegister(Matcher::_regEncode[dst_first]), as_FloatRegister(Matcher::_regEncode[src_first]));
#ifndef PRODUCT
        } else {
			if(!do_size){
				if (size != 0) st->print("\n\t");
				st->print("mov_d  %s, %s\t# spill 18",
						  Matcher::regName[dst_first],
						  Matcher::regName[src_first]);
			}
#endif
        }
		size += 4;
      } else {
        // 32-bit
        assert(!((src_first & 1) == 0 && src_first + 1 == src_second), "no transform");
        assert(!((dst_first & 1) == 0 && dst_first + 1 == dst_second), "no transform");
        if (cbuf) {
          MacroAssembler _masm(cbuf);
          __ mov_s( as_FloatRegister(Matcher::_regEncode[dst_first]), as_FloatRegister(Matcher::_regEncode[src_first]));
#ifndef PRODUCT
        } else {
			if(!do_size){
				if (size != 0) st->print("\n\t");
				st->print("mov_s  %s, %s\t# spill 19",
						  Matcher::regName[dst_first],
						  Matcher::regName[src_first]);
			}
#endif
        }
		size += 4;
      }
      return size;
    }
  }

  assert(0," foo ");
  Unimplemented();
  return size;

}

#ifndef PRODUCT
void MachSpillCopyNode::format( PhaseRegAlloc *ra_, outputStream* st ) const {
  implementation( NULL, ra_, false, st );
}
#endif

void MachSpillCopyNode::emit(CodeBuffer &cbuf, PhaseRegAlloc *ra_) const {
  implementation( &cbuf, ra_, false, NULL );
}

uint MachSpillCopyNode::size(PhaseRegAlloc *ra_) const {
  return implementation( NULL, ra_, true, NULL );
}

//=============================================================================
#

#ifndef PRODUCT
void MachBreakpointNode::format( PhaseRegAlloc *, outputStream* st ) const {
  st->print("INT3");
}
#endif

void MachBreakpointNode::emit(CodeBuffer &cbuf, PhaseRegAlloc* ra_) const {
  MacroAssembler _masm(&cbuf);
  __ int3();
}

uint MachBreakpointNode::size(PhaseRegAlloc* ra_) const {
  return MachNode::size(ra_);
}


//=============================================================================
#ifndef PRODUCT
void MachEpilogNode::format( PhaseRegAlloc *ra_, outputStream* st ) const {
  Compile *C = ra_->C;
  int framesize = C->frame_size_in_bytes();

  assert((framesize & (StackAlignmentInBytes-1)) == 0, "frame size not aligned");

  st->print("daddiu   SP, SP, %d # Rlease stack @ MachEpilogNode",framesize);
  st->cr(); st->print("\t");
  st->print("ld    RA, SP, %d # Restore RA @ MachEpilogNode", -8);
  st->cr(); st->print("\t");
  st->print("ld    FP, SP, %d # Restore FP @ MachEpilogNode", -16);

  if( do_polling() && C->is_method_compilation() ) {
    st->print("Poll Safepoint # MachEpilogNode");
  }
}
#endif

void MachEpilogNode::emit(CodeBuffer &cbuf, PhaseRegAlloc *ra_) const {
  Compile *C = ra_->C;
  MacroAssembler _masm(&cbuf);
  int framesize = C->frame_size_in_bytes();

  assert((framesize & (StackAlignmentInBytes-1)) == 0, "frame size not aligned");

  __ daddiu(SP, SP, framesize);
  __ ld(RA, SP, -wordSize );
  __ ld(FP, SP, -wordSize*2 );

  /* 2012/11/19 Jin: The epilog in a RuntimeStub should not contain a safepoint */
  if( do_polling() && C->is_method_compilation() ) {
#ifndef OPT_SAFEPOINT
    __ li48(AT, (long)os::get_polling_page());
    __ relocate(relocInfo::poll_return_type);
    __ lw(AT, AT, 0);
#else
    __ lui(AT, Assembler::split_high((intptr_t)os::get_polling_page()));
    __ relocate(relocInfo::poll_return_type);
    __ lw(AT, AT, Assembler::split_low((intptr_t)os::get_polling_page()));
#endif
  }
}

uint MachEpilogNode::size(PhaseRegAlloc *ra_) const {
  return MachNode::size(ra_); // too many variables; just compute it the hard way  fujie debug
}

int MachEpilogNode::reloc() const {
  return 0; // a large enough number
}

const Pipeline * MachEpilogNode::pipeline() const {
  return MachNode::pipeline_class();
}

int MachEpilogNode::safepoint_offset() const { return 0; }

//=============================================================================

#ifndef PRODUCT
void BoxLockNode::format( PhaseRegAlloc *ra_, outputStream* st ) const {
  int offset = ra_->reg2offset(in_RegMask(0).find_first_elem());
  int reg = ra_->get_reg_first(this);
  st->print("ADDI %s, SP, %d   @BoxLockNode",Matcher::regName[reg],offset);
}
#endif


uint BoxLockNode::size(PhaseRegAlloc *ra_) const {
  return 4;
}

void BoxLockNode::emit(CodeBuffer &cbuf, PhaseRegAlloc *ra_) const {
  MacroAssembler _masm(&cbuf);
  int offset = ra_->reg2offset(in_RegMask(0).find_first_elem());
  int reg = ra_->get_encode(this);

  __ addi(as_Register(reg), SP, offset);
/*
  if( offset >= 128 ) {
    emit_opcode(cbuf, 0x8D);      // LEA  reg,[SP+offset]
    emit_rm(cbuf, 0x2, reg, 0x04);
    emit_rm(cbuf, 0x0, 0x04, SP_enc);
    emit_d32(cbuf, offset);
  }
  else {
    emit_opcode(cbuf, 0x8D);      // LEA  reg,[SP+offset]
    emit_rm(cbuf, 0x1, reg, 0x04);
    emit_rm(cbuf, 0x0, 0x04, SP_enc);
    emit_d8(cbuf, offset);
  }
*/
}


//static int sizeof_FFree_Float_Stack_All = -1;

int MachCallRuntimeNode::ret_addr_offset() {
  //lui
  //ori
  //dsll
  //ori
  //jalr
  //nop
  assert(NativeCall::instruction_size == 24, "in MachCallRuntimeNode::ret_addr_offset()");
  return NativeCall::instruction_size;
//  return 16;
}





//=============================================================================
#ifndef PRODUCT
void MachNopNode::format( PhaseRegAlloc *, outputStream* st ) const {
  st->print("NOP \t# %d bytes pad for loops and calls", 4 * _count);
}
#endif

void MachNopNode::emit(CodeBuffer &cbuf, PhaseRegAlloc * ) const {
  MacroAssembler _masm(&cbuf);
  int i = 0;
  for(i = 0; i < _count; i++)
     __ nop();
}

uint MachNopNode::size(PhaseRegAlloc *) const {
  return 4 * _count; 
}
const Pipeline* MachNopNode::pipeline() const {
  return MachNode::pipeline_class();
}

//=============================================================================

//=============================================================================
#ifndef PRODUCT
void MachUEPNode::format( PhaseRegAlloc *ra_, outputStream* st ) const {
  st->print_cr("load_klass(AT, T0)");
  st->print_cr("\tbeq(AT, iCache, L)");
  st->print_cr("\tnop");
  st->print_cr("\tjmp(SharedRuntime::get_ic_miss_stub(), relocInfo::runtime_call_type)");
  st->print_cr("\tnop");
  st->print_cr("\tnop");
  st->print_cr("    L:");
}
#endif


void MachUEPNode::emit(CodeBuffer &cbuf, PhaseRegAlloc *ra_) const {
  MacroAssembler _masm(&cbuf);
#ifdef ASSERT
  //uint code_size = cbuf.code_size();
#endif
  int  ic_reg = Matcher::inline_cache_reg_encode();
  Label L;
  Register receiver = T0;
  Register   iCache = as_Register(ic_reg);
  __ load_klass(AT, receiver);
  __ beq(AT, iCache, L);
  __ nop();

  __ relocate(relocInfo::runtime_call_type);
  __ li48(T9, (long)SharedRuntime::get_ic_miss_stub());
  __ jr(T9);
  __ nop();

  /* WARNING these NOPs are critical so that verified entry point is properly
   *      8 bytes aligned for patching by NativeJump::patch_verified_entry() */
  __ align(CodeEntryAlignment);
  __ bind(L);
}

uint MachUEPNode::size(PhaseRegAlloc *ra_) const {
  return MachNode::size(ra_); 
}



//=============================================================================

const RegMask& MachConstantBaseNode::_out_RegMask = RegMask::Empty;

int Compile::ConstantTable::calculate_table_base_offset() const {
  return 0;  // absolute addressing, no offset
}

bool MachConstantBaseNode::requires_postalloc_expand() const { return false; }
void MachConstantBaseNode::postalloc_expand(GrowableArray <Node *> *nodes, PhaseRegAlloc *ra_) {
  ShouldNotReachHere();
}

void MachConstantBaseNode::emit(CodeBuffer& cbuf, PhaseRegAlloc* ra_) const {
  // Empty encoding
}

uint MachConstantBaseNode::size(PhaseRegAlloc* ra_) const {
  return 0;
}

#ifndef PRODUCT
void MachConstantBaseNode::format(PhaseRegAlloc* ra_, outputStream* st) const {
  st->print("# MachConstantBaseNode (empty encoding)");
}
#endif


//=============================================================================
#ifndef PRODUCT
void MachPrologNode::format( PhaseRegAlloc *ra_, outputStream* st ) const {
  Compile* C = ra_->C;

  int framesize = C->frame_size_in_bytes();
  int bangsize = C->bang_size_in_bytes();
  assert((framesize & (StackAlignmentInBytes-1)) == 0, "frame size not aligned");

  // Calls to C2R adapters often do not accept exceptional returns.
  // We require that their callers must bang for them.  But be careful, because
  // some VM calls (such as call site linkage) can use several kilobytes of
  // stack.  But the stack safety zone should account for that.
  // See bugs 4446381, 4468289, 4497237.
  if (C->need_stack_bang(bangsize)) {
    st->print_cr("# stack bang"); st->print("\t");
  }
    st->print("sd       RA, (SP)-8  @ MachPrologNode\n\t");
    st->print("sd       FP, (SP)-16 \n\t");
    st->print("daddiu   FP, SP, -16 \n\t");
    st->print("daddiu   SP, SP, -%d \t",framesize);
}
#endif


void MachPrologNode::emit(CodeBuffer &cbuf, PhaseRegAlloc *ra_) const {
  Compile* C = ra_->C;
  MacroAssembler _masm(&cbuf);

  int framesize = C->frame_size_in_bytes();
  int bangsize = C->bang_size_in_bytes();

//  __ verified_entry(framesize, C->need_stack_bang(bangsize)?bangsize:0, false);

  assert((framesize & (StackAlignmentInBytes-1)) == 0, "frame size not aligned");

  if (C->need_stack_bang(framesize)) {
    __ generate_stack_overflow_check(framesize);
  }

  __ sd(RA, SP, -wordSize);
  __ sd(FP, SP, -wordSize*2);
  __ daddiu(FP, SP, -wordSize*2);
  __ daddiu(SP, SP, -framesize);
  __ nop(); /* 2013.10.22 Jin: Make enough room for patch_verified_entry() */
  __ nop();

  C->set_frame_complete(cbuf.insts_size());
  if (C->has_mach_constant_base_node()) {
	  // NOTE: We set the table base offset here because users might be
	  // emitted before MachConstantBaseNode.
	  Compile::ConstantTable& constant_table = C->constant_table();
	  constant_table.set_table_base_offset(constant_table.calculate_table_base_offset());
  }

}


uint MachPrologNode::size(PhaseRegAlloc *ra_) const {
//fprintf(stderr, "\nPrologNode::size(ra_)= %d \n", MachNode::size(ra_));//fujie debug
  return MachNode::size(ra_); // too many variables; just compute it the hard way
}

int MachPrologNode::reloc() const {
  return 0; // a large enough number
}

%}

//----------ENCODING BLOCK-----------------------------------------------------
// This block specifies the encoding classes used by the compiler to output
// byte streams.  Encoding classes generate functions which are called by
// Machine Instruction Nodes in order to generate the bit encoding of the
// instruction.  Operands specify their base encoding interface with the
// interface keyword.  There are currently supported four interfaces,
// REG_INTER, CONST_INTER, MEMORY_INTER, & COND_INTER.  REG_INTER causes an
// operand to generate a function which returns its register number when
// queried.   CONST_INTER causes an operand to generate a function which
// returns the value of the constant when queried.  MEMORY_INTER causes an
// operand to generate four functions which return the Base Register, the
// Index Register, the Scale Value, and the Offset Value of the operand when
// queried.  COND_INTER causes an operand to generate six functions which
// return the encoding code (ie - encoding bits for the instruction)
// associated with each basic boolean condition for a conditional instruction.
// Instructions specify two basic values for encoding.  They use the
// ins_encode keyword to specify their encoding class (which must be one of
// the class names specified in the encoding block), and they use the
// opcode keyword to specify, in order, their primary, secondary, and
// tertiary opcode.  Only the opcode sections which a particular instruction
// needs for encoding need to be specified.
encode %{
/*
Alias:
1044   b   java.io.ObjectInputStream::readHandle (130 bytes)
    118   B14: #    B19 B15 <- B13  Freq: 0.899955
    118     add    S1, S2, V0 #@addP_reg_reg
    11c     lb   S0, [S1 + #-8257524] #@loadB
    120     BReq   S0, #3, B19 #@branchConI_reg_imm  P=0.100000 C=-1.000000
*/
  //Load byte signed
  enc_class load_B_enc (mRegI dst, memory mem) %{
     MacroAssembler _masm(&cbuf);
     int  dst = $dst$$reg;
     int  base = $mem$$base;
     int  index = $mem$$index;
     int  scale = $mem$$scale;
     int  disp = $mem$$disp;

     guarantee(scale == 0, "scale is not zero !");

     if( index != 0 ) {
        if( Assembler::is_simm16(disp) ) { 
           if( UseLoongsonISA && Assembler::is_simm(disp, 8) ) {
              __ gslbx(as_Register(dst), as_Register(base), as_Register(index), disp);
           } else {
              __ addu(AT, as_Register(base), as_Register(index));
              __ lb(as_Register(dst), AT, disp);
           }
        } else {
           __ addu(AT, as_Register(base), as_Register(index));
           __ move(T9, disp);
           if( UseLoongsonISA ) {
              __ gslbx(as_Register(dst), AT, T9, 0);
           } else {
              __ addu(AT, AT, T9); 
              __ lb(as_Register(dst), AT, 0);
           }
        }    
     } else {
        if( Assembler::is_simm16(disp) ) { 
           __ lb(as_Register(dst), as_Register(base), disp);
        } else {
           __ move(T9, disp);   
           if( UseLoongsonISA ) {
              __ gslbx(as_Register(dst), as_Register(base), T9, 0);
           } else {
              __ addu(AT, as_Register(base), T9); 
              __ lb(as_Register(dst), AT, 0);
           }
        }    
     }
  %}

  //Load byte unsigned
  enc_class load_UB_enc (mRegI dst, memory mem) %{
     MacroAssembler _masm(&cbuf);
     int  dst = $dst$$reg;
     int  base = $mem$$base;
     int  index = $mem$$index;
     int  scale = $mem$$scale;
     int  disp = $mem$$disp;

     guarantee(scale == 0, "scale is not zero !");

     if( index != 0 ) {
        __ daddu(AT, as_Register(base), as_Register(index));
        if( Assembler::is_simm16(disp) ) { 
           __ lbu(as_Register(dst), AT, disp);
        } else {
           __ move(T9, disp);
           __ daddu(AT, AT, T9); 
           __ lbu(as_Register(dst), AT, 0);
        }    
     } else {
        if( Assembler::is_simm16(disp) ) { 
           __ lbu(as_Register(dst), as_Register(base), disp);
        } else {
           __ move(T9, disp);   
           __ daddu(AT, as_Register(base), T9); 
           __ lbu(as_Register(dst), AT, 0);
        }    
     }
  %}

  enc_class store_B_reg_enc (memory mem, mRegI src) %{
     MacroAssembler _masm(&cbuf);
     int  src = $src$$reg;
     int  base = $mem$$base;
     int  index = $mem$$index;
     int  scale = $mem$$scale;
     int  disp = $mem$$disp;

     guarantee(scale == 0, "scale is not zero !");

     if( index != 0 ) {
        __ addu(AT, as_Register(base), as_Register(index));
        if( Assembler::is_simm16(disp) ) { 
           __ sb(as_Register(src), AT, disp);
        } else {
           __ move(T9, disp);
           __ addu(AT, AT, T9); 
           __ sb(as_Register(src), AT, 0);
        }    
     } else {
        if( Assembler::is_simm16(disp) ) { 
           __ sb(as_Register(src), as_Register(base), disp);
        } else {
           __ move(T9, disp);   
           __ addu(AT, as_Register(base), T9); 
           __ sb(as_Register(src), AT, 0);
        }    
     }
  %}

  enc_class store_B_immI_enc (memory mem, immI8 src) %{
     MacroAssembler _masm(&cbuf);
     int  base = $mem$$base;
     int  index = $mem$$index;
     int  scale = $mem$$scale;
     int  disp = $mem$$disp;
     int value = $src$$constant;

     guarantee(scale == 0, "scale is not zero !");

     if( index != 0 ) {
        __ daddu(AT, as_Register(base), as_Register(index));
        if( Assembler::is_simm16(disp) ) { 
           if (value == 0) {
              __ sb(R0, AT, disp);
           } else {
              __ move(T9, value);
              __ sb(T9, AT, disp);
           }
        } else {
           if (value == 0) {
              __ move(T9, disp);
              __ daddu(AT, AT, T9); 
              __ sb(R0, AT, 0);
           } else {
              __ move(T9, disp);
              __ daddu(AT, AT, T9); 
              __ move(T9, value);
              __ sb(T9, AT, 0);
           }
        }    
     } else {
        if( Assembler::is_simm16(disp) ) { 
           if (value == 0) {
              __ sb(R0, as_Register(base), disp);
           } else {
              __ move(AT, value);
              __ sb(AT, as_Register(base), disp);
           }
        } else {
           if (value == 0) {
              __ move(T9, disp);   
              __ daddu(AT, as_Register(base), T9); 
              __ sb(R0, AT, 0);
           } else {
              __ move(T9, disp);   
              __ daddu(AT, as_Register(base), T9); 
              __ move(T9, value);
              __ sb(T9, AT, 0);
           }
        }    
     }
  %}


  enc_class store_B_immI_enc_sync (memory mem, immI8 src) %{
     MacroAssembler _masm(&cbuf);
     int  base = $mem$$base;
     int  index = $mem$$index;
     int  scale = $mem$$scale;
     int  disp = $mem$$disp;
     int value = $src$$constant;

     guarantee(scale == 0, "scale is not zero !");

     if( index != 0 ) {
        __ daddu(AT, as_Register(base), as_Register(index));
        if( Assembler::is_simm16(disp) ) { 
           if (value == 0) {
              __ sync();
              __ sb(R0, AT, disp);
           } else {
              __ move(T9, value);
              __ sync();
              __ sb(T9, AT, disp);
           }
        } else {
           if (value == 0) {
              __ move(T9, disp);
              __ daddu(AT, AT, T9); 
              __ sync();
              __ sb(R0, AT, 0);
           } else {
              __ move(T9, disp);
              __ daddu(AT, AT, T9); 
              __ move(T9, value);
              __ sync();
              __ sb(T9, AT, 0);
           }
        }    
     } else {
        if( Assembler::is_simm16(disp) ) { 
           if (value == 0) {
              __ sync();
              __ sb(R0, as_Register(base), disp);
           } else {
              __ move(AT, value);
              __ sync();
              __ sb(AT, as_Register(base), disp);
           }
        } else {
           if (value == 0) {
              __ move(T9, disp);   
              __ daddu(AT, as_Register(base), T9); 
              __ sync();
              __ sb(R0, AT, 0);
           } else {
              __ move(T9, disp);   
              __ daddu(AT, as_Register(base), T9); 
              __ move(T9, value);
              __ sync();
              __ sb(T9, AT, 0);
           }
        }    
     }
  %}

  // Load Short (16bit signed)
  enc_class load_S_enc (mRegI dst, memory mem) %{
     MacroAssembler _masm(&cbuf);
     int  dst = $dst$$reg;
     int  base = $mem$$base;
     int  index = $mem$$index;
     int  scale = $mem$$scale;
     int  disp = $mem$$disp;

     guarantee(scale == 0, "scale is not zero !");

     if( index != 0 ) {
        __ addu(AT, as_Register(base), as_Register(index));
        if( Assembler::is_simm16(disp) ) { 
           __ lh(as_Register(dst), AT, disp);
        } else {
           __ move(T9, disp);
           __ addu(AT, AT, T9); 
           __ lh(as_Register(dst), AT, 0);
        }    
     } else {
        if( Assembler::is_simm16(disp) ) { 
           __ lh(as_Register(dst), as_Register(base), disp);
        } else {
           __ move(T9, disp);   
           __ addu(AT, as_Register(base), T9); 
           __ lh(as_Register(dst), AT, 0);
        }    
     }
  %}

  // Load Char (16bit unsigned)
  enc_class load_C_enc (mRegI dst, memory mem) %{
     MacroAssembler _masm(&cbuf);
     int  dst = $dst$$reg;
     int  base = $mem$$base;
     int  index = $mem$$index;
     int  scale = $mem$$scale;
     int  disp = $mem$$disp;

     guarantee(scale == 0, "scale is not zero !");

     if( index != 0 ) {
        __ daddu(AT, as_Register(base), as_Register(index));
        if( Assembler::is_simm16(disp) ) { 
           __ lhu(as_Register(dst), AT, disp);
        } else {
           __ move(T9, disp);
           __ addu(AT, AT, T9); 
           __ lhu(as_Register(dst), AT, 0);
        }    
     } else {
        if( Assembler::is_simm16(disp) ) { 
           __ lhu(as_Register(dst), as_Register(base), disp);
        } else {
           __ move(T9, disp);   
           __ daddu(AT, as_Register(base), T9); 
           __ lhu(as_Register(dst), AT, 0);
        }    
     }
  %}

  // Store Char (16bit unsigned)
  enc_class store_C_reg_enc (memory mem, mRegI src) %{
     MacroAssembler _masm(&cbuf);
     int  src = $src$$reg;
     int  base = $mem$$base;
     int  index = $mem$$index;
     int  scale = $mem$$scale;
     int  disp = $mem$$disp;

     guarantee(scale == 0, "scale is not zero !");

     if( index != 0 ) {
        if( Assembler::is_simm16(disp) ) { 
           if( UseLoongsonISA && Assembler::is_simm(disp, 8) ) {
              __ gsshx(as_Register(src), as_Register(base), as_Register(index), disp);
           } else {
              __ addu(AT, as_Register(base), as_Register(index));
              __ sh(as_Register(src), AT, disp);
           }
        } else {
           __ addu(AT, as_Register(base), as_Register(index));
           __ move(T9, disp);
           if( UseLoongsonISA ) {
              __ gsshx(as_Register(src), AT, T9, 0);
           } else {
              __ addu(AT, AT, T9); 
              __ sh(as_Register(src), AT, 0);
           }
        }    
     } else {
        if( Assembler::is_simm16(disp) ) { 
           __ sh(as_Register(src), as_Register(base), disp);
        } else {
           __ move(T9, disp);   
           if( UseLoongsonISA ) {
              __ gsshx(as_Register(src), as_Register(base), T9, 0);
           } else {
              __ addu(AT, as_Register(base), T9); 
              __ sh(as_Register(src), AT, 0);
           }
        }    
     }
  %}

  enc_class load_I_enc (mRegI dst, memory mem) %{
     MacroAssembler _masm(&cbuf);
     int  dst = $dst$$reg;
     int  base = $mem$$base;
     int  index = $mem$$index;
     int  scale = $mem$$scale;
     int  disp = $mem$$disp;

     guarantee(scale == 0, "scale is not zero !");

     if( index != 0 ) {
        if( Assembler::is_simm16(disp) ) { 
           if( UseLoongsonISA && Assembler::is_simm(disp, 8) ) {
              __ gslwx(as_Register(dst), as_Register(base), as_Register(index), disp);
           } else {
              __ addu(AT, as_Register(base), as_Register(index));
              __ lw(as_Register(dst), AT, disp);
           }
        } else {
           __ addu(AT, as_Register(base), as_Register(index));
           __ move(T9, disp);
           if( UseLoongsonISA ) {
              __ gslwx(as_Register(dst), AT, T9, 0);
           } else {
              __ addu(AT, AT, T9); 
              __ lw(as_Register(dst), AT, 0);
           }
        }    
     } else {
        if( Assembler::is_simm16(disp) ) { 
           __ lw(as_Register(dst), as_Register(base), disp);
        } else {
           __ move(T9, disp);   
           if( UseLoongsonISA ) {
              __ gslwx(as_Register(dst), as_Register(base), T9, 0);
           } else {
              __ addu(AT, as_Register(base), T9); 
              __ lw(as_Register(dst), AT, 0);
           }
        }    
     }
  %}

  enc_class store_I_reg_enc (memory mem, mRegI src) %{
     MacroAssembler _masm(&cbuf);
     int  src = $src$$reg;
     int  base = $mem$$base;
     int  index = $mem$$index;
     int  scale = $mem$$scale;
     int  disp = $mem$$disp;

     guarantee(scale == 0, "scale is not zero !");

     if( index != 0 ) {
        if( Assembler::is_simm16(disp) ) { 
           if( UseLoongsonISA && Assembler::is_simm(disp, 8) ) {
              __ gsswx(as_Register(src), as_Register(base), as_Register(index), disp);
           } else {
              __ addu(AT, as_Register(base), as_Register(index));
              __ sw(as_Register(src), AT, disp);
           }
        } else {
           __ addu(AT, as_Register(base), as_Register(index));
           __ move(T9, disp);
           if( UseLoongsonISA ) {
              __ gsswx(as_Register(src), AT, T9, 0);
           } else {
              __ addu(AT, AT, T9); 
              __ sw(as_Register(src), AT, 0);
           }
        }    
     } else {
        if( Assembler::is_simm16(disp) ) { 
           __ sw(as_Register(src), as_Register(base), disp);
        } else {
           __ move(T9, disp);   
           if( UseLoongsonISA ) {
              __ gsswx(as_Register(src), as_Register(base), T9, 0);
           } else {
              __ addu(AT, as_Register(base), T9); 
              __ sw(as_Register(src), AT, 0);
           }
        }    
     }
  %}

  enc_class store_I_immI_enc (memory mem, immI src) %{
     MacroAssembler _masm(&cbuf);
     int  base = $mem$$base;
     int  index = $mem$$index;
     int  scale = $mem$$scale;
     int  disp = $mem$$disp;
     int value = $src$$constant;

     guarantee(scale == 0, "scale is not zero !");

     if( index != 0 ) {
        __ daddu(AT, as_Register(base), as_Register(index));
        if( Assembler::is_simm16(disp) ) { 
           if (value == 0) {
              __ sw(R0, AT, disp);
           } else {
              __ move(T9, value);
              __ sw(T9, AT, disp);
           }
        } else {
           if (value == 0) {
              __ move(T9, disp);
              __ addu(AT, AT, T9); 
              __ sw(R0, AT, 0);
           } else {
              __ move(T9, disp);
              __ addu(AT, AT, T9); 
              __ move(T9, value);
              __ sw(T9, AT, 0);
           }
        }    
     } else {
        if( Assembler::is_simm16(disp) ) { 
           if (value == 0) {
              __ sw(R0, as_Register(base), disp);
           } else {
              __ move(AT, value);
              __ sw(AT, as_Register(base), disp);
           }
        } else {
           if (value == 0) {
              __ move(T9, disp);   
              __ addu(AT, as_Register(base), T9); 
              __ sw(R0, AT, 0);
           } else {
              __ move(T9, disp);   
              __ addu(AT, as_Register(base), T9); 
              __ move(T9, value);
              __ sw(T9, AT, 0);
           }
        }    
     }
  %}

  enc_class load_N_enc (mRegN dst, memory mem) %{
     MacroAssembler _masm(&cbuf);
     int  dst = $dst$$reg;
     int  base = $mem$$base;
     int  index = $mem$$index;
     int  scale = $mem$$scale;
     int  disp = $mem$$disp;
	 relocInfo::relocType disp_reloc = $mem->disp_reloc();
	 assert(disp_reloc == relocInfo::none, "cannot have disp");

     if( index != 0 ) {
        __ daddu(AT, as_Register(base), as_Register(index));
        if( Assembler::is_simm16(disp) ) { 
           __ lwu(as_Register(dst), AT, disp);
        } else {
           __ li(T9, disp);
           __ daddu(AT, AT, T9);
           __ lwu(as_Register(dst), AT, 0);
        }    
     } else {
        if( Assembler::is_simm16(disp) ) { 
           __ lwu(as_Register(dst), as_Register(base), disp);
        } else {
           __ li(T9, disp);   
           __ daddu(AT, as_Register(base), T9);
           __ lwu(as_Register(dst), AT, 0);
        }    
     }

  %}
  enc_class load_P_enc (mRegP dst, memory mem) %{
     MacroAssembler _masm(&cbuf);
     int  dst = $dst$$reg;
     int  base = $mem$$base;
     int  index = $mem$$index;
     int  scale = $mem$$scale;
     int  disp = $mem$$disp;
	 relocInfo::relocType disp_reloc = $mem->disp_reloc();
	 assert(disp_reloc == relocInfo::none, "cannot have disp");

     if( index != 0 ) {
        __ daddu(AT, as_Register(base), as_Register(index));
        if( Assembler::is_simm16(disp) ) { 
           __ ld(as_Register(dst), AT, disp);
        } else {
           __ li(T9, disp);
           __ daddu(AT, AT, T9);
           __ ld(as_Register(dst), AT, 0);
        }    
     } else {
        if( Assembler::is_simm16(disp) ) { 
           __ ld(as_Register(dst), as_Register(base), disp);
        } else {
           __ li(T9, disp);   
           __ daddu(AT, as_Register(base), T9);
           __ ld(as_Register(dst), AT, 0);
        }    
     }
//     if( disp_reloc != relocInfo::none) __ ld(as_Register(dst), as_Register(dst), 0);
  %}

  enc_class store_P_reg_enc (memory mem, mRegP src) %{
     MacroAssembler _masm(&cbuf);
     int  src = $src$$reg;
     int  base = $mem$$base;
     int  index = $mem$$index;
     int  scale = $mem$$scale;
     int  disp = $mem$$disp;

     guarantee(scale == 0, "scale is not zero !");

     if( index != 0 ) {
        __ daddu(AT, as_Register(base), as_Register(index));
        if( Assembler::is_simm16(disp) ) { 
           __ sd(as_Register(src), AT, disp);
        } else {
           __ move(T9, disp);
           __ daddu(AT, AT, T9); 
           __ sd(as_Register(src), AT, 0);
        }    
     } else {
        if( Assembler::is_simm16(disp) ) { 
           __ sd(as_Register(src), as_Register(base), disp);
        } else {
           __ move(T9, disp);   
           __ daddu(AT, as_Register(base), T9); 
           __ sd(as_Register(src), AT, 0);
        }    
     }
  %}

  enc_class store_N_reg_enc (memory mem, mRegN src) %{
     MacroAssembler _masm(&cbuf);
     int  src = $src$$reg;
     int  base = $mem$$base;
     int  index = $mem$$index;
     int  scale = $mem$$scale;
     int  disp = $mem$$disp;

     guarantee(scale == 0, "scale is not zero !");

     if( index != 0 ) {
        __ addu(AT, as_Register(base), as_Register(index));
        if( Assembler::is_simm16(disp) ) { 
           __ sw(as_Register(src), AT, disp);
        } else {
           __ move(T9, disp);
           __ addu(AT, AT, T9); 
           __ sw(as_Register(src), AT, 0);
        }    
     } else {
        if( Assembler::is_simm16(disp) ) { 
           __ sw(as_Register(src), as_Register(base), disp);
        } else {
           __ move(T9, disp);   
           __ addu(AT, as_Register(base), T9); 
           __ sw(as_Register(src), AT, 0);
        }    
     }
  %}

  enc_class store_P_immP_enc (memory mem, immP31 src) %{
     MacroAssembler _masm(&cbuf);
     int  base = $mem$$base;
     int  index = $mem$$index;
     int  scale = $mem$$scale;
     int  disp = $mem$$disp;
     long value = $src$$constant;

     guarantee(scale == 0, "scale is not zero !");

     if( index != 0 ) {
        __ daddu(AT, as_Register(base), as_Register(index));
        if( Assembler::is_simm16(disp) ) { 
           if (value == 0) {
              __ sd(R0, AT, disp);
           } else {
              __ move(T9, value);
              __ sd(T9, AT, disp);
           }
        } else {
           if (value == 0) {
              __ move(T9, disp);
              __ daddu(AT, AT, T9); 
              __ sd(R0, AT, 0);
           } else {
              __ move(T9, disp);
              __ daddu(AT, AT, T9); 
              __ move(T9, value);
              __ sd(T9, AT, 0);
           }
        }    
     } else {
        if( Assembler::is_simm16(disp) ) { 
           if (value == 0) {
              __ sd(R0, as_Register(base), disp);
           } else {
              __ move(AT, value);
              __ sd(AT, as_Register(base), disp);
           }
        } else {
           if (value == 0) {
              __ move(T9, disp);   
              __ daddu(AT, as_Register(base), T9); 
              __ sd(R0, AT, 0);
           } else {
              __ move(T9, disp);   
              __ daddu(AT, as_Register(base), T9); 
              __ move(T9, value);
              __ sd(T9, AT, 0);
           }
        }    
     }
  %}

/*
 * 1d4     storeImmN    [S0 + #16 (8-bit)], narrowoop: spec/benchmarks/_213_javac/Identifier:exact *   
 *                      # compressed ptr ! Field: spec/benchmarks/_213_javac/Identifier.value
 *  0x00000055648065d4: daddu at, s0, zero
 *  0x00000055648065d8: lui t9, 0x0       ;   {oop(a 'spec/benchmarks/_213_javac/Identifier')}
 *  0x00000055648065dc: ori t9, t9, 0xfffff610
 *  0x00000055648065e0: dsll t9, t9, 16
 *  0x00000055648065e4: ori t9, t9, 0xffffc628
 *  0x00000055648065e8: sw t9, 0x10(at)
 */
  enc_class storeImmN_enc (memory mem, immN src) %{
     MacroAssembler _masm(&cbuf);
     int  base = $mem$$base;
     int  index = $mem$$index;
     int  scale = $mem$$scale;
     int  disp = $mem$$disp;
     long * value = (long *)$src$$constant;

     if (value == NULL) {
         guarantee(Assembler::is_simm16(disp), "FIXME: disp is not simm16!");
         if (index == 0) {
             __ sw(R0, as_Register(base), disp);
         } else {
             __ daddu(AT, as_Register(base), as_Register(index));
             __ sw(R0, AT, disp);
         }

         return;
     }

     int oop_index = __ oop_recorder()->find_index((jobject)value);
     RelocationHolder rspec = oop_Relocation::spec(oop_index);

     guarantee(scale == 0, "FIXME: scale is not zero !");
     guarantee(value != 0, "FIXME: value is zero !");

    if (index != 0) {
	 __ daddu(AT, as_Register(base), as_Register(index));
	 if( Assembler::is_simm16(disp) ) { 
		 if(rspec.type() != relocInfo::none) {
			 __ relocate(rspec, Assembler::narrow_oop_operand);
			 __ li48(T9, oop_index);
		 } else {
			 __ move(T9, oop_index);
		 }
		 __ sw(T9, AT, disp);
	 } else {
		 __ move(T9, disp);
		 __ addu(AT, AT, T9); 

		 if(rspec.type() != relocInfo::none) {
			 __ relocate(rspec, Assembler::narrow_oop_operand);
			 __ li48(T9, oop_index);
		 } else {
			 __ move(T9, oop_index);
		 }
		 __ sw(T9, AT, 0);
	 }
     }
     else {
         if( Assembler::is_simm16(disp) ) { 
		 if($src->constant_reloc() != relocInfo::none) {
			 __ relocate(rspec, Assembler::narrow_oop_operand);
			 __ li48(T9, oop_index);
		 }
             else {
                 __ li48(T9, oop_index);
	     }     
	     __ sw(T9, as_Register(base), disp);
	 } else {
		 __ move(T9, disp);
		 __ daddu(AT, as_Register(base), T9);  

		 if($src->constant_reloc() != relocInfo::none){
			 __ relocate(rspec, Assembler::narrow_oop_operand);
			 __ li48(T9, oop_index);
		 } else {
			 __ li48(T9, oop_index);
		 }     
		 __ sw(T9, AT, 0);
         }     
     }
  %}

  enc_class storeImmNKlass_enc (memory mem, immNKlass src) %{
     MacroAssembler _masm(&cbuf);

     assert (UseCompressedOops, "should only be used for compressed headers");
     assert (__ oop_recorder() != NULL, "this assembler needs an OopRecorder");

     int  base = $mem$$base;
     int  index = $mem$$index;
     int  scale = $mem$$scale;
     int  disp = $mem$$disp;
     long value = $src$$constant;

     guarantee(scale == 0, "scale is not zero !");

	 int klass_index = __ oop_recorder()->find_index((Klass*)value);
	 RelocationHolder rspec = metadata_Relocation::spec(klass_index);
	 long narrowp = Klass::encode_klass((Klass*)value);

	 if(index!=0){
		 __ daddu(AT, as_Register(base), as_Register(index));
		 if( Assembler::is_simm16(disp) ) { 
			 if(rspec.type() != relocInfo::none){
				 __ relocate(rspec, Assembler::narrow_oop_operand);
				 __ li48(T9, narrowp);
			 }
			 else {
				 __ li48(T9, narrowp);
			 }
			 __ sw(T9, AT, disp);
		 } else {
			 __ move(T9, disp);
			 __ daddu(AT, AT, T9); 

			 if(rspec.type() != relocInfo::none){
				 __ relocate(rspec, Assembler::narrow_oop_operand);
				 __ li48(T9, narrowp);
			 }
			 else {
				 __ li48(T9, narrowp);
			 }

			 __ sw(T9, AT, 0);
		 }    
	 }
	 else {
		 if( Assembler::is_simm16(disp) ) { 
			 if(rspec.type() != relocInfo::none){
				 __ relocate(rspec, Assembler::narrow_oop_operand);
				 __ li48(T9, narrowp);
			 }
			 else {
				 __ li48(T9, narrowp);
			 }
			 __ sw(T9, as_Register(base), disp);
		 } else {
			 __ move(T9, disp);
			 __ daddu(AT, as_Register(base), T9); 

			 if(rspec.type() != relocInfo::none){
				 __ relocate(rspec, Assembler::narrow_oop_operand);
				 __ li48(T9, narrowp);
			 }
			 else {
				 __ li48(T9, narrowp);
			 }
			 __ sw(T9, AT, 0);
		 }    
	 }
  %}

  enc_class storeImmN0_enc(memory mem, ImmN0 src) %{
     MacroAssembler _masm(&cbuf);
     int  base = $mem$$base;
     int  index = $mem$$index;
     int  scale = $mem$$scale;
     int  disp = $mem$$disp;

     guarantee(scale == 0, "scale is not zero !");

	 if(index!=0){
		 __ daddu(AT, as_Register(base), as_Register(index));
		 if( Assembler::is_simm16(disp) ) { 
			 __ sw(S5_heapbase, AT, disp);
		 } else {
			 __ move(T9, disp);
			 __ daddu(AT, AT, T9); 
			 __ sw(S5_heapbase, AT, 0);
		 }   
	 } 
     else {
		 if( Assembler::is_simm16(disp) ) { 
			 __ sw(S5_heapbase, as_Register(base), disp);
		 } else {
			 __ move(T9, disp);
			 __ daddu(AT, as_Register(base), T9); 
			 __ sw(S5_heapbase, AT, 0);
		 }   
	 }
  %} 

  enc_class load_L_enc (mRegL dst, memory mem) %{
     MacroAssembler _masm(&cbuf);
     int  base = $mem$$base;
     int  index = $mem$$index;
     int  scale = $mem$$scale;
     int  disp = $mem$$disp;
     Register  dst_reg = as_Register($dst$$reg);

     guarantee(scale == 0, "scale is not zero !");

     /*********************2013/03/27**************************
      * Jin: $base may contain a null object.
      * Server JIT force the exception_offset to be the pos of 
      * the first instruction.
      * I insert such a 'null_check' at the beginning.
      *******************************************************/

     __ lw(AT, as_Register(base), 0);

     /*********************2012/10/04**************************
      * Error case found in SortTest
      * 337   b   java.util.Arrays::sort1 (401 bytes)
      * B73:
      *       d34     lw    T4.lo, [T4 + #16]   #@loadL-lo
      *               lw    T4.hi, [T4 + #16]+4 #@loadL-hi
      *
      * The original instructions generated here are :
      *       __ lw(dst_lo, as_Register(base), disp);
      *       __ lw(dst_hi, as_Register(base), disp + 4);
      *******************************************************/

     if( index != 0 ) {
        __ daddu(AT, as_Register(base), as_Register(index));
        if( Assembler::is_simm16(disp) ) { 
           __ ld(dst_reg, AT, disp);
        } else {
           __ move(T9, disp);
           __ daddu(AT, AT, T9); 
           __ ld(dst_reg, AT, 0);
        }    
     } else {
        if( Assembler::is_simm16(disp) ) { 
           __ move(AT, as_Register(base));
           __ ld(dst_reg, AT, disp);
        } else {
           __ move(T9, disp);   
           __ daddu(AT, as_Register(base), T9); 
           __ ld(dst_reg, AT, 0);
        }    
     }
  %}

  enc_class store_L_reg_enc (memory mem, mRegL src) %{
     MacroAssembler _masm(&cbuf);
     int  base = $mem$$base;
     int  index = $mem$$index;
     int  scale = $mem$$scale;
     int  disp = $mem$$disp;
     Register  src_reg = as_Register($src$$reg);

     guarantee(scale == 0, "scale is not zero !");

     if( index != 0 ) {
        __ daddu(AT, as_Register(base), as_Register(index));
        if( Assembler::is_simm16(disp) ) { 
           __ sd(src_reg, AT, disp);
        } else {
           __ move(T9, disp);
           __ daddu(AT, AT, T9); 
           __ sd(src_reg, AT, 0);
        }    
     } else {
        if( Assembler::is_simm16(disp) ) { 
           __ move(AT, as_Register(base));
           __ sd(src_reg, AT, disp);
        } else {
           __ move(T9, disp);   
           __ daddu(AT, as_Register(base), T9); 
           __ sd(src_reg, AT, 0);
        }    
     }
  %}

  enc_class store_L_immL0_enc (memory mem, immL0 src) %{
     MacroAssembler _masm(&cbuf);
     int  base = $mem$$base;
     int  index = $mem$$index;
     int  scale = $mem$$scale;
     int  disp = $mem$$disp;

     guarantee(scale == 0, "scale is not zero !");

     if( index != 0 ) {
        __ daddu(AT, as_Register(base), as_Register(index));
        if( Assembler::is_simm16(disp) ) { 
           __ sd(R0, AT, disp);
        } else {
           __ move(T9, disp);
           __ addu(AT, AT, T9); 
           __ sd(R0, AT, 0);
        }    
     } else {
        if( Assembler::is_simm16(disp) ) { 
           __ move(AT, as_Register(base));
           __ sd(R0, AT, disp);
        } else {
           __ move(T9, disp);   
           __ addu(AT, as_Register(base), T9); 
           __ sd(R0, AT, 0);
        }    
     }
  %}

  enc_class store_L_immL_enc (memory mem, immL src) %{
     MacroAssembler _masm(&cbuf);
     int  base = $mem$$base;
     int  index = $mem$$index;
     int  scale = $mem$$scale;
     int  disp = $mem$$disp;
     long  imm = $src$$constant; 

     guarantee(scale == 0, "scale is not zero !");

     if( index != 0 ) {
        __ daddu(AT, as_Register(base), as_Register(index));
        if( Assembler::is_simm16(disp) ) { 
           __ li(T9, imm);
           __ sd(T9, AT, disp);
        } else {
           __ move(T9, disp);
           __ addu(AT, AT, T9); 
           __ li(T9, imm);
           __ sd(T9, AT, 0);
        }    
     } else {
        if( Assembler::is_simm16(disp) ) { 
           __ move(AT, as_Register(base));
           __ li(T9, imm);
           __ sd(T9, AT, disp);
        } else {
           __ move(T9, disp);   
           __ addu(AT, as_Register(base), T9); 
           __ li(T9, imm);
           __ sd(T9, AT, 0);
        }    
     }
  %}

  enc_class load_F_enc (regF dst, memory mem) %{
     MacroAssembler _masm(&cbuf);
     int  base = $mem$$base;
     int  index = $mem$$index;
     int  scale = $mem$$scale;
     int  disp = $mem$$disp;
     FloatRegister dst = $dst$$FloatRegister;

     guarantee(scale == 0, "scale is not zero !");

     if( index != 0 ) {
        if( Assembler::is_simm16(disp) ) { 
           if( UseLoongsonISA && Assembler::is_simm(disp, 8) ) {
              __ gslwxc1(dst, as_Register(base), as_Register(index), disp);
           } else {
              __ daddu(AT, as_Register(base), as_Register(index));
              __ lwc1(dst, AT, disp);
           }
        } else {
           __ daddu(AT, as_Register(base), as_Register(index));
           __ move(T9, disp);
           if( UseLoongsonISA ) {
              __ gslwxc1(dst, AT, T9, 0);
           } else {
              __ daddu(AT, AT, T9); 
              __ lwc1(dst, AT, 0);
           }
        }    
     } else {
        if( Assembler::is_simm16(disp) ) { 
           __ lwc1(dst, as_Register(base), disp);
        } else {
           __ move(T9, disp);   
           if( UseLoongsonISA ) {
              __ gslwxc1(dst, as_Register(base), T9, 0);
           } else {
              __ daddu(AT, as_Register(base), T9); 
              __ lwc1(dst, AT, 0);
           }
        }    
     }
  %}

  enc_class store_F_reg_enc (memory mem, regF src) %{
     MacroAssembler _masm(&cbuf);
     int  base = $mem$$base;
     int  index = $mem$$index;
     int  scale = $mem$$scale;
     int  disp = $mem$$disp;
     FloatRegister src = $src$$FloatRegister;

     guarantee(scale == 0, "scale is not zero !");

     if( index != 0 ) {
        if( Assembler::is_simm16(disp) ) { 
           if( UseLoongsonISA && Assembler::is_simm(disp, 8) ) {
              __ gsswxc1(src, as_Register(base), as_Register(index), disp);
           } else {
              __ daddu(AT, as_Register(base), as_Register(index));
              __ swc1(src, AT, disp);
           }
        } else {
           __ daddu(AT, as_Register(base), as_Register(index));
           __ move(T9, disp);
           if( UseLoongsonISA ) {
              __ gsswxc1(src, AT, T9, 0);
           } else {
              __ daddu(AT, AT, T9); 
              __ swc1(src, AT, 0);
           }
        }    
     } else {
        if( Assembler::is_simm16(disp) ) { 
           __ swc1(src, as_Register(base), disp);
        } else {
           __ move(T9, disp);   
           if( UseLoongsonISA ) {
              __ gslwxc1(src, as_Register(base), T9, 0);
           } else {
              __ daddu(AT, as_Register(base), T9); 
              __ swc1(src, AT, 0);
           }
        }    
     }
  %}

  enc_class load_D_enc (regD dst, memory mem) %{
     MacroAssembler _masm(&cbuf);
     int  base = $mem$$base;
     int  index = $mem$$index;
     int  scale = $mem$$scale;
     int  disp = $mem$$disp;
     FloatRegister dst_reg = as_FloatRegister($dst$$reg);

     guarantee(scale == 0, "scale is not zero !");

     if( index != 0 ) {
        if( Assembler::is_simm16(disp) ) { 
           if( UseLoongsonISA && Assembler::is_simm(disp, 8) ) {
              __ gsldxc1(dst_reg, as_Register(base), as_Register(index), disp);
           } else {
              __ daddu(AT, as_Register(base), as_Register(index));
              __ ldc1(dst_reg, AT, disp);
           }
        } else {
           __ daddu(AT, as_Register(base), as_Register(index));
           __ move(T9, disp);
           if( UseLoongsonISA ) {
              __ gsldxc1(dst_reg, AT, T9, 0);
           } else {
              __ addu(AT, AT, T9); 
              __ ldc1(dst_reg, AT, 0);
           }
        }    
     } else {
        if( Assembler::is_simm16(disp) ) { 
           __ ldc1(dst_reg, as_Register(base), disp);
        } else {
           __ move(T9, disp);   
           if( UseLoongsonISA ) {
              __ gsldxc1(dst_reg, as_Register(base), T9, 0);
           } else {
              __ addu(AT, as_Register(base), T9); 
              __ ldc1(dst_reg, AT, 0);
           }
        }    
     }
  %}

  enc_class store_D_reg_enc (memory mem, regD src) %{
     MacroAssembler _masm(&cbuf);
     int  base = $mem$$base;
     int  index = $mem$$index;
     int  scale = $mem$$scale;
     int  disp = $mem$$disp;
     FloatRegister src_reg = as_FloatRegister($src$$reg);

     guarantee(scale == 0, "scale is not zero !");

     if( index != 0 ) {
        if( Assembler::is_simm16(disp) ) { 
           if( UseLoongsonISA && Assembler::is_simm(disp, 8) ) {
              __ gssdxc1(src_reg, as_Register(base), as_Register(index), disp);
           } else {
              __ daddu(AT, as_Register(base), as_Register(index));
              __ sdc1(src_reg, AT, disp);
           }
        } else {
           __ daddu(AT, as_Register(base), as_Register(index));
           __ move(T9, disp);
           if( UseLoongsonISA ) {
              __ gssdxc1(src_reg, AT, T9, 0);
           } else {
              __ addu(AT, AT, T9); 
              __ sdc1(src_reg, AT, 0);
           }
        }    
     } else {
        if( Assembler::is_simm16(disp) ) { 
           __ sdc1(src_reg, as_Register(base), disp);
        } else {
           __ move(T9, disp);   
           if( UseLoongsonISA ) {
              __ gssdxc1(src_reg, as_Register(base), T9, 0);
           } else {
              __ addu(AT, as_Register(base), T9); 
              __ sdc1(src_reg, AT, 0);
           }
        }    
     }
  %}

  enc_class Java_To_Runtime (method meth) %{    // CALL Java_To_Runtime, Java_To_Runtime_Leaf
      MacroAssembler _masm(&cbuf);
    // This is the instruction starting address for relocation info.
    __ block_comment("Java_To_Runtime");
    cbuf.set_insts_mark();
    __ relocate(relocInfo::runtime_call_type);

	__ li48(T9, (long)$meth$$method);
    __ jalr(T9);
    __ nop();
    %}

  enc_class Java_Static_Call (method meth) %{    // JAVA STATIC CALL
    // CALL to fixup routine.  Fixup routine uses ScopeDesc info to determine
    // who we intended to call.
    MacroAssembler _masm(&cbuf);
    cbuf.set_insts_mark();

    if ( !_method ) {
      __ relocate(relocInfo::runtime_call_type);
      //emit_d32_reloc(cbuf, ($meth$$method - (int)(cbuf.code_end()) - 4),
      //               runtime_call_Relocation::spec(), RELOC_IMM32 );
    } else if(_optimized_virtual) {
      __ relocate(relocInfo::opt_virtual_call_type);
      //emit_d32_reloc(cbuf, ($meth$$method - (int)(cbuf.code_end()) - 4),
      //               opt_virtual_call_Relocation::spec(), RELOC_IMM32 );
    } else {
      __ relocate(relocInfo::static_call_type);
      //emit_d32_reloc(cbuf, ($meth$$method - (int)(cbuf.code_end()) - 4),
      //               static_call_Relocation::spec(), RELOC_IMM32 );
    }

    __ li(T9, $meth$$method);
    __ jalr(T9);
    __ nop();
    if( _method ) {  // Emit stub for static call
      emit_java_to_interp(cbuf);
    }
  %}


/*
 * [Ref: LIR_Assembler::ic_call() ]
 */
enc_class Java_Dynamic_Call (method meth) %{    // JAVA DYNAMIC CALL
    MacroAssembler _masm(&cbuf);
	__ block_comment("Java_Dynamic_Call");
	__ ic_call((address)$meth$$method);
  %}

  enc_class call_epilog %{
/*
    if( VerifyStackAtCalls ) {
      // Check that stack depth is unchanged: find majik cookie on stack
      int framesize = ra_->reg2offset_unchecked(OptoReg::add(ra_->_matcher._old_SP,-3*VMRegImpl::slots_per_word));
      if(framesize >= 128) {
        emit_opcode(cbuf, 0x81); // cmp [esp+0],0xbadb1ood
        emit_d8(cbuf,0xBC);
        emit_d8(cbuf,0x24);
        emit_d32(cbuf,framesize); // Find majik cookie from ESP
        emit_d32(cbuf, 0xbadb100d);
      }
      else {
        emit_opcode(cbuf, 0x81); // cmp [esp+0],0xbadb1ood
        emit_d8(cbuf,0x7C);
        emit_d8(cbuf,0x24);
        emit_d8(cbuf,framesize); // Find majik cookie from ESP
        emit_d32(cbuf, 0xbadb100d);
      }
      // jmp EQ around INT3
      // QQQ TODO
      const int jump_around = 5; // size of call to breakpoint, 1 for CC
      emit_opcode(cbuf,0x74);
      emit_d8(cbuf, jump_around);
      // QQQ temporary
      emit_break(cbuf);
      // Die if stack mismatch
      // emit_opcode(cbuf,0xCC);
    }
*/
 %}
 


  enc_class Set_Flags_After_Fast_Lock_Unlock(FlagsReg cr) %{
    Register flags = $cr$$Register;
    Label  L;

    MacroAssembler _masm(&cbuf);

    __ addu(flags, R0, R0);    
    __ beq(AT, R0, L);
    __ delayed()->nop();
    __ move(flags, 0xFFFFFFFF);
    __ bind(L);
  %}

  enc_class enc_PartialSubtypeCheck(mRegP result, mRegP sub, mRegP super) %{
    Register result = $result$$Register;
    Register sub    = $sub$$Register;
    Register super  = $super$$Register;
    Register length = T8;
    Register tmp    = T9;
    Label miss;

    /* 2012/9/28 Jin: result may be the same as sub
     *    47c   B40: #    B21 B41 <- B20  Freq: 0.155379
     *    47c     partialSubtypeCheck result=S1, sub=S1, super=S3, length=S0
     *    4bc     mov   S2, NULL #@loadConP
     *    4c0     beq   S1, S2, B21 #@branchConP  P=0.999999 C=-1.000000
    */
    MacroAssembler _masm(&cbuf);
    Label done;
    __ check_klass_subtype_slow_path(sub, super, length, tmp,
                                     NULL, &miss,
                                     /*set_cond_codes:*/ true);
    /* 2013/7/22 Jin: Refer to X86_64's RDI */
    __ move(result, 0);
    __ b(done);
    __ nop();

    __ bind(miss);
    __ move(result, 1);
    __ bind(done);
  %}

%}


//---------MIPS FRAME--------------------------------------------------------------
// Definition of frame structure and management information.
//
//  S T A C K   L A Y O U T    Allocators stack-slot number
//                             |   (to get allocators register number
//  G  Owned by    |        |  v    add SharedInfo::stack0)
//  r   CALLER     |        |
//  o     |        +--------+      pad to even-align allocators stack-slot 
//  w     V        |  pad0  |        numbers; owned by CALLER
//  t   -----------+--------+----> Matcher::_in_arg_limit, unaligned
//  h     ^        |   in   |  5   
//        |        |  args  |  4   Holes in incoming args owned by SELF
//  |     |    old |        |  3
//  |     |     SP-+--------+----> Matcher::_old_SP, even aligned
//  v     |        |  ret   |  3   return address
//     Owned by    +--------+
//      Self       |  pad2  |  2   pad to align old SP
//        |        +--------+  1
//        |        | locks  |  0
//        |        +--------+----> SharedInfo::stack0, even aligned  
//        |        |  pad1  | 11   pad to align new SP
//        |        +--------+
//        |        |        | 10
//        |        | spills |  9   spills
//        V        |        |  8   (pad0 slot for callee)
//      -----------+--------+----> Matcher::_out_arg_limit, unaligned
//        ^        |  out   |  7   
//        |        |  args  |  6   Holes in outgoing args owned by CALLEE
//   Owned by  new |				|
//		Callee    SP-+--------+----> Matcher::_new_SP, even aligned
//           			 |        |
//
// Note 1: Only region 8-11 is determined by the allocator.  Region 0-5 is 
//         known from SELF's arguments and the Java calling convention.
//         Region 6-7 is determined per call site.
// Note 2: If the calling convention leaves holes in the incoming argument 
//         area, those holes are owned by SELF.  Holes in the outgoing area
//         are owned by the CALLEE.  Holes should not be nessecary in the
//         incoming area, as the Java calling convention is completely under
//         the control of the AD file.  Doubles can be sorted and packed to
//         avoid holes.  Holes in the outgoing arguments may be nessecary for
//         varargs C calling conventions.
// Note 3: Region 0-3 is even aligned, with pad2 as needed.  Region 3-5 is 
//         even aligned with pad0 as needed.
//         Region 6 is even aligned.  Region 6-7 is NOT even aligned;
//         region 6-11 is even aligned; it may be padded out more so that
//         the region from SP to FP meets the minimum stack alignment.
// Note 4: For I2C adapters, the incoming FP may not meet the minimum stack
//         alignment.  Region 11, pad1, may be dynamically extended so that
//         SP meets the minimum alignment.


frame %{

  stack_direction(TOWARDS_LOW);

  // These two registers define part of the calling convention 
  // between compiled code and the interpreter.
	// SEE StartI2CNode::calling_convention & StartC2INode::calling_convention & StartOSRNode::calling_convention 
	// for more information. by yjl 3/16/2006

  inline_cache_reg(T1);                // Inline Cache Register
  interpreter_method_oop_reg(S3);      // Method Oop Register when calling interpreter
 /*
  inline_cache_reg(T1);          // Inline Cache Register or methodOop for I2C
  interpreter_arg_ptr_reg(A0);         // Argument pointer for I2C adapters
*/

  // Optional: name the operand used by cisc-spilling to access [stack_pointer + offset]
  cisc_spilling_operand_name(indOffset32);  

  // Number of stack slots consumed by locking an object
	// generate Compile::sync_stack_slots
#ifdef _LP64
  sync_stack_slots(2);
#else
  sync_stack_slots(1);
#endif

  frame_pointer(SP);

  // Interpreter stores its frame pointer in a register which is 
  // stored to the stack by I2CAdaptors.
  // I2CAdaptors convert from interpreted java to compiled java.

  interpreter_frame_pointer(FP);

	// generate Matcher::stack_alignment
  stack_alignment(StackAlignmentInBytes);  //wordSize = sizeof(char*);            

  // Number of stack slots between incoming argument block and the start of 
  // a new frame.  The PROLOG must add this many slots to the stack.  The
  // EPILOG must remove this many slots.  Intel needs one slot for
  // return address.
	// generate Matcher::in_preserve_stack_slots
  //in_preserve_stack_slots(VerifyStackAtCalls + 2);  //Now VerifyStackAtCalls is defined as false ! Leave one stack slot for ra and fp
  in_preserve_stack_slots(4);  //Now VerifyStackAtCalls is defined as false ! Leave two stack slots for ra and fp

  // Number of outgoing stack slots killed above the out_preserve_stack_slots
  // for calls to C.  Supports the var-args backing area for register parms.
  varargs_C_out_slots_killed(0);

  // The after-PROLOG location of the return address.  Location of
  // return address specifies a type (REG or STACK) and a number
  // representing the register number (i.e. - use a register name) or
  // stack slot.
  // Ret Addr is on stack in slot 0 if no locks or verification or alignment.
  // Otherwise, it is above the locks and verification slot and alignment word
  //return_addr(STACK -1+ round_to(1+VerifyStackAtCalls+Compile::current()->sync()*Compile::current()->sync_stack_slots(),WordsPerLong));
  return_addr(REG RA);

  // Body of function which returns an integer array locating
  // arguments either in registers or in stack slots.  Passed an array
  // of ideal registers called "sig" and a "length" count.  Stack-slot
  // offsets are based on outgoing arguments, i.e. a CALLER setting up
  // arguments for a CALLEE.  Incoming stack arguments are
  // automatically biased by the preserve_stack_slots field above.
	

	// will generated to Matcher::calling_convention(OptoRegPair *sig, uint length, bool is_outgoing)
	// StartNode::calling_convention call this. by yjl 3/16/2006
  calling_convention %{           
    SharedRuntime::java_calling_convention(sig_bt, regs, length, false);
  %}




  // Body of function which returns an integer array locating
  // arguments either in registers or in stack slots.  Passed an array
  // of ideal registers called "sig" and a "length" count.  Stack-slot
  // offsets are based on outgoing arguments, i.e. a CALLER setting up
  // arguments for a CALLEE.  Incoming stack arguments are
  // automatically biased by the preserve_stack_slots field above.


	// SEE CallRuntimeNode::calling_convention for more information. by yjl 3/16/2006
  c_calling_convention %{          
   (void) SharedRuntime::c_calling_convention(sig_bt, regs, /*regs2=*/NULL, length);
  %}


  // Location of C & interpreter return values
	// register(s) contain(s) return value for Op_StartI2C and Op_StartOSR. 
	// SEE Matcher::match. by yjl 3/16/2006
  c_return_value %{
    assert( ideal_reg >= Op_RegI && ideal_reg <= Op_RegL, "only return normal values" );
                               /* -- , -- , Op_RegN, Op_RegI, Op_RegP, Op_RegF, Op_RegD, Op_RegL */
    static int lo[Op_RegL+1] = { 0, 0, V0_num,       V0_num,       V0_num,       F0_num,       F0_num,    V0_num };
    static int hi[Op_RegL+1] = { 0, 0, OptoReg::Bad, OptoReg::Bad, V0_H_num,     OptoReg::Bad, F0_H_num,  V0_H_num };
    return OptoRegPair(hi[ideal_reg],lo[ideal_reg]);
  %}

  // Location of return values
	// register(s) contain(s) return value for Op_StartC2I and Op_Start. 
	// SEE Matcher::match. by yjl 3/16/2006

  return_value %{
    assert( ideal_reg >= Op_RegI && ideal_reg <= Op_RegL, "only return normal values" );
                               /* -- , -- , Op_RegN, Op_RegI, Op_RegP, Op_RegF, Op_RegD, Op_RegL */
    static int lo[Op_RegL+1] = { 0, 0, V0_num,       V0_num,       V0_num,       F0_num,       F0_num,     V0_num };
    static int hi[Op_RegL+1] = { 0, 0, OptoReg::Bad, OptoReg::Bad, V0_H_num,     OptoReg::Bad, F0_H_num,   V0_H_num};
    return OptoRegPair(hi[ideal_reg],lo[ideal_reg]);
  %}

%}

//----------ATTRIBUTES---------------------------------------------------------
//----------Operand Attributes-------------------------------------------------
op_attrib op_cost(0);        // Required cost attribute

//----------Instruction Attributes---------------------------------------------
ins_attrib ins_cost(100);       // Required cost attribute
ins_attrib ins_size(32);         // Required size attribute (in bits)
ins_attrib ins_pc_relative(0);  // Required PC Relative flag
ins_attrib ins_short_branch(0); // Required flag: is this instruction a
                                // non-matching short branch variant of some
                                                            // long branch?
ins_attrib ins_alignment(4);    // Required alignment attribute (must be a power of 2)
                                // specifies the alignment that some part of the instruction (not
                                // necessarily the start) requires.  If > 1, a compute_padding()
                                // function must be provided for the instruction

//----------OPERANDS-----------------------------------------------------------
// Operand definitions must precede instruction definitions for correct parsing
// in the ADLC because operands constitute user defined types which are used in
// instruction definitions.


// Flags register, used as output of compare instructions
operand FlagsReg() %{
  constraint(ALLOC_IN_RC(mips_flags));
  match(RegFlags);

  format %{ "EFLAGS" %}
  interface(REG_INTER);
%}

//----------Simple Operands----------------------------------------------------
//TODO: Should we need to define some more special immediate number ?
// Immediate Operands
// Integer Immediate
operand immI() %{
  match(ConI);
  //TODO: should not match immI8 here LEE
  match(immI8);

  op_cost(20);
  format %{ %}
  interface(CONST_INTER);
%}

// Long Immediate 8-bit
operand immL8()
%{
  predicate(-0x80L <= n->get_long() && n->get_long() < 0x80L);
  match(ConL);

  op_cost(5);
  format %{ %}
  interface(CONST_INTER);
%}

// Constant for test vs zero
operand immI0() %{
  predicate(n->get_int() == 0);
  match(ConI);

  op_cost(0);
  format %{ %}
  interface(CONST_INTER);
%}

// Constant for increment
operand immI1() %{
  predicate(n->get_int() == 1);
  match(ConI);

  op_cost(0);
  format %{ %}
  interface(CONST_INTER);
%}

// Constant for decrement
operand immI_M1() %{
  predicate(n->get_int() == -1);
  match(ConI);

  op_cost(0);
  format %{ %}
  interface(CONST_INTER);
%}

// Valid scale values for addressing modes
operand immI2() %{
  predicate(0 <= n->get_int() && (n->get_int() <= 3));
  match(ConI);

  format %{ %}
  interface(CONST_INTER);
%}

operand immI8() %{
  predicate((-128 <= n->get_int()) && (n->get_int() <= 127));
  match(ConI);

  op_cost(5);
  format %{ %}
  interface(CONST_INTER);
%}

operand immI16() %{
  predicate((-32768 <= n->get_int()) && (n->get_int() <= 32767));
  match(ConI);

  op_cost(10);
  format %{ %}
  interface(CONST_INTER);
%}

// Constant for long shifts
operand immI_32() %{
  predicate( n->get_int() == 32 );
  match(ConI);

  op_cost(0);
  format %{ %}
  interface(CONST_INTER);
%}

operand immI_1_31() %{
  predicate( n->get_int() >= 1 && n->get_int() <= 31 );
  match(ConI);

  op_cost(0);
  format %{ %}
  interface(CONST_INTER);
%}

operand immI_32_63() %{
  predicate( n->get_int() >= 32 && n->get_int() <= 63 );
  match(ConI);
  op_cost(0);

  format %{ %}
  interface(CONST_INTER);
%}

operand immI16_sub() %{
  predicate((-32767 <= n->get_int()) && (n->get_int() <= 32767));
  match(ConI);

  op_cost(10);
  format %{ %}
  interface(CONST_INTER);
%}

operand immI_0_65535() %{
  predicate( n->get_int() >= 0 && n->get_int() <= 65535 );
  match(ConI);
  op_cost(0);

  format %{ %}
  interface(CONST_INTER);
%}

operand immI_1() %{
  predicate( n->get_int() == 1 );
  match(ConI);

  op_cost(0);
  format %{ %}
  interface(CONST_INTER);
%}

operand immI_2() %{
  predicate( n->get_int() == 2 );
  match(ConI);

  op_cost(0);
  format %{ %}
  interface(CONST_INTER);
%}

operand immI_3() %{
  predicate( n->get_int() == 3 );
  match(ConI);

  op_cost(0);
  format %{ %}
  interface(CONST_INTER);
%}

// Immediates for special shifts (sign extend)

// Constants for increment
operand immI_16() %{
  predicate( n->get_int() == 16 );
  match(ConI);

  format %{ %}
  interface(CONST_INTER);
%}

operand immI_24() %{
  predicate( n->get_int() == 24 );
  match(ConI);

  format %{ %}
  interface(CONST_INTER);
%}

// Constant for byte-wide masking
operand immI_255() %{
  predicate( n->get_int() == 255 );
  match(ConI);

  format %{ %}
  interface(CONST_INTER);
%}

// Pointer Immediate
operand immP() %{
  match(ConP);

  op_cost(10);
  format %{ %}
  interface(CONST_INTER);
%}

operand immP31()
%{
  predicate(n->as_Type()->type()->reloc() == relocInfo::none
            && (n->get_ptr() >> 31) == 0);
  match(ConP);

  op_cost(5);
  format %{ %} 
  interface(CONST_INTER);
%}

// NULL Pointer Immediate
operand immP0() %{
  predicate( n->get_ptr() == 0 );
  match(ConP);
  op_cost(0);

  format %{ %}
  interface(CONST_INTER);
%}

// Pointer Immediate
operand immN() %{
  match(ConN);

  op_cost(10);
  format %{ %}
  interface(CONST_INTER);
%}

operand immNKlass() %{
  match(ConNKlass);

  op_cost(10);
  format %{ %}
  interface(CONST_INTER);
%}

// NULL Pointer Immediate
operand immN0() %{
  predicate(n->get_narrowcon() == 0);
  match(ConN);

  op_cost(5);
  format %{ %}
  interface(CONST_INTER);
%}

// Long Immediate
operand immL() %{
  match(ConL);

  op_cost(20);
  format %{ %}
  interface(CONST_INTER);
%}

// Long Immediate zero
operand immL0() %{
  predicate( n->get_long() == 0L );
  match(ConL);
  op_cost(0);

  format %{ %}
  interface(CONST_INTER);
%}

// Long Immediate zero
operand immL_M1() %{
  predicate( n->get_long() == -1L );
  match(ConL);
  op_cost(0);

  format %{ %}
  interface(CONST_INTER);
%}

// Long immediate from 0 to 127.
// Used for a shorter form of long mul by 10.
operand immL_127() %{
  predicate((0 <= n->get_long()) && (n->get_long() <= 127));
  match(ConL);
  op_cost(0);

  format %{ %}
  interface(CONST_INTER);
%}


// Long Immediate: low 32-bit mask
operand immL_32bits() %{
  predicate(n->get_long() == 0xFFFFFFFFL);
  match(ConL);
  op_cost(20);

  format %{ %}
  interface(CONST_INTER);
%}

// Long Immediate 32-bit signed
operand immL32()
%{
  predicate(n->get_long() == (int) (n->get_long()));
  match(ConL);

  op_cost(15);
  format %{ %}
  interface(CONST_INTER);
%}


//single-precision floating-point zero
operand immF0() %{
  predicate(jint_cast(n->getf()) == 0);
  match(ConF);

  op_cost(5);
  format %{ %}
  interface(CONST_INTER);
%}

//single-precision floating-point immediate
operand immF() %{
  match(ConF);

  op_cost(20);
  format %{ %}
  interface(CONST_INTER);
%}

//double-precision floating-point zero 
operand immD0() %{
  predicate(jlong_cast(n->getd()) == 0);
  match(ConD);

  op_cost(5);
  format %{ %}
  interface(CONST_INTER);
%}

//double-precision floating-point immediate
operand immD() %{
  match(ConD);

  op_cost(20);
  format %{ %}
  interface(CONST_INTER);
%}

// Register Operands
// Integer Register
operand mRegI() %{
  constraint(ALLOC_IN_RC(int_reg));
  match(RegI);
  match(s_RegI);
  match(t_RegI);

  format %{ %}
  interface(REG_INTER);
%}


// Subset of Integer Registers
operand s_RegI(mRegI reg) %{
  constraint(ALLOC_IN_RC(s_reg));
  match(reg);
  match(mS0RegI);
  match(mS1RegI);
  match(mS2RegI);
  match(mS3RegI);
  match(mS4RegI);

  format %{ %}
  interface(REG_INTER);
%}

operand mS0RegI(s_RegI reg) %{
  constraint(ALLOC_IN_RC(s0_reg));
  match(reg);
  match(mRegI);

  format %{ "S0" %}
  interface(REG_INTER);
%}

operand mS1RegI(s_RegI reg) %{
  constraint(ALLOC_IN_RC(s1_reg));
  match(reg);
  match(mRegI);

  format %{ "S1" %}
  interface(REG_INTER);
%}

operand mS2RegI(s_RegI reg) %{
  constraint(ALLOC_IN_RC(s2_reg));
  match(reg);
  match(mRegI);

  format %{ "S0" %}
  interface(REG_INTER);
%}

operand mS3RegI(s_RegI reg) %{
  constraint(ALLOC_IN_RC(s3_reg));
  match(reg);
  match(mRegI);

  format %{ "S3" %}
  interface(REG_INTER);
%}

operand mS4RegI(s_RegI reg) %{
  constraint(ALLOC_IN_RC(s4_reg));
  match(reg);
  match(mRegI);

  format %{ "S4" %}
  interface(REG_INTER);
%}

// Subset of Integer Registers
operand t_RegI(mRegI reg) %{
  constraint(ALLOC_IN_RC(t_reg));
  match(reg);
  match(mT0RegI);
  match(mT1RegI);
  match(mT2RegI);
  match(mT3RegI);

  format %{ %}
  interface(REG_INTER);
%}

operand mT0RegI(t_RegI reg) %{
  constraint(ALLOC_IN_RC(t0_reg));
  match(reg);
  match(mRegI);

  format %{ "T0" %}
  interface(REG_INTER);
%}

operand mT1RegI(t_RegI reg) %{
  constraint(ALLOC_IN_RC(t1_reg));
  match(reg);
  match(mRegI);

  format %{ "T1" %}
  interface(REG_INTER);
%}

operand mT2RegI(t_RegI reg) %{
  constraint(ALLOC_IN_RC(t2_reg));
  match(reg);
  match(mRegI);

  format %{ "T2" %}
  interface(REG_INTER);
%}

operand mT3RegI(t_RegI reg) %{
  constraint(ALLOC_IN_RC(t3_reg));
  match(reg);
  match(mRegI);

  format %{ "T3" %}
  interface(REG_INTER);
%}

operand mRegN() %{
  constraint(ALLOC_IN_RC(int_reg));
  match(RegN);

  match(t0_RegN);
  match(t1_RegN);
  match(t2_RegN);
  match(t3_RegN);

  match(a3_RegN);
  format %{ %}
  interface(REG_INTER);
%}

operand t0_RegN() %{
  constraint(ALLOC_IN_RC(t0_reg));
  match(RegN);
  match(mRegN);

  format %{ %}
  interface(REG_INTER);
%}

operand t1_RegN() %{
  constraint(ALLOC_IN_RC(t1_reg));
  match(RegN);
  match(mRegN);

  format %{ %}
  interface(REG_INTER);
%}

operand t2_RegN() %{
  constraint(ALLOC_IN_RC(t2_reg));
  match(RegN);
  match(mRegN);

  format %{ %}
  interface(REG_INTER);
%}

operand t3_RegN() %{
  constraint(ALLOC_IN_RC(t3_reg));
  match(RegN);
  match(mRegN);

  format %{ %}
  interface(REG_INTER);
%}

operand a3_RegN() %{
  constraint(ALLOC_IN_RC(a3_reg));
  match(RegN);
  match(mRegN);

  format %{ %}
  interface(REG_INTER);
%}
// Pointer Register
operand mRegP() %{
  constraint(ALLOC_IN_RC(p_reg));
  match(RegP);
  
  match(t0_RegP);
  match(t1_RegP);
  match(t2_RegP);
  match(t3_RegP);
  match(a3_RegP);
  match(a4_RegP);
  match(a5_RegP);
  match(a6_RegP);
  match(a7_RegP);

  match(a0_RegP);

  match(s0_RegP);
  match(s1_RegP);
  match(s2_RegP);
  match(s3_RegP);
  match(s4_RegP);
  //match(s5_RegP);
//  match(s7_RegP);

  //match(mSPRegP);
  //match(mFPRegP);

  format %{  %}
  interface(REG_INTER);
%} 

operand a0_RegP()
%{
  constraint(ALLOC_IN_RC(a0_long_reg));
  match(RegP);
  match(mRegP);

  format %{ %}
  interface(REG_INTER);
%}

operand s0_RegP()
%{
  constraint(ALLOC_IN_RC(s0_long_reg));
  match(RegP);
  match(mRegP);

  format %{ %}
  interface(REG_INTER);
%}

operand s1_RegP()
%{
  constraint(ALLOC_IN_RC(s1_long_reg));
  match(RegP);
  match(mRegP);

  format %{ %}
  interface(REG_INTER);
%}

operand s2_RegP()
%{
  constraint(ALLOC_IN_RC(s2_long_reg));
  match(RegP);
  match(mRegP);

  format %{ %}
  interface(REG_INTER);
%}

operand s3_RegP()
%{
  constraint(ALLOC_IN_RC(s3_long_reg));
  match(RegP);
  match(mRegP);

  format %{ %}
  interface(REG_INTER);
%}

operand s4_RegP()
%{
  constraint(ALLOC_IN_RC(s4_long_reg));
  match(RegP);
  match(mRegP);

  format %{ %}
  interface(REG_INTER);
%}

operand t0_RegP()
%{
  constraint(ALLOC_IN_RC(t0_long_reg));
  match(RegP);
  match(mRegP);

  format %{ %}
  interface(REG_INTER);
%}

operand t1_RegP()
%{
  constraint(ALLOC_IN_RC(t1_long_reg));
  match(RegP);
  match(mRegP);

  format %{ %}
  interface(REG_INTER);
%}

operand t2_RegP()
%{
  constraint(ALLOC_IN_RC(t2_long_reg));
  match(RegP);
  match(mRegP);

  format %{ %}
  interface(REG_INTER);
%}

operand t3_RegP()
%{
  constraint(ALLOC_IN_RC(t3_long_reg));
  match(RegP);
  match(mRegP);

  format %{ %}
  interface(REG_INTER);
%}

operand a3_RegP()
%{
  constraint(ALLOC_IN_RC(a3_long_reg));
  match(RegP);
  match(mRegP);

  format %{ %}
  interface(REG_INTER);
%}

operand a4_RegP()
%{
  constraint(ALLOC_IN_RC(a4_long_reg));
  match(RegP);
  match(mRegP);

  format %{ %}
  interface(REG_INTER);
%}


operand a5_RegP()
%{
  constraint(ALLOC_IN_RC(a5_long_reg));
  match(RegP);
  match(mRegP);

  format %{ %}
  interface(REG_INTER);
%}

operand a6_RegP()
%{
  constraint(ALLOC_IN_RC(a6_long_reg));
  match(RegP);
  match(mRegP);

  format %{ %}
  interface(REG_INTER);
%}

operand a7_RegP()
%{
  constraint(ALLOC_IN_RC(a7_long_reg));
  match(RegP);
  match(mRegP);

  format %{ %}
  interface(REG_INTER);
%}

/*
operand mSPRegP(mRegP reg) %{
  constraint(ALLOC_IN_RC(sp_reg));
  match(reg);

  format %{ "SP"  %}
  interface(REG_INTER);
%}

operand mFPRegP(mRegP reg) %{
  constraint(ALLOC_IN_RC(fp_reg));
  match(reg);

  format %{ "FP"  %}
  interface(REG_INTER);
%}
*/

operand mRegL() %{
  constraint(ALLOC_IN_RC(long_reg));
  match(RegL);
  match(v0RegL);
  match(v1RegL);
  match(a0RegL);
  match(a1RegL);
  match(a2RegL);
  match(a3RegL);
  match(t0RegL);
  match(t1RegL);
  match(t2RegL);
  match(t3RegL);
  match(a4RegL);
  match(a5RegL);
  match(a6RegL);
  match(a7RegL);

  format %{ %}
  interface(REG_INTER);
%}

operand v0RegL() %{
  constraint(ALLOC_IN_RC(v0_long_reg));
  match(RegL);
  match(mRegL);

  format %{ %}
  interface(REG_INTER);
%}

operand v1RegL() %{
  constraint(ALLOC_IN_RC(v1_long_reg));
  match(RegL);
  match(mRegL);

  format %{ %}
  interface(REG_INTER);
%}

operand a0RegL() %{
  constraint(ALLOC_IN_RC(a0_long_reg));
  match(RegL);
  match(mRegL);

  format %{ "A0" %}
  interface(REG_INTER);
%}

operand a1RegL() %{
  constraint(ALLOC_IN_RC(a1_long_reg));
  match(RegL);
  match(mRegL);

  format %{ %}
  interface(REG_INTER);
%}

operand a2RegL() %{
  constraint(ALLOC_IN_RC(a2_long_reg));
  match(RegL);
  match(mRegL);

  format %{ %}
  interface(REG_INTER);
%}

operand a3RegL() %{
  constraint(ALLOC_IN_RC(a3_long_reg));
  match(RegL);
  match(mRegL);

  format %{ %}
  interface(REG_INTER);
%}

operand t0RegL() %{
  constraint(ALLOC_IN_RC(t0_long_reg));
  match(RegL);
  match(mRegL);

  format %{ %}
  interface(REG_INTER);
%}

operand t1RegL() %{
  constraint(ALLOC_IN_RC(t1_long_reg));
  match(RegL);
  match(mRegL);

  format %{ %}
  interface(REG_INTER);
%}

operand t2RegL() %{
  constraint(ALLOC_IN_RC(t2_long_reg));
  match(RegL);
  match(mRegL);

  format %{ %}
  interface(REG_INTER);
%}

operand t3RegL() %{
  constraint(ALLOC_IN_RC(t3_long_reg));
  match(RegL);
  match(mRegL);

  format %{ %}
  interface(REG_INTER);
%}

operand a4RegL() %{
  constraint(ALLOC_IN_RC(a4_long_reg));
  match(RegL);
  match(mRegL);

  format %{ %}
  interface(REG_INTER);
%}

operand a5RegL() %{
  constraint(ALLOC_IN_RC(a5_long_reg));
  match(RegL);
  match(mRegL);

  format %{ %}
  interface(REG_INTER);
%}

operand a6RegL() %{
  constraint(ALLOC_IN_RC(a6_long_reg));
  match(RegL);
  match(mRegL);

  format %{ %}
  interface(REG_INTER);
%}

operand a7RegL() %{
  constraint(ALLOC_IN_RC(a7_long_reg));
  match(RegL);
  match(mRegL);

  format %{ %}
  interface(REG_INTER);
%}

// Floating register operands
operand regF() %{
  constraint(ALLOC_IN_RC(flt_reg));
  match(RegF);

  format %{ %}
  interface(REG_INTER);
%}

//Double Precision Floating register operands
operand regD() %{
  constraint(ALLOC_IN_RC(dbl_reg));
  match(RegD);

  format %{ %}
  interface(REG_INTER);
%}

//----------Memory Operands----------------------------------------------------
// Indirect Memory Operand
operand indirect(mRegP reg) %{
  constraint(ALLOC_IN_RC(p_reg));
  op_cost(10);
  match(reg);

  format %{ "[$reg] @ indirect" %}
  interface(MEMORY_INTER) %{
    base($reg);
    index(0x0);	/* NO_INDEX */
    scale(0x0);
    disp(0x0);
  %}
%}

// Indirect Memory Plus Short Offset Operand
operand indOffset8(mRegP reg, immL8 off)
%{
  constraint(ALLOC_IN_RC(p_reg));
  op_cost(20);
  match(AddP reg off);

  format %{ "[$reg + $off (8-bit)] @ indOffset8" %}
  interface(MEMORY_INTER) %{
    base($reg);
    index(0x0); /* NO_INDEX */
    scale(0x0);
    disp($off);
  %}
%}

// [base + index + offset] 
operand baseIndexOffset8(mRegP base, mRegL index, immL8 off)
%{
  constraint(ALLOC_IN_RC(p_reg));
  op_cost(5);
  match(AddP (AddP base index) off);

  format %{ "[$base + $index + $off (8-bit)] @ baseIndexOffset8" %}
  interface(MEMORY_INTER) %{
    base($base);
    index($index);
    scale(0x0);
    disp($off);
  %}
%}

// [base + index + offset] 
operand baseIndexOffset8_convI2L(mRegP base, mRegI index, immL8 off)
%{
  constraint(ALLOC_IN_RC(p_reg));
  op_cost(5);
  match(AddP (AddP base (ConvI2L index)) off);

  format %{ "[$base + $index + $off (8-bit)] @ baseIndexOffset8_convI2L" %}
  interface(MEMORY_INTER) %{
    base($base);
    index($index);
    scale(0x0);
    disp($off);
  %}
%}

//FIXME: I think it's better to limit the immI to be 16-bit at most!
// Indirect Memory Plus Long Offset Operand
operand indOffset32(mRegP reg, immL32 off) %{
  constraint(ALLOC_IN_RC(p_reg));
  op_cost(20);
  match(AddP reg off);

  format %{ "[$reg + $off (32-bit)] @ indOffset32" %}
  interface(MEMORY_INTER) %{
    base($reg);
    index(0x0); 	/* NO_INDEX */
    scale(0x0);
    disp($off);
  %}
%}

// Indirect Memory Plus Index Register 
operand indIndex(mRegP addr, mRegL index) %{
  constraint(ALLOC_IN_RC(p_reg));
  match(AddP addr index);

  op_cost(20);
  format %{"[$addr + $index] @ indIndex" %}
  interface(MEMORY_INTER) %{
    base($addr);
    index($index);
    scale(0x0);
    disp(0x0);
  %}
%}

operand indirectNarrowKlass(mRegN reg)
%{
  predicate(Universe::narrow_klass_shift() == 0);
  constraint(ALLOC_IN_RC(p_reg));
  op_cost(10);
  match(DecodeNKlass reg);

  format %{ "[$reg] @ indirectNarrowKlass" %}
  interface(MEMORY_INTER) %{
    base($reg);
    index(0x0);
    scale(0x0);
    disp(0x0);
  %}
%}

operand indOffset8NarrowKlass(mRegN reg, immL8 off)
%{
  predicate(Universe::narrow_klass_shift() == 0);
  constraint(ALLOC_IN_RC(p_reg));
  op_cost(10);
  match(AddP (DecodeNKlass reg) off);

  format %{ "[$reg + $off (8-bit)] @ indOffset8NarrowKlass" %}
  interface(MEMORY_INTER) %{
    base($reg);
    index(0x0);
    scale(0x0);
    disp($off);
  %}
%}

operand indOffset32NarrowKlass(mRegN reg, immL32 off)
%{
  predicate(Universe::narrow_klass_shift() == 0);
  constraint(ALLOC_IN_RC(p_reg));
  op_cost(10);
  match(AddP (DecodeNKlass reg) off);

  format %{ "[$reg + $off (32-bit)] @ indOffset32NarrowKlass" %}
  interface(MEMORY_INTER) %{
    base($reg);
    index(0x0);
    scale(0x0);
    disp($off);
  %}
%}

operand indIndexOffsetNarrowKlass(mRegN reg, mRegL lreg, immL32 off)
%{
  predicate(Universe::narrow_klass_shift() == 0);
  constraint(ALLOC_IN_RC(p_reg));
  match(AddP (AddP (DecodeNKlass reg) lreg) off);

  op_cost(10);
  format %{"[$reg + $off + $lreg] @ indIndexOffsetNarrowKlass" %}
  interface(MEMORY_INTER) %{
    base($reg);
    index($lreg);
    scale(0x0);
    disp($off);
  %}
%}

operand indIndexNarrowKlass(mRegN reg, mRegL lreg)
%{
  predicate(Universe::narrow_klass_shift() == 0);
  constraint(ALLOC_IN_RC(p_reg));
  match(AddP (DecodeNKlass reg) lreg);

  op_cost(10);
  format %{"[$reg + $lreg] @ indIndexNarrowKlass" %}
  interface(MEMORY_INTER) %{
    base($reg);
    index($lreg);
    scale(0x0);
    disp(0x0);
  %}
%}

// Indirect Memory Operand
operand indirectNarrow(mRegN reg)
%{
  predicate(Universe::narrow_oop_shift() == 0);
  constraint(ALLOC_IN_RC(p_reg));
  op_cost(10);
  match(DecodeN reg);

  format %{ "[$reg] @ indirectNarrow" %}
  interface(MEMORY_INTER) %{
    base($reg);
    index(0x0);
    scale(0x0);
    disp(0x0);
  %}
%}

//----------Load Long Memory Operands------------------------------------------
// The load-long idiom will use it's address expression again after loading
// the first word of the long.  If the load-long destination overlaps with
// registers used in the addressing expression, the 2nd half will be loaded
// from a clobbered address.  Fix this by requiring that load-long use
// address registers that do not overlap with the load-long target.

// load-long support
operand load_long_RegP() %{
  constraint(ALLOC_IN_RC(p_reg));
  match(RegP);
  match(mRegP);
  op_cost(100);
  format %{  %}
  interface(REG_INTER);
%}

// Indirect Memory Operand Long
operand load_long_indirect(load_long_RegP reg) %{
  constraint(ALLOC_IN_RC(p_reg));
  match(reg);

  format %{ "[$reg]" %}
  interface(MEMORY_INTER) %{
    base($reg);
    index(0x0);
    scale(0x0);
    disp(0x0);
  %}
%}

// Indirect Memory Plus Long Offset Operand
operand load_long_indOffset32(load_long_RegP reg, immL32 off) %{
  match(AddP reg off);

  format %{ "[$reg + $off]" %}
  interface(MEMORY_INTER) %{
    base($reg);
    index(0x0);
    scale(0x0);
    disp($off);
  %}
%}

//----------Conditional Branch Operands----------------------------------------
// Comparison Op  - This is the operation of the comparison, and is limited to
//                  the following set of codes:
//                  L (<), LE (<=), G (>), GE (>=), E (==), NE (!=)
//
// Other attributes of the comparison, such as unsignedness, are specified
// by the comparison instruction that sets a condition code flags register.
// That result is represented by a flags operand whose subtype is appropriate
// to the unsignedness (etc.) of the comparison.
//
// Later, the instruction which matches both the Comparison Op (a Bool) and
// the flags (produced by the Cmp) specifies the coding of the comparison op
// by matching a specific subtype of Bool operand below, such as cmpOpU.

// Comparision Code
operand cmpOp() %{
  match(Bool);

  format %{ "" %}
  interface(COND_INTER) %{
    equal(0x01);
    not_equal(0x02);
    greater(0x03);
    greater_equal(0x04);
    less(0x05);
    less_equal(0x06);
    overflow(0x7);
    no_overflow(0x8);
  %}
%}


// Comparision Code
// Comparison Code, unsigned compare.  Used by FP also, with
// C2 (unordered) turned into GT or LT already.  The other bits
// C0 and C3 are turned into Carry & Zero flags.
operand cmpOpU() %{
  match(Bool);

  format %{ "" %}
  interface(COND_INTER) %{
    equal(0x01);
    not_equal(0x02);
    greater(0x03);
    greater_equal(0x04);
    less(0x05);
    less_equal(0x06);
    overflow(0x7);
    no_overflow(0x8);
  %}
%}

/*
// Comparison Code, unsigned compare.  Used by FP also, with
// C2 (unordered) turned into GT or LT already.  The other bits
// C0 and C3 are turned into Carry & Zero flags.
operand cmpOpU() %{
  match(Bool);

  format %{ "" %}
  interface(COND_INTER) %{
    equal(0x4);
    not_equal(0x5);
    less(0x2);
    greater_equal(0x3);
    less_equal(0x6);
    greater(0x7);
  %}
%}
*/
/*
// Comparison Code for FP conditional move
operand cmpOp_fcmov() %{
  match(Bool);

  format %{ "" %}
  interface(COND_INTER) %{
    equal        (0x01);
    not_equal    (0x02);
    greater      (0x03);
    greater_equal(0x04);
    less         (0x05);
    less_equal   (0x06);
  %}
%}

// Comparision Code used in long compares
operand cmpOp_commute() %{
  match(Bool);

  format %{ "" %}
  interface(COND_INTER) %{
    equal(0x4);
    not_equal(0x5);
    less(0xF);
    greater_equal(0xE);
    less_equal(0xD);
    greater(0xC);
  %}
%}
*/

/*
//----------Special Memory Operands--------------------------------------------
// Stack Slot Operand - This operand is used for loading and storing temporary
//                      values on the stack where a match requires a value to
//                      flow through memory.
operand stackSlotP(sRegP reg) %{
  constraint(ALLOC_IN_RC(stack_slots));
  // No match rule because this operand is only generated in matching
  op_cost(50);
  format %{ "[$reg]" %}
  interface(MEMORY_INTER) %{
    base(0x1d);   // SP
    index(0x0);  // No Index
    scale(0x0);  // No Scale
    disp($reg);  // Stack Offset
  %}
%}

operand stackSlotI(sRegI reg) %{
  constraint(ALLOC_IN_RC(stack_slots));
  // No match rule because this operand is only generated in matching
  op_cost(50);
  format %{ "[$reg]" %}
  interface(MEMORY_INTER) %{
    base(0x1d);   // SP
    index(0x0);  // No Index
    scale(0x0);  // No Scale
    disp($reg);  // Stack Offset
  %}
%}

operand stackSlotF(sRegF reg) %{
  constraint(ALLOC_IN_RC(stack_slots));
  // No match rule because this operand is only generated in matching
  op_cost(50);
  format %{ "[$reg]" %}
  interface(MEMORY_INTER) %{
    base(0x1d);   // SP
    index(0x0);  // No Index
    scale(0x0);  // No Scale
    disp($reg);  // Stack Offset
  %}
%}

operand stackSlotD(sRegD reg) %{
  constraint(ALLOC_IN_RC(stack_slots));
  // No match rule because this operand is only generated in matching
  op_cost(50);
  format %{ "[$reg]" %}
  interface(MEMORY_INTER) %{
    base(0x1d);   // SP
    index(0x0);  // No Index
    scale(0x0);  // No Scale
    disp($reg);  // Stack Offset
  %}
%}

operand stackSlotL(sRegL reg) %{
  constraint(ALLOC_IN_RC(stack_slots));
  // No match rule because this operand is only generated in matching
  op_cost(50);
  format %{ "[$reg]" %}
  interface(MEMORY_INTER) %{
    base(0x1d);   // SP
    index(0x0);  // No Index
    scale(0x0);  // No Scale
    disp($reg);  // Stack Offset
  %}
%}
*/
 

//------------------------OPERAND CLASSES--------------------------------------
//opclass memory( direct, indirect, indOffset16, indOffset32, indOffset32X, indIndexOffset );
opclass memory( indirect, indirectNarrow, indOffset8, indOffset32, indIndex, load_long_indirect, load_long_indOffset32, baseIndexOffset8, baseIndexOffset8_convI2L); 


//----------PIPELINE-----------------------------------------------------------
// Rules which define the behavior of the target architectures pipeline.
 
pipeline %{

//----------ATTRIBUTES---------------------------------------------------------
attributes %{
 	fixed_size_instructions;        	// Fixed size instructions
 	branch_has_delay_slot;			// branch have delay slot in gs2
 	max_instructions_per_bundle = 1;   	// 1 instruction per bundle
 	max_bundles_per_cycle = 4;       	// Up to 4 bundles per cycle
        bundle_unit_size=4;
 	instruction_unit_size = 4;         	// An instruction is 4 bytes long
 	instruction_fetch_unit_size = 16;  	// The processor fetches one line
 	instruction_fetch_units = 1;       	// of 16 bytes
 
 	// List of nop instructions
 	nops( MachNop );
 %}
 
 //----------RESOURCES----------------------------------------------------------
 // Resources are the functional units available to the machine
 
 resources(D1, D2, D3, D4, DECODE = D1 | D2 | D3| D4,  ALU1, ALU2,  ALU = ALU1 | ALU2,  FPU1, FPU2, FPU = FPU1 | FPU2,  MEM,  BR); 

 //----------PIPELINE DESCRIPTION-----------------------------------------------
 // Pipeline Description specifies the stages in the machine's pipeline

 // IF: fetch
 // ID: decode
 // RD: read 
 // CA: caculate 
 // WB: write back 
 // CM: commit 

 pipe_desc(IF, ID, RD, CA, WB, CM);


 //----------PIPELINE CLASSES---------------------------------------------------
 // Pipeline Classes describe the stages in which input and output are
 // referenced by the hardware pipeline.

 //No.1 Integer ALU reg-reg operation : dst <-- reg1 op reg2  
 pipe_class ialu_regI_regI(mRegI dst, mRegI src1, mRegI src2) %{
        single_instruction;
 	src1   : RD(read);
 	src2   : RD(read);
        dst    : WB(write)+1;
        DECODE : ID;
 	ALU    : CA;
 %}

 //No.19 Integer mult operation : dst <-- reg1 mult reg2  
 pipe_class ialu_mult(mRegI dst, mRegI src1, mRegI src2) %{
 	src1   : RD(read);
 	src2   : RD(read);
        dst    : WB(write)+5;
        DECODE : ID;
 	ALU2   : CA;
 %}

 pipe_class mulL_reg_reg(mRegL dst, mRegL src1, mRegL src2) %{
 	src1   : RD(read);
 	src2   : RD(read);
        dst    : WB(write)+10;
        DECODE : ID;
 	ALU2   : CA;
 %}

 //No.19 Integer div operation : dst <-- reg1 div reg2  
 pipe_class ialu_div(mRegI dst, mRegI src1, mRegI src2) %{
 	src1   : RD(read);
 	src2   : RD(read);
        dst    : WB(write)+10;
        DECODE : ID;
 	ALU2   : CA;
 %}

 //No.19 Integer mod operation : dst <-- reg1 mod reg2  
 pipe_class ialu_mod(mRegI dst, mRegI src1, mRegI src2) %{
        instruction_count(2);
 	src1   : RD(read);
 	src2   : RD(read);
        dst    : WB(write)+10;
        DECODE : ID;
 	ALU2   : CA;
 %}

 //No.15 Long ALU reg-reg operation : dst <-- reg1 op reg2  
 pipe_class ialu_regL_regL(mRegL dst, mRegL src1, mRegL src2) %{
        instruction_count(2);
 	src1   : RD(read);
 	src2   : RD(read);
        dst    : WB(write);
        DECODE : ID;
 	ALU    : CA;
 %}

 //No.18 Long ALU reg-imm16 operation : dst <-- reg1 op imm16 
 pipe_class ialu_regL_imm16(mRegL dst, mRegL src) %{
        instruction_count(2);
 	src    : RD(read);
        dst    : WB(write);
        DECODE : ID;
 	ALU    : CA;
 %}

 //no.16 load Long from memory :                     
 pipe_class ialu_loadL(mRegL dst, memory mem) %{
 	instruction_count(2);
 	mem    : RD(read);
 	dst    : WB(write)+5;
        DECODE : ID;
 	MEM    : RD;
 %}

 //No.17 Store Long to Memory :                     
 pipe_class ialu_storeL(mRegL src, memory mem) %{
 	instruction_count(2);
 	mem    : RD(read);
 	src    : RD(read);
        DECODE : ID;
 	MEM    : RD;
 %}

 //No.2 Integer ALU reg-imm16 operation : dst <-- reg1 op imm16  
 pipe_class ialu_regI_imm16(mRegI dst, mRegI src) %{
        single_instruction;
 	src    : RD(read);
        dst    : WB(write);
        DECODE : ID;
 	ALU    : CA;
 %}

 //No.3 Integer move operation : dst <-- reg  
 pipe_class ialu_regI_mov(mRegI dst, mRegI src) %{
 	src    : RD(read);
        dst    : WB(write);
        DECODE : ID;
 	ALU    : CA;
 %}
 
 //No.4 No instructions : do nothing 
 pipe_class empty( ) %{
        instruction_count(0);
 %}

 //No.5 UnConditional branch :
 pipe_class pipe_jump( label labl ) %{
        multiple_bundles;
        DECODE : ID;
	BR     : RD;
 %}

 //No.6 ALU Conditional branch :
 pipe_class pipe_alu_branch(mRegI src1, mRegI src2, label labl ) %{
        multiple_bundles;
        src1   : RD(read);
        src2   : RD(read);
        DECODE : ID;
	BR     : RD;
 %}

 //no.7 load integer from memory :                     
 pipe_class ialu_loadI(mRegI dst, memory mem) %{
 	mem    : RD(read);
 	dst    : WB(write)+3;
        DECODE : ID;
 	MEM    : RD;
 %}

 //No.8 Store Integer to Memory :                     
 pipe_class ialu_storeI(mRegI src, memory mem) %{
 	mem    : RD(read);
 	src    : RD(read);
        DECODE : ID;
 	MEM    : RD;
 %}


 //No.10 Floating FPU reg-reg operation : dst <-- reg1 op reg2  
 pipe_class fpu_regF_regF(regF dst, regF src1, regF src2) %{
 	src1   : RD(read);
 	src2   : RD(read);
        dst    : WB(write);
        DECODE : ID;
 	FPU    : CA;
 %}

 //No.22 Floating div operation : dst <-- reg1 div reg2  
 pipe_class fpu_div(regF dst, regF src1, regF src2) %{
 	src1   : RD(read);
 	src2   : RD(read);
        dst    : WB(write);
        DECODE : ID;
 	FPU2   : CA;
 %}

 pipe_class fcvt_I2D(regD dst, mRegI src) %{
 	src    : RD(read);
        dst    : WB(write);
        DECODE : ID;
 	FPU1   : CA;
 %}

 pipe_class fcvt_D2I(mRegI dst, regD src) %{
 	src    : RD(read);
        dst    : WB(write);
        DECODE : ID;
 	FPU1   : CA;
 %}

 pipe_class pipe_mfc1(mRegI dst, regD src) %{
 	src    : RD(read);
        dst    : WB(write);
        DECODE : ID;
 	MEM    : RD;
 %}

 pipe_class pipe_mtc1(regD dst, mRegI src) %{
 	src    : RD(read);
        dst    : WB(write);
        DECODE : ID;
 	MEM    : RD(5);
 %}

 //No.23 Floating sqrt operation : dst <-- reg1 sqrt reg2  
 pipe_class fpu_sqrt(regF dst, regF src1, regF src2) %{
        multiple_bundles;
 	src1   : RD(read);
 	src2   : RD(read);
        dst    : WB(write);
        DECODE : ID;
 	FPU2   : CA;
 %}

 //No.11 Load Floating from Memory :                     
 pipe_class fpu_loadF(regF dst, memory mem) %{
        instruction_count(1);
 	mem    : RD(read);
 	dst    : WB(write)+3;
        DECODE : ID;
 	MEM    : RD;
 %}

 //No.12 Store Floating to Memory :                     
 pipe_class fpu_storeF(regF src, memory mem) %{
        instruction_count(1);
 	mem    : RD(read);
 	src    : RD(read);
        DECODE : ID;
 	MEM    : RD;
 %}

 //No.13 FPU Conditional branch :
 pipe_class pipe_fpu_branch(regF src1, regF src2, label labl ) %{
        multiple_bundles;
        src1   : RD(read);
        src2   : RD(read);
        DECODE : ID;
	BR     : RD;
 %}

//No.14 Floating FPU reg operation : dst <-- op reg  
 pipe_class fpu1_regF(regF dst, regF src) %{
 	src    : RD(read);
        dst    : WB(write);
        DECODE : ID;
 	FPU    : CA;
 %}

 pipe_class long_memory_op() %{
	instruction_count(10); multiple_bundles; force_serialization;
	fixed_latency(30);
 %}

 pipe_class simple_call() %{
	instruction_count(10); multiple_bundles; force_serialization;
	fixed_latency(200);
	BR     : RD;
 %}

 pipe_class call() %{
	instruction_count(10); multiple_bundles; force_serialization;
	fixed_latency(200);
 %}

 //FIXME:
 //No.9 Piple slow : for multi-instructions 
 pipe_class pipe_slow(  ) %{
	instruction_count(20);
        force_serialization;
        multiple_bundles;
	fixed_latency(50);
 %}

%}



//----------INSTRUCTIONS-------------------------------------------------------
// 
// match      -- States which machine-independent subtree may be replaced 
//               by this instruction.
// ins_cost   -- The estimated cost of this instruction is used by instruction
//               selection to identify a minimum cost tree of machine 
//               instructions that matches a tree of machine-independent 
//               instructions.
// format     -- A string providing the disassembly for this instruction.
//               The value of an instruction's operand may be inserted 
//               by referring to it with a '$' prefix.
// opcode     -- Three instruction opcodes may be provided.  These are referred 
//               to within an encode class as $primary, $secondary, and $tertiary
//               respectively.  The primary opcode is commonly used to 
//               indicate the type of machine instruction, while secondary 
//               and tertiary are often used for prefix options or addressing 
//               modes.
// ins_encode -- A list of encode classes with parameters. The encode class
//               name must have been defined in an 'enc_class' specification
//               in the encode section of the architecture description.


// Load Integer
instruct loadI(mRegI dst, memory mem) %{
  match(Set dst (LoadI mem));

  ins_cost(125);
  format %{ "lw    $dst, $mem 	#@loadI" %}
  ins_encode (load_I_enc(dst, mem));
  ins_pipe( ialu_loadI );
%}

instruct loadI_convI2L(mRegL dst, memory mem) %{
  match(Set dst (ConvI2L (LoadI mem)));

  ins_cost(125);
  format %{ "lw    $dst, $mem 	#@loadI_convI2L" %}
  ins_encode (load_I_enc(dst, mem));
  ins_pipe( ialu_loadI );
%}

// Load Long.
instruct loadL(mRegL dst, memory mem) %{
//  predicate(!((LoadLNode*)n)->require_atomic_access());
  match(Set dst (LoadL mem));

  ins_cost(250);
  format %{ "ld    $dst, $mem   #@loadL" %}
  ins_encode(load_L_enc(dst, mem));
  ins_pipe( ialu_loadL );
%}

// Load Long - UNaligned
instruct loadL_unaligned(mRegL dst, memory mem) %{
  match(Set dst (LoadL_unaligned mem));

  // FIXME: Jin: Need more effective ldl/ldr
  ins_cost(450);
  format %{ "ld    $dst, $mem   #@loadL_unaligned\n\t" %}
  ins_encode(load_L_enc(dst, mem));
  ins_pipe( ialu_loadL );
%}

// Store Long
instruct storeL_reg(memory mem, mRegL src) %{
  predicate(!((StoreLNode*)n)->require_atomic_access());
  match(Set mem (StoreL mem src));

  ins_cost(200);
  format %{ "sd    $mem,   $src #@storeL_reg\n" %}
  ins_encode(store_L_reg_enc(mem, src));
  ins_pipe( ialu_storeL );
%}

//FIXME:volatile! atomic!
// Volatile Store Long.  Must be atomic, so move it into
// the FP TOS and then do a 64-bit FIST.  Has to probe the
// target address before the store (for null-ptr checks)
// so the memory operand is used twice in the encoding.
instruct storeL_reg_atomic(memory mem, mRegL src) %{
  predicate(((StoreLNode*)n)->require_atomic_access());
  match(Set mem (StoreL mem src));

  ins_cost(200);
  format %{ "sw    $mem,   $src #@storeL_reg_atomic\n\t"
            "sw    $mem+4, $src.hi #@storeL_reg_atomic" %}
  ins_encode %{
    Register src = as_Register($src$$reg);

    int      base = $mem$$base;
    int     index = $mem$$index;
    int     scale = $mem$$scale;
    int      disp = $mem$$disp;

//    assert(false, "storeL_reg_atomic should store a long value atomically");

    if( scale != 0 ) Unimplemented();
    if( index != 0 ) {
       if( Assembler::is_simm16(disp) ) { 
          __ addu(AT, as_Register(base), as_Register(index));
          __ sd(src, AT, disp);
       } else {
          __ addu(AT, as_Register(base), as_Register(index));
          __ move(T9, disp);
          __ addu(AT, AT, T9);
          __ sd(src, AT, 0);
       }
    } else {
       if( Assembler::is_simm16(disp) ) { 
          __ move(AT, as_Register(base));
          __ sd(src, AT, disp);
       } else {
          __ move(AT, as_Register(base));
          __ move(T9, disp);
          __ addu(AT, AT, T9);
          __ sd(src, AT, 0);
       }
    }

  %}
  ins_pipe( ialu_storeL );
%}

instruct storeL_immL0(memory mem, immL0 zero) %{
  match(Set mem (StoreL mem zero));

  ins_cost(180);
  format %{ "sd    $mem,   zero #@storeL_immL0" %}
  ins_encode(store_L_immL0_enc(mem, zero));
  ins_pipe( ialu_storeL );
%}

instruct storeL_imm(memory mem, immL src) %{
  match(Set mem (StoreL mem src));

  ins_cost(200);
  format %{ "sw    $mem,   $src #@storeL_imm" %}
  ins_encode(store_L_immL_enc(mem, src));
  ins_pipe( ialu_storeL );
%}

// Load Compressed Pointer
instruct loadN(mRegN dst, memory mem)
%{
   match(Set dst (LoadN mem));

   ins_cost(125); // XXX
   format %{ "lwu    $dst, $mem\t# compressed ptr @ loadN" %}
//TODO: Address should be implemented
/*
   ins_encode %{
     __ lwu($dst$$Register, $mem$$Address);
   %}
*/
  ins_encode (load_N_enc(dst, mem));
   ins_pipe( ialu_loadI ); // XXX
%}

// Load Pointer
instruct loadP(mRegP dst, memory mem) %{
  match(Set dst (LoadP mem));

  ins_cost(125);
  format %{ "ld    $dst, $mem #@loadP" %}
  ins_encode (load_P_enc(dst, mem));
  ins_pipe( ialu_loadI );
%}

// Load Klass Pointer
instruct loadKlass(mRegP dst, memory mem) %{
  match(Set dst (LoadKlass mem));

  ins_cost(125);
  format %{ "MOV    $dst,$mem @ loadKlass" %}
  ins_encode (load_P_enc(dst, mem));
  ins_pipe( ialu_loadI );
%}

// Load narrow Klass Pointer
instruct loadNKlass(mRegN dst, memory mem)
%{
  match(Set dst (LoadNKlass mem));

  ins_cost(125); // XXX
  format %{ "lwu    $dst, $mem\t# compressed klass ptr" %}
  ins_encode (load_N_enc(dst, mem));
/*
  ins_encode %{
    __ lwu($dst$$Register, $mem$$Address);
  %}
*/
  ins_pipe( ialu_loadI ); // XXX
%}

// Load Constant
instruct loadConI(mRegI dst, immI src) %{
  match(Set dst src);

  format %{ "mov    $dst, $src #@loadConI" %}
  ins_encode %{
    Register dst = $dst$$Register;
    int    value = $src$$constant;
    __ move(dst, value);
  %}
  ins_pipe( ialu_regI_regI );
%}


instruct loadConL(mRegL dst, immL src) %{
  match(Set dst src);
//  effect(ILL cr);
  ins_cost(200);
  format %{ "li    $dst, $src #@loadConL\t"
         %}
  ins_encode %{
    Register dst_reg = as_Register($dst$$reg);
    __ li(dst_reg, (long)$src$$constant);
  %}
  ins_pipe( ialu_regL_regL );
%}


// Load Range
instruct loadRange(mRegI dst, memory mem) %{
  match(Set dst (LoadRange mem));

  ins_cost(125);
  format %{ "MOV    $dst,$mem @ loadRange" %}
  ins_encode(load_I_enc(dst, mem));
  ins_pipe( ialu_loadI );
%}


instruct storeP(memory mem, mRegP src ) %{
  match(Set mem (StoreP mem src));

  ins_cost(125);
  format %{ "sd    $src, $mem #@storeP" %}
  ins_encode(store_P_reg_enc(mem, src));
  ins_pipe( ialu_storeI );
%}

/*
[Ref: loadConP]

Error:
  0x2d4b6d40: lui t9, 0x4f			<--- handle
  0x2d4b6d44: addiu t9, t9, 0xffff808c
  0x2d4b6d48: sw t9, 0x4(s2)

OK:
  0x2cc5ed40: lui t9, 0x336a 			<--- klass
  0x2cc5ed44: addiu t9, t9, 0x5a10 
  0x2cc5ed48: sw t9, 0x4(s2)
*/
// Store Pointer Immediate; null pointers or constant oops that do not
// need card-mark barriers.

// Store NULL Pointer, mark word, or other simple pointer constant.
instruct storeImmP(memory mem, immP31 src) %{
  match(Set mem (StoreP mem src));

  ins_cost(150);
  format %{ "mov    $mem, $src #@storeImmP" %}
  ins_encode(store_P_immP_enc(mem, src));
  ins_pipe( ialu_storeI );
%}

// Store Byte Immediate
instruct storeImmB(memory mem, immI8 src) %{
  match(Set mem (StoreB mem src));

  ins_cost(150);
  format %{ "movb   $mem, $src #@storeImmB" %}
  ins_encode(store_B_immI_enc(mem, src));
  ins_pipe( ialu_storeI );
%}

// Store Compressed Pointer
instruct storeN(memory mem, mRegN src)
%{
  match(Set mem (StoreN mem src));

  ins_cost(125); // XXX
  format %{ "sw    $mem, $src\t# compressed ptr @ storeN" %}
  ins_encode(store_N_reg_enc(mem, src)); 
  ins_pipe( ialu_storeI );
%}

instruct storeNKlass(memory mem, mRegN src)
%{
  match(Set mem (StoreNKlass mem src));

  ins_cost(125); // XXX
  format %{ "sw    $mem, $src\t# compressed klass ptr" %}
  ins_encode(store_N_reg_enc(mem, src));
  ins_pipe( ialu_storeI );
%}

instruct storeImmN0(memory mem, immN0 zero)
%{
  predicate(Universe::narrow_oop_base() == NULL && Universe::narrow_klass_base() == NULL);
  match(Set mem (StoreN mem zero));

  ins_cost(125); // XXX
  format %{ "storeN0    $mem, R12\t# compressed ptr (R12_heapbase==0)" %}
  ins_encode(storeImmN0_enc(mem, zero));
  ins_pipe( ialu_storeI );
%}

instruct storeImmN(memory mem, immN src)
%{
  match(Set mem (StoreN mem src));

  ins_cost(150); // XXX
  format %{ "storeImmN    $mem, $src\t# compressed ptr @ storeImmN" %}
  ins_encode(storeImmN_enc(mem, src));
  ins_pipe( ialu_storeI );
%}

instruct storeImmNKlass(memory mem, immNKlass src)
%{
  match(Set mem (StoreNKlass mem src));

  ins_cost(150); // XXX
  format %{ "sw    $mem, $src\t# compressed klass ptr" %}
  ins_encode(storeImmNKlass_enc(mem, src));
  ins_pipe( ialu_storeI );
%}

// Store Byte
instruct storeB(memory mem, mRegI src) %{
  match(Set mem (StoreB mem src));

  ins_cost(125);
  format %{ "sb    $src, $mem #@storeB" %}
  ins_encode(store_B_reg_enc(mem, src));
  ins_pipe( ialu_storeI );
%}

// Load Byte (8bit signed)
instruct loadB(mRegI dst, memory mem) %{
  match(Set dst (LoadB mem));

  ins_cost(125);
  format %{ "lb   $dst, $mem #@loadB" %}
  ins_encode(load_B_enc(dst, mem));
  ins_pipe( ialu_loadI );
%}

// Load Byte (8bit UNsigned)
instruct loadUB(mRegI dst, memory mem) %{
  match(Set dst (LoadUB mem));

  ins_cost(125);
  format %{ "lbu   $dst, $mem #@loadUB" %}
  ins_encode(load_UB_enc(dst, mem));
  ins_pipe( ialu_loadI );
%}

// Load Short (16bit signed)
instruct loadS(mRegI dst, memory mem) %{
  match(Set dst (LoadS mem));

  ins_cost(125);
  format %{ "lh   $dst, $mem #@loadS" %}
  ins_encode(load_S_enc(dst, mem));
  ins_pipe( ialu_loadI );
%}

instruct prefetchAllocNTA( memory mem ) %{
  match(PrefetchAllocation mem);
  ins_cost(400);
  format %{ "PREFETCHNTA $mem\t# Prefetch allocation to non-temporal cache for write (empty)" %}
  ins_encode %{
    // __ sync();
  %}
  ins_pipe(empty);
%}

// Store Integer Immediate
instruct storeImmI(memory mem, immI src) %{
  match(Set mem (StoreI mem src));

  ins_cost(150);
  format %{ "mov    $mem, $src #@storeImmI" %}
  ins_encode(store_I_immI_enc(mem, src));
  ins_pipe( ialu_storeI );
%}

// Store Integer
instruct storeI(memory mem, mRegI src) %{
  match(Set mem (StoreI mem src));

  ins_cost(125);
  format %{ "sw    $mem, $src #@storeI" %}
  ins_encode(store_I_reg_enc(mem, src));
  ins_pipe( ialu_storeI );
%}

// Load Float
instruct loadF(regF dst, memory mem) %{
  match(Set dst (LoadF mem));

  ins_cost(150);
  format %{ "loadF $dst, $mem #@loadF" %}
  ins_encode(load_F_enc(dst, mem));
  ins_pipe( ialu_loadI );
%}

instruct loadConP(mRegP dst, immP src) %{
  match(Set dst src);

  format %{ "li   $dst, $src #@loadConP" %}

  ins_encode %{
    Register dst = $dst$$Register;
	long* value = (long*)$src$$constant;
	bool is_need_reloc = $src->constant_reloc() != relocInfo::none;

    /* During GC, klassOop may be moved to new position in the heap.
     * It must be relocated.
     * Refer: [c1_LIRAssembler_mips.cpp] jobject2reg()
     */
    if (is_need_reloc) {
		if($src->constant_reloc() == relocInfo::metadata_type){
			int klass_index = __ oop_recorder()->find_index((Klass*)value);
			RelocationHolder rspec = metadata_Relocation::spec(klass_index);

			__ relocate(rspec);
			__ li48(dst, (long)value);
		}

		if($src->constant_reloc() == relocInfo::oop_type){
			int oop_index = __ oop_recorder()->find_index((jobject)value);
			RelocationHolder rspec = oop_Relocation::spec(oop_index);

			__ relocate(rspec);
			__ li48(dst, (long)value);
		}
    } else {
		__ li48(dst, (long)value);
    }
  %}

  ins_pipe( ialu_regI_regI );
%}

instruct loadConP0(mRegP dst, immP0 src)
%{
  match(Set dst src); 

  ins_cost(50);
  format %{ "mov    $dst, R0\t# ptr" %}
  ins_encode %{
		Register dst_reg = $dst$$Register;
		__ move(dst_reg, R0);
	%}
  ins_pipe( ialu_regI_regI );
%}

instruct loadConN0(mRegN dst, immN0 src, FlagsReg cr) %{
  match(Set dst src);
  effect(KILL cr);
  format %{ "move    $dst, R0\t# compressed NULL ptr" %}
  ins_encode %{
    __ move($dst$$Register, R0);
  %}
  ins_pipe( ialu_regI_regI );
%}

instruct loadConN(mRegN dst, immN src) %{
  match(Set dst src);

  ins_cost(125);
  format %{ "li    $dst, $src\t# compressed ptr @ loadConN" %}
  ins_encode %{
    address con = (address)$src$$constant;
    if (con == NULL) {
      ShouldNotReachHere();
    } else {
		assert (UseCompressedOops, "should only be used for compressed headers");
		assert (Universe::heap() != NULL, "java heap should be initialized");
		assert (__ oop_recorder() != NULL, "this assembler needs an OopRecorder");

		Register dst = $dst$$Register;
		long*   value = (long*)$src$$constant;
		int oop_index = __ oop_recorder()->find_index((jobject)value);
		RelocationHolder rspec = oop_Relocation::spec(oop_index);
		if(rspec.type()!=relocInfo::none){
			__ relocate(rspec, Assembler::narrow_oop_operand);
			__ li48(dst, oop_index);
		}
		else {
			__ li48(dst, oop_index);
		}
    }
  %}
  ins_pipe( ialu_regI_regI ); // XXX
%}

instruct loadConNKlass(mRegN dst, immNKlass src) %{
  match(Set dst src);

  ins_cost(125);
  format %{ "li    $dst, $src\t# compressed klass ptr" %}
  ins_encode %{
    address con = (address)$src$$constant;
    if (con == NULL) {
      ShouldNotReachHere();
    } else {
		Register dst = $dst$$Register;
		long*   value = (long*)$src$$constant;

		int klass_index = __ oop_recorder()->find_index((Klass*)value);
		RelocationHolder rspec = metadata_Relocation::spec(klass_index);
		long narrowp = (long)Klass::encode_klass((Klass*)value);

		if(rspec.type()!=relocInfo::none){
			__ relocate(rspec, Assembler::narrow_oop_operand);
			__ li48(dst, narrowp);
		}
		else {
			__ li48(dst, narrowp);
		}
    }
  %}
  ins_pipe( ialu_regI_regI ); // XXX
%}

/*
// Load Stack Slot
instruct loadSSI(mRegI dst, stackSlotI src) %{
  match(Set dst src);
  ins_cost(25);

  format %{ "MOV    $dst,$src #@loadSSI" %}
  ins_encode %{
    Register  dst = $dst$$Register;

    int      base = $src$$base;
    int     index = $src$$index;
    int     scale = $src$$scale;
    int      disp = $src$$disp;

fprintf(stderr, "\n?????????????????????????\n");//fujie debug
    if( scale != 0 ) Unimplemented();
    if( index != 0 ) {
       __ add(AT, as_Register(base), as_Register(index));
       __ lw(dst, AT, disp);
    } else {
       __ lw(dst, as_Register(base), disp);
    }
   
  %}

  ins_pipe( ialu_reg_mem );
%}

// Load Stack Slot
instruct loadSSP(mRegP dst, stackSlotP src) %{
  match(Set dst src);
  ins_cost(25);

  format %{ "MOV    $dst,$src #@loadSSP" %}
  ins_encode %{
    Register  dst = $dst$$Register;

    int      base = $src$$base;
    int     index = $src$$index;
    int     scale = $src$$scale;
    int      disp = $src$$disp;

fprintf(stderr, "\n?????????????????????????\n");//fujie debug
    if( scale != 0 ) Unimplemented();
    if( index != 0 ) {
       __ add(AT, as_Register(base), as_Register(index));
       __ lw(dst, AT, disp);
    } else {
       __ lw(dst, as_Register(base), disp);
    }
   
  %}

  ins_pipe( ialu_reg_mem );
%}
*/

//FIXME
// Tail Call; Jump from runtime stub to Java code.
// Also known as an 'interprocedural jump'.
// Target of jump will eventually return to caller.
// TailJump below removes the return address.
instruct TailCalljmpInd(mRegP jump_target, mRegP method_oop) %{
  match(TailCall jump_target method_oop );
  ins_cost(300);
  format %{ "JMP    $jump_target \t# @TailCalljmpInd" %}

  ins_encode %{
    Register target = $jump_target$$Register;
    Register    oop = $method_oop$$Register;

    /* 2012/10/12 Jin: RA will be used in generate_forward_exception() */
    __ push(RA);

    __ move(S3, oop);
    __ jr(target);
    __ nop();
  %}

  ins_pipe( pipe_jump );
%}

// Create exception oop: created by stack-crawling runtime code.
// Created exception is now available to this handler, and is setup
// just prior to jumping to this handler.  No code emitted.
instruct CreateException( a0_RegP ex_oop )
%{
  match(Set ex_oop (CreateEx));

  // use the following format syntax
  format %{ "# exception oop is in A0; no code emitted @CreateException" %}
  ins_encode %{
    /* Jin: X86 leaves this function empty */
    __ block_comment("CreateException is empty in X86/MIPS");
  %}
  ins_pipe( empty );
//  ins_pipe( pipe_jump );
%}


/* 2012/9/14 Jin: The mechanism of exception handling is clear now.

- Common try/catch:
 2012/9/14 Jin: [stubGenerator_mips.cpp] generate_forward_exception()
                    |- V0, V1 are created
                    |- T9 <= SharedRuntime::exception_handler_for_return_address
                    `- jr T9
                         `- the caller's exception_handler
                               `- jr OptoRuntime::exception_blob
                                      `- here
- Rethrow(e.g. 'unwind'):
  * The callee:
     |- an exception is triggered during execution
     `- exits the callee method through RethrowException node
          |- The callee pushes exception_oop(T0) and exception_pc(RA)
          `- The callee jumps to OptoRuntime::rethrow_stub()
  * In OptoRuntime::rethrow_stub:
     |- The VM calls _rethrow_Java to determine the return address in the caller method
     `- exits the stub with tailjmpInd
          |- pops exception_oop(V0) and exception_pc(V1)
          `- jumps to the return address(usually an exception_handler)
  * The caller:
     `- continues processing the exception_blob with V0/V1
*/

/*
Disassembling OptoRuntime::rethrow_stub()

; locals
   0x2d3bf320: addiu sp, sp, 0xfffffff8
   0x2d3bf324: sw ra, 0x4(sp)
   0x2d3bf328: sw fp, 0x0(sp)
   0x2d3bf32c: addu fp, sp, zero
   0x2d3bf330: addiu sp, sp, 0xfffffff0
   0x2d3bf334: sw ra, 0x8(sp)
   0x2d3bf338: sw t0, 0x4(sp)
   0x2d3bf33c: sw sp, 0x0(sp)

; get_thread(S2)
   0x2d3bf340: addu s2, sp, zero
   0x2d3bf344: srl s2, s2, 12
   0x2d3bf348: sll s2, s2, 2
   0x2d3bf34c: lui at, 0x2c85
   0x2d3bf350: addu at, at, s2
   0x2d3bf354: lw s2, 0xffffcc80(at)

   0x2d3bf358: lw s0, 0x0(sp)
   0x2d3bf35c: sw s0, 0x118(s2)		// last_sp -> threa
   0x2d3bf360: sw s2, 0xc(sp)

; OptoRuntime::rethrow_C(oopDesc* exception, JavaThread* thread, address ret_pc)
   0x2d3bf364: lw a0, 0x4(sp)
   0x2d3bf368: lw a1, 0xc(sp)
   0x2d3bf36c: lw a2, 0x8(sp)
  ;; Java_To_Runtime
   0x2d3bf370: lui t9, 0x2c34
   0x2d3bf374: addiu t9, t9, 0xffff8a48
   0x2d3bf378: jalr t9
   0x2d3bf37c: nop

   0x2d3bf380: addu s3, v0, zero		 ; S3: SharedRuntime::raw_exception_handler_for_return_address()

   0x2d3bf384: lw s0, 0xc(sp)
   0x2d3bf388: sw zero, 0x118(s0)
   0x2d3bf38c: sw zero, 0x11c(s0)
   0x2d3bf390: lw s1, 0x144(s0)			; ex_oop: S1
   0x2d3bf394: addu s2, s0, zero
   0x2d3bf398: sw zero, 0x144(s2)
   0x2d3bf39c: lw s0, 0x4(s2)
   0x2d3bf3a0: addiu s4, zero, 0x0
   0x2d3bf3a4: bne s0, s4, 0x2d3bf3d4
   0x2d3bf3a8: nop
   0x2d3bf3ac: addiu sp, sp, 0x10
   0x2d3bf3b0: addiu sp, sp, 0x8
   0x2d3bf3b4: lw ra, 0xfffffffc(sp)
   0x2d3bf3b8: lw fp, 0xfffffff8(sp)
   0x2d3bf3bc: lui at, 0x2b48
   0x2d3bf3c0: lw at, 0x100(at)

; tailjmpInd: Restores exception_oop & exception_pc
   0x2d3bf3c4: addu v1, ra, zero
   0x2d3bf3c8: addu v0, s1, zero
   0x2d3bf3cc: jr s3
   0x2d3bf3d0: nop
; Exception:
   0x2d3bf3d4: lui s1, 0x2cc8		; generate_forward_exception()
   0x2d3bf3d8: addiu s1, s1, 0x40
   0x2d3bf3dc: addiu s2, zero, 0x0
   0x2d3bf3e0: addiu sp, sp, 0x10
   0x2d3bf3e4: addiu sp, sp, 0x8
   0x2d3bf3e8: lw ra, 0xfffffffc(sp)
   0x2d3bf3ec: lw fp, 0xfffffff8(sp)
   0x2d3bf3f0: lui at, 0x2b48
   0x2d3bf3f4: lw at, 0x100(at)
; TailCalljmpInd 
              __ push(RA);		; to be used in generate_forward_exception()
   0x2d3bf3f8: addu t7, s2, zero
   0x2d3bf3fc: jr s1
   0x2d3bf400: nop
*/
// Rethrow exception:
// The exception oop will come in the first argument position.
// Then JUMP (not call) to the rethrow stub code.
instruct RethrowException()
%{
  match(Rethrow);

  // use the following format syntax
  format %{ "JMP    rethrow_stub #@RethrowException" %}
  ins_encode %{
    __ block_comment("@ RethrowException");

    cbuf.set_insts_mark();
    cbuf.relocate(cbuf.insts_mark(), runtime_call_Relocation::spec());

    // call OptoRuntime::rethrow_stub to get the exception handler in parent method
    __ li(T9, OptoRuntime::rethrow_stub());
    __ jr(T9);
    __ nop();
  %}
  ins_pipe( pipe_jump );
%}

instruct branchConP_zero(cmpOpU cmp, mRegP op1, immP0 zero, label labl) %{
  match(If cmp (CmpP op1 zero));
  effect(USE labl);

  ins_cost(180);
  format %{ "b$cmp   $op1, R0, $labl #@branchConP_zero" %}

  ins_encode %{
    Register op1 = $op1$$Register;
    Register op2 = R0;
    Label    &L  = *($labl$$label);
    int     flag = $cmp$$cmpcode;

    switch(flag)
    {
      case 0x01: //equal
	if (&L)
        	__ beq(op1, op2, L); 
	else 
        	__ beq(op1, op2, (int)0); 
        break;
      case 0x02: //not_equal
	if (&L)
        	__ bne(op1, op2, L); 
	else
        	__ bne(op1, op2, (int)0); 
        break;
/*
      case 0x03: //above
        __ sltu(AT, op2, op1);
        if(&L)
        	__ bne(R0, AT, L); 
        else
                __ bne(R0, AT, (int)0);
        break;
      case 0x04: //above_equal
        __ sltu(AT, op1, op2);
        if(&L)
       	        __ beq(AT, R0, L);
        else
       	        __ beq(AT, R0, (int)0);
        break;
      case 0x05: //below
        __ sltu(AT, op1, op2);
        if(&L)
      		 __ bne(R0, AT, L); 
        else
        	 __ bne(R0, AT, (int)0);
        break;
      case 0x06: //below_equal
        __ sltu(AT, op2, op1);
        if(&L)
        	__ beq(AT, R0, L);
        else
        	__ beq(AT, R0, (int)0);
       break;
*/
      default:
          Unimplemented();
    }  
    __ nop();
  %}

  ins_pc_relative(1);
  ins_pipe( pipe_alu_branch );
%}


instruct branchConP(cmpOpU cmp, mRegP op1, mRegP op2, label labl) %{
  match(If cmp (CmpP op1 op2));
//  predicate(can_branch_register(_kids[0]->_leaf, _kids[1]->_leaf));
  effect(USE labl);

  ins_cost(200);
  format %{ "b$cmp   $op1, $op2, $labl #@branchConP" %}

  ins_encode %{
    Register op1 = $op1$$Register;
    Register op2 = $op2$$Register;
    Label    &L  = *($labl$$label);
    int     flag = $cmp$$cmpcode;

    switch(flag)
    {
      case 0x01: //equal
	if (&L)
        	__ beq(op1, op2, L); 
	else 
        	__ beq(op1, op2, (int)0); 
        break;
      case 0x02: //not_equal
	if (&L)
        	__ bne(op1, op2, L); 
	else
        	__ bne(op1, op2, (int)0); 
        break;
      case 0x03: //above
        __ sltu(AT, op2, op1);
        if(&L)
        	__ bne(R0, AT, L); 
        else
                __ bne(R0, AT, (int)0);
        break;
      case 0x04: //above_equal
        __ sltu(AT, op1, op2);
        if(&L)
       	        __ beq(AT, R0, L);
        else
       	        __ beq(AT, R0, (int)0);
        break;
      case 0x05: //below
        __ sltu(AT, op1, op2);
        if(&L)
      		 __ bne(R0, AT, L); 
        else
        	 __ bne(R0, AT, (int)0);
        break;
      case 0x06: //below_equal
        __ sltu(AT, op2, op1);
        if(&L)
        	__ beq(AT, R0, L);
        else
        	__ beq(AT, R0, (int)0);
       break;
      default:
          Unimplemented();
    }  
    __ nop();
  %}

  ins_pc_relative(1);
  ins_pipe( pipe_alu_branch );
%}

instruct cmpN_null_branch(cmpOp cmp, mRegN op1, immN0 null, label labl) %{
  match(If cmp (CmpN op1 null));
  effect(USE labl);

  ins_cost(180);
  format %{ "CMP    $op1,0\t! compressed ptr\n\t"
            "BP$cmp   $labl" %}
  ins_encode %{
    Register op1 = $op1$$Register;
    Register op2 = R0;
    Label    &L  = *($labl$$label);
    int     flag = $cmp$$cmpcode;

    switch(flag)
    {
		case 0x01: //equal
			if (&L)
				__ beq(op1, op2, L); 
			else 
				__ beq(op1, op2, (int)0); 
			break;
		case 0x02: //not_equal
			if (&L)
				__ bne(op1, op2, L); 
			else
				__ bne(op1, op2, (int)0); 
			break;
		default:
          Unimplemented();
    }  
    __ nop();
  %}
//TODO: pipe_branchP or create pipe_branchN LEE
  ins_pc_relative(1);
  ins_pipe( pipe_alu_branch );
%}

instruct cmpN_reg_branch(cmpOp cmp, mRegN op1, mRegN op2, label labl) %{
  match(If cmp (CmpN op1 op2));
  effect(USE labl);

  ins_cost(180);
  format %{ "CMP    $op1,$op2\t! compressed ptr\n\t"
            "BP$cmp   $labl" %}
  ins_encode %{
    Register op1_reg = $op1$$Register;
    Register op2_reg = $op2$$Register;
    Label    &L  = *($labl$$label);
    int     flag = $cmp$$cmpcode;

    switch(flag)
    {
		case 0x01: //equal
			if (&L)
				__ beq(op1_reg, op2_reg, L); 
			else 
				__ beq(op1_reg, op2_reg, (int)0); 
			break;
		case 0x02: //not_equal
			if (&L)
				__ bne(op1_reg, op2_reg, L); 
			else
				__ bne(op1_reg, op2_reg, (int)0); 
			break;
		case 0x03: //above
			__ sltu(AT, op2_reg, op1_reg);
			if(&L)
				__ bne(R0, AT, L); 
			else
				__ bne(R0, AT, (int)0);
			break;
		case 0x04: //above_equal
			__ sltu(AT, op1_reg, op2_reg);
			if(&L)
				__ beq(AT, R0, L);
			else
				__ beq(AT, R0, (int)0);
			break;
		case 0x05: //below
			__ sltu(AT, op1_reg, op2_reg);
			if(&L)
				__ bne(R0, AT, L); 
			else
				__ bne(R0, AT, (int)0);
			break;
		case 0x06: //below_equal
			__ sltu(AT, op2_reg, op1_reg);
			if(&L)
				__ beq(AT, R0, L);
			else
				__ beq(AT, R0, (int)0);
			break;
		default:
          Unimplemented();
    }  
    __ nop();
  %}
  ins_pc_relative(1);
  ins_pipe( pipe_alu_branch );
%}

instruct branchConIU_reg_reg(cmpOpU cmp, mRegI src1, mRegI src2, label labl) %{
  match( If cmp (CmpU src1 src2) );
  effect(USE labl);
  format %{ "BR$cmp   $src1, $src2, $labl #@branchConIU_reg_reg" %}

  ins_encode %{
    Register op1 = $src1$$Register;
    Register op2 = $src2$$Register;
    Label     &L = *($labl$$label);
    int     flag = $cmp$$cmpcode;

    switch(flag)
    {
      case 0x01: //equal
	if (&L)
        	__ beq(op1, op2, L); 
	else 
        	__ beq(op1, op2, (int)0); 
        break;
      case 0x02: //not_equal
	if (&L)
        	__ bne(op1, op2, L); 
	else
        	__ bne(op1, op2, (int)0); 
        break;
      case 0x03: //above
        __ sltu(AT, op2, op1);
        if(&L)
        	__ bne(AT, R0, L); 
        else
                __ bne(AT, R0, (int)0);
        break;
      case 0x04: //above_equal
        __ sltu(AT, op1, op2);
        if(&L)
        	__ beq(AT, R0, L);
        else
                __ beq(AT, R0, (int)0);
        break;
      case 0x05: //below
        __ sltu(AT, op1, op2);
        if(&L)
      		 __ bne(AT, R0, L); 
        else
        	 __ bne(AT, R0, (int)0);
        break;
      case 0x06: //below_equal
        __ sltu(AT, op2, op1);
        if(&L)
        	__ beq(AT, R0, L);
        else
        	__ beq(AT, R0, (int)0);
        break;
      default:
          Unimplemented();
    }  
    __ nop();
  %}

  ins_pc_relative(1);
  ins_pipe( pipe_alu_branch );
%}


instruct branchConIU_reg_imm(cmpOpU cmp, mRegI src1, immI src2, label labl) %{
  match( If cmp (CmpU src1 src2) );
  effect(USE labl);
  format %{ "BR$cmp   $src1, $src2, $labl #@branchConIU_reg_imm" %}

  ins_encode %{
    Register op1 = $src1$$Register;
    int      val = $src2$$constant;
    Label     &L = *($labl$$label);
    int     flag = $cmp$$cmpcode;

    __ move(AT, val);
    switch(flag)
    {
      case 0x01: //equal
	if (&L)
        	__ beq(op1, AT, L); 
	else 
        	__ beq(op1, AT, (int)0); 
        break;
      case 0x02: //not_equal
	if (&L)
        	__ bne(op1, AT, L); 
	else
        	__ bne(op1, AT, (int)0); 
        break;
      case 0x03: //above
        __ sltu(AT, AT, op1);
        if(&L)
        	__ bne(R0, AT, L); 
        else
                __ bne(R0, AT, (int)0);
        break;
      case 0x04: //above_equal
        __ sltu(AT, op1, AT);
        if(&L)
        	__ beq(AT, R0, L);
        else
                __ beq(AT, R0, (int)0);
        break;
      case 0x05: //below
        __ sltu(AT, op1, AT);
        if(&L)
      		 __ bne(R0, AT, L); 
        else
        	 __ bne(R0, AT, (int)0);
        break;
      case 0x06: //below_equal
        __ sltu(AT, AT, op1);
        if(&L)
        	__ beq(AT, R0, L);
        else
        	__ beq(AT, R0, (int)0);
       break;
      default:
          Unimplemented();
    }  
    __ nop();
  %}

  ins_pc_relative(1);
  ins_pipe( pipe_alu_branch );
%}

instruct branchConI_reg_reg(cmpOp cmp, mRegI src1, mRegI src2, label labl) %{
  match( If cmp (CmpI src1 src2) );
  effect(USE labl);
  format %{ "BR$cmp   $src1, $src2, $labl #@branchConI_reg_reg" %}

  ins_encode %{
    Register op1 = $src1$$Register;
    Register op2 = $src2$$Register;
    Label     &L = *($labl$$label);
    int     flag = $cmp$$cmpcode;

    switch(flag)
    {
      case 0x01: //equal
	if (&L)
        	__ beq(op1, op2, L); 
	else 
        	__ beq(op1, op2, (int)0); 
        break;
      case 0x02: //not_equal
	if (&L)
        	__ bne(op1, op2, L); 
	else
        	__ bne(op1, op2, (int)0); 
        break;
      case 0x03: //above
        __ slt(AT, op2, op1);
        if(&L)
        	__ bne(R0, AT, L); 
        else
                __ bne(R0, AT, (int)0);
        break;
      case 0x04: //above_equal
        __ slt(AT, op1, op2);
        if(&L)
        	__ beq(AT, R0, L);
        else
                __ beq(AT, R0, (int)0);
        break;
      case 0x05: //below
        __ slt(AT, op1, op2);
        if(&L)
      		 __ bne(R0, AT, L); 
        else
        	 __ bne(R0, AT, (int)0);
        break;
      case 0x06: //below_equal
        __ slt(AT, op2, op1);
        if(&L)
        	__ beq(AT, R0, L);
        else
        	__ beq(AT, R0, (int)0);
       break;
      default:
          Unimplemented();
    }  
    __ nop();
  %}

  ins_pc_relative(1);
  ins_pipe( pipe_alu_branch );
%}

instruct branchConI_reg_imm0(cmpOp cmp, mRegI src1, immI0 src2, label labl) %{
  match( If cmp (CmpI src1 src2) );
  effect(USE labl);
  ins_cost(170);
  format %{ "BR$cmp   $src1, $src2, $labl #@branchConI_reg_imm0" %}

  ins_encode %{
    Register op1 = $src1$$Register;
//    int      val = $src2$$constant;
    Label     &L =  *($labl$$label);
    int     flag = $cmp$$cmpcode;

    //__ move(AT, val);
    switch(flag)
    {
      case 0x01: //equal
	if (&L)
        	__ beq(op1, R0, L); 
	else 
        	__ beq(op1, R0, (int)0); 
        break;
      case 0x02: //not_equal
	if (&L)
        	__ bne(op1, R0, L); 
	else
        	__ bne(op1, R0, (int)0); 
        break;
      case 0x03: //greater
        if(&L)
               __ bgtz(op1, L);
        else
               __ bgtz(op1, (int)0);
        break;
      case 0x04: //greater_equal
        if(&L)
               __ bgez(op1, L);
        else
               __ bgez(op1, (int)0);
        break;
      case 0x05: //less
        if(&L)
                __ bltz(op1, L);
        else
                __ bltz(op1, (int)0);
        break;
      case 0x06: //less_equal
        if(&L)
               __ blez(op1, L);
        else
               __ blez(op1, (int)0);
       break;
      default:
          Unimplemented();
    }  
    __ nop();
  %}

  ins_pc_relative(1);
  ins_pipe( pipe_alu_branch );
%}


instruct branchConI_reg_imm(cmpOp cmp, mRegI src1, immI src2, label labl) %{
  match( If cmp (CmpI src1 src2) );
  effect(USE labl);
  ins_cost(200);
  format %{ "BR$cmp   $src1, $src2, $labl #@branchConI_reg_imm" %}

  ins_encode %{
    Register op1 = $src1$$Register;
    int      val = $src2$$constant;
    Label     &L =  *($labl$$label);
    int     flag = $cmp$$cmpcode;

    __ move(AT, val);
    switch(flag)
    {
      case 0x01: //equal
	if (&L)
        	__ beq(op1, AT, L); 
	else 
        	__ beq(op1, AT, (int)0); 
        break;
      case 0x02: //not_equal
	if (&L)
        	__ bne(op1, AT, L); 
	else
        	__ bne(op1, AT, (int)0); 
        break;
      case 0x03: //greater
        __ slt(AT, AT, op1);
        if(&L)
        	__ bne(R0, AT, L); 
        else
                __ bne(R0, AT, (int)0);
        break;
      case 0x04: //greater_equal
        __ slt(AT, op1, AT);
        if(&L)
        	__ beq(AT, R0, L);
        else
                __ beq(AT, R0, (int)0);
        break;
      case 0x05: //less
        __ slt(AT, op1, AT);
        if(&L)
      		 __ bne(R0, AT, L); 
        else
        	 __ bne(R0, AT, (int)0);
        break;
      case 0x06: //less_equal
        __ slt(AT, AT, op1);
        if(&L)
        	__ beq(AT, R0, L);
        else
        	__ beq(AT, R0, (int)0);
       break;
      default:
          Unimplemented();
    }  
    __ nop();
  %}

  ins_pc_relative(1);
  ins_pipe( pipe_alu_branch );
%}

instruct branchConIU_reg_imm0(cmpOpU cmp, mRegI src1, immI0 zero, label labl) %{
  match( If cmp (CmpU src1 zero) );
  effect(USE labl);
  format %{ "BR$cmp   $src1, zero, $labl #@branchConIU_reg_imm0" %}

  ins_encode %{
    Register op1 = $src1$$Register;
    Label     &L = *($labl$$label);
    int     flag = $cmp$$cmpcode;

    switch(flag)
    {
      case 0x01: //equal
       if (&L)
               __ beq(op1, R0, L); 
       else 
               __ beq(op1, R0, (int)0); 
        break;
      case 0x02: //not_equal
       if (&L)
               __ bne(op1, R0, L); 
       else
               __ bne(op1, R0, (int)0); 
        break;
      case 0x03: //above
        if(&L)
               __ bne(R0, op1, L); 
        else
                __ bne(R0, op1, (int)0);
        break;
      case 0x04: //above_equal
        if(&L)
               __ beq(R0, R0, L);
        else
                __ beq(R0, R0, (int)0);
        break;
      case 0x05: //below
        return;
        break;
      case 0x06: //below_equal
        if(&L)
               __ beq(op1, R0, L);
        else
               __ beq(op1, R0, (int)0);
       break;
      default:
          Unimplemented();
    }  
    __ nop();
  %}

  ins_pc_relative(1);
  ins_pipe( pipe_alu_branch );
%}


instruct branchConIU_reg_immI16(cmpOpU cmp, mRegI src1, immI16 src2, label labl) %{
  match( If cmp (CmpU src1 src2) );
  effect(USE labl);
  ins_cost(180);
  format %{ "BR$cmp   $src1, $src2, $labl #@branchConIU_reg_immI16" %}

  ins_encode %{
    Register op1 = $src1$$Register;
    int      val = $src2$$constant;
    Label     &L = *($labl$$label);
    int     flag = $cmp$$cmpcode;

    switch(flag)
    {
      case 0x01: //equal
        __ move(AT, val);
       if (&L)
               __ beq(op1, AT, L); 
       else 
               __ beq(op1, AT, (int)0); 
        break;
      case 0x02: //not_equal
        __ move(AT, val);
       if (&L)
               __ bne(op1, AT, L); 
       else
               __ bne(op1, AT, (int)0); 
        break;
      case 0x03: //above
        __ move(AT, val);
        __ sltu(AT, AT, op1);
        if(&L)
               __ bne(R0, AT, L); 
        else
                __ bne(R0, AT, (int)0);
        break;
      case 0x04: //above_equal
        __ sltiu(AT, op1, val);
        if(&L)
               __ beq(AT, R0, L);
        else
                __ beq(AT, R0, (int)0);
        break;
      case 0x05: //below
        __ sltiu(AT, op1, val);
        if(&L)
                __ bne(R0, AT, L); 
        else
                __ bne(R0, AT, (int)0);
        break;
      case 0x06: //below_equal
        __ move(AT, val);
        __ sltu(AT, AT, op1);
        if(&L)
               __ beq(AT, R0, L);
        else
               __ beq(AT, R0, (int)0);
       break;
      default:
          Unimplemented();
    }  
    __ nop();
  %}

  ins_pc_relative(1);
  ins_pipe( pipe_alu_branch );
%}


instruct branchConL_regL_regL(cmpOp cmp, mRegL src1, mRegL src2, label labl) %{
  match( If cmp (CmpL src1 src2) );
  effect(USE labl);
  format %{ "BR$cmp   $src1, $src2, $labl #@branchConL_regL_regL" %}
  ins_cost(250);

  ins_encode %{
    Register opr1_reg = as_Register($src1$$reg);
    Register opr2_reg = as_Register($src2$$reg);

    Label   &target = *($labl$$label);
    int     flag = $cmp$$cmpcode;

    switch(flag)
    {
      case 0x01: //equal
        if (&target) 
			__ beq(opr1_reg, opr2_reg, target);
        else
			__ beq(opr1_reg, opr2_reg, (int)0);
        __ delayed()->nop();
        break;

      case 0x02: //not_equal
        if(&target)
           __ bne(opr1_reg, opr2_reg, target);
        else
           __ bne(opr1_reg, opr2_reg, (int)0);
        __ delayed()->nop();
        break;

      case 0x03: //greater
        __ slt(AT, opr2_reg, opr1_reg);
        if(&target)
           __ bne(AT, R0, target);
        else
           __ bne(AT, R0, (int)0);
        __ delayed()->nop();
        break;

      case 0x04: //greater_equal
        __ slt(AT, opr1_reg, opr2_reg);
        if(&target)
           __ beq(AT, R0, target);
        else
           __ beq(AT, R0, (int)0);
        __ delayed()->nop();

        break;

      case 0x05: //less
        __ slt(AT, opr1_reg, opr2_reg);
        if(&target)
           __ bne(AT, R0, target);
        else
           __ bne(AT, R0, (int)0);
        __ delayed()->nop();

        break;

      case 0x06: //less_equal
       __ slt(AT, opr2_reg, opr1_reg);

       if(&target)
          __ beq(AT, R0, target);
       else
          __ beq(AT, R0, (int)0);
       __ delayed()->nop();

       break;

      default:
          Unimplemented();
    }  
  %}


  ins_pc_relative(1);
  ins_pipe( pipe_alu_branch );
%}

instruct branchConI_reg_imm16_sub(cmpOp cmp, mRegI src1, immI16_sub src2, label labl) %{
  match( If cmp (CmpI src1 src2) );
  effect(USE labl);
  ins_cost(180);
  format %{ "BR$cmp   $src1, $src2, $labl #@branchConI_reg_imm16_sub" %}

  ins_encode %{
    Register op1 = $src1$$Register;
    int      val = $src2$$constant;
    Label     &L =  *($labl$$label);
    int     flag = $cmp$$cmpcode;

    __ addiu32(AT, op1, -1 * val);
    switch(flag)
    {
      case 0x01: //equal
       if (&L)
               __ beq(R0, AT, L); 
       else 
               __ beq(R0, AT, (int)0); 
        break;
      case 0x02: //not_equal
       if (&L)
               __ bne(R0, AT, L); 
       else
               __ bne(R0, AT, (int)0); 
        break;
      case 0x03: //greater
        if(&L)
               __ bgtz(AT, L); 
        else
                __ bgtz(AT, (int)0);
        break;
      case 0x04: //greater_equal
        if(&L)
               __ bgez(AT, L);
        else
                __ bgez(AT, (int)0);
        break;
      case 0x05: //less
        if(&L)
                __ bltz(AT, L); 
        else
                __ bltz(AT, (int)0);
        break;
      case 0x06: //less_equal
        if(&L)
               __ blez(AT, L);
        else
               __ blez(AT, (int)0);
       break;
      default:
          Unimplemented();
    }  
    __ nop();
  %}

  ins_pc_relative(1);
  ins_pipe( pipe_alu_branch );
%}

instruct branchConL_regL_immL0(cmpOp cmp, mRegL src1, immL0 zero, label labl) %{
  match( If cmp (CmpL src1 zero) );
  effect(USE labl);
  format %{ "BR$cmp   $src1, zero, $labl #@branchConL_regL_immL0" %}
  ins_cost(220);

  ins_encode %{
    Register opr1_reg = as_Register($src1$$reg);
    Label   &target = *($labl$$label);
    int     flag = $cmp$$cmpcode;

    switch(flag)
    {
      case 0x01: //equal
        if (&target) 
           __ beq(opr1_reg, R0, target);
        else
           __ beq(opr1_reg, R0, int(0));
        break;

      case 0x02: //not_equal
        if(&target)
           __ bne(opr1_reg, R0, target);
        else
           __ bne(opr1_reg, R0, (int)0);
        break;

      case 0x03: //greater
        if(&target)
           __ bgtz(opr1_reg, target);
        else
           __ bgtz(opr1_reg, (int)0);
       break;

      case 0x04: //greater_equal
        if(&target)
           __ bgez(opr1_reg, target);
        else
           __ bgez(opr1_reg, (int)0);
        break;

      case 0x05: //less
        __ slt(AT, opr1_reg, R0);
        if(&target)
           __ bne(AT, R0, target);
        else
           __ bne(AT, R0, (int)0);
        break;

      case 0x06: //less_equal
        if (&target) 
           __ blez(opr1_reg, target);
        else
           __ blez(opr1_reg, int(0));
        break;

      default:
          Unimplemented();
    }  
	__ delayed()->nop();
  %}


  ins_pc_relative(1);
  ins_pipe( pipe_alu_branch );
%}

/*
// Conditional Direct Branch
instruct branchCon(cmpOp cmp, flagsReg icc, label labl) %{
  match(If cmp icc);
  effect(USE labl);

  size(8);
  ins_cost(BRANCH_COST);
  format %{ "BP$cmp   $icc,$labl" %}
  // Prim = bits 24-22, Secnd = bits 31-30
  ins_encode( enc_bp( labl, cmp, icc ) );
  ins_pc_relative(1);
  ins_pipe(br_cc);
%}
*/

//FIXME
instruct branchConF_reg_reg(cmpOp cmp, regF src1, regF src2, label labl) %{
  match( If cmp (CmpF src1 src2) );
  effect(USE labl);
  format %{ "BR$cmp   $src1, $src2, $labl #@branchConF_reg_reg" %}

  ins_encode %{
    FloatRegister reg_op1 = $src1$$FloatRegister;
    FloatRegister reg_op2 = $src2$$FloatRegister;
    Label     &L =  *($labl$$label);
    int     flag = $cmp$$cmpcode;

    switch(flag)
    {
      case 0x01: //equal
        __ c_eq_s(reg_op1, reg_op2);
	if (&L)
                __ bc1t(L);
	else 
                __ bc1t((int)0);
        break;
      case 0x02: //not_equal
        __ c_ueq_s(reg_op1, reg_op2);
	if (&L)
                __ bc1f(L);
	else
                __ bc1f((int)0);
        break;
      case 0x03: //greater
        __ c_ule_s(reg_op1, reg_op2);
        if(&L)
                __ bc1f(L);
        else
                __ bc1f((int)0);
        break;
      case 0x04: //greater_equal
        __ c_ult_s(reg_op1, reg_op2);
        if(&L)
                __ bc1f(L);
        else
                __ bc1f((int)0);
        break;
      case 0x05: //less
        __ c_ult_s(reg_op1, reg_op2);
        if(&L)
                __ bc1t(L);
        else
                __ bc1t((int)0);
        break;
      case 0x06: //less_equal
        __ c_ule_s(reg_op1, reg_op2);
        if(&L)
                __ bc1t(L);
        else
                __ bc1t((int)0);
       break;
      default:
          Unimplemented();
    }  
    __ nop();
  %}

  ins_pc_relative(1);
  ins_pipe(pipe_slow);
%}

instruct branchConD_reg_reg(cmpOp cmp, regD src1, regD src2, label labl) %{
  match( If cmp (CmpD src1 src2) );
  effect(USE labl);
  format %{ "BR$cmp   $src1, $src2, $labl #@branchConD_reg_reg" %}

  ins_encode %{
    FloatRegister reg_op1 = $src1$$FloatRegister;
    FloatRegister reg_op2 = $src2$$FloatRegister;
    Label     &L =  *($labl$$label);
    int     flag = $cmp$$cmpcode;

    switch(flag)
    {
      case 0x01: //equal
        __ c_eq_d(reg_op1, reg_op2);
	if (&L)
                __ bc1t(L);
	else 
                __ bc1t((int)0);
        break;
      case 0x02: //not_equal
//2016/4/19 aoqi: c_ueq_d cannot distinguish NaN from equal. Double.isNaN(Double) is implemented by 'f != f', so the use of c_ueq_d causes bugs.
        __ c_eq_d(reg_op1, reg_op2);
	if (&L)
                __ bc1f(L);
	else
                __ bc1f((int)0);
        break;
      case 0x03: //greater
        __ c_ule_d(reg_op1, reg_op2);
        if(&L)
                __ bc1f(L);
        else
                __ bc1f((int)0);
        break;
      case 0x04: //greater_equal
        __ c_ult_d(reg_op1, reg_op2);
        if(&L)
                __ bc1f(L);
        else
                __ bc1f((int)0);
        break;
      case 0x05: //less
        __ c_ult_d(reg_op1, reg_op2);
        if(&L)
                __ bc1t(L);
        else
                __ bc1t((int)0);
        break;
      case 0x06: //less_equal
        __ c_ule_d(reg_op1, reg_op2);
        if(&L)
                __ bc1t(L);
        else
                __ bc1t((int)0);
       break;
      default:
          Unimplemented();
    }  
    __ nop();
  %}

  ins_pc_relative(1);
  ins_pipe(pipe_slow);
%}


// Call Runtime Instruction
instruct CallRuntimeDirect(method meth) %{
  match(CallRuntime );
  effect(USE meth);

  ins_cost(300);
  format %{ "CALL,runtime #@CallRuntimeDirect" %}
  ins_encode( Java_To_Runtime( meth ) );
  ins_pipe( pipe_slow );
  ins_alignment(16);
%}



//------------------------MemBar Instructions-------------------------------
//Memory barrier flavors

instruct membar_acquire() %{
  match(MemBarAcquire);
  match(LoadFence);
  ins_cost(400);

  format %{ "MEMBAR-acquire" %}
//  ins_encode( enc_membar_acquire );
  ins_encode %{
    __ sync(); 
  %}
  ins_pipe(pipe_slow);
%}

instruct membar_acquire_lock() %{
  match(MemBarAcquireLock);
  ins_cost(400);
  format %{ "MEMBAR-acquire (prior CMPXCHG in FastLock just sync)" %}
  ins_encode %{
    __ sync(); 
  %}
  ins_pipe(pipe_slow);
%}

instruct membar_release() %{
  match(MemBarRelease);
  match(StoreFence);
  ins_cost(400);

  format %{ "MEMBAR-release" %}

  ins_encode %{
    __ sync(); 
  %}

  ins_pipe(pipe_slow);
%}

instruct membar_release_lock() %{
  match(MemBarReleaseLock);
  ins_cost(400);
  format %{ "MEMBAR-release (a FastiUnlock follows so just sync)" %}

  ins_encode %{
    __ sync(); 
  %}
  ins_pipe(pipe_slow);
%}

instruct membar_volatile() %{
  match(MemBarVolatile);
  ins_cost(400);

  format %{ "MEMBAR-volatile" %}
/*  ins_encode( enc_membar_volatile ); */
  ins_encode %{
    if( !os::is_MP() ) return;     // Not needed on single CPU
    __ sync();

  %}
  ins_pipe(pipe_slow);
%}

instruct unnecessary_membar_volatile() %{
  match(MemBarVolatile);
  predicate(Matcher::post_store_load_barrier(n));
  ins_cost(400);
  format %{ "MEMBAR-volatile (unnecessary so just sync)" %}
  ins_encode %{
     __ sync();
  %}
  ins_pipe(pipe_slow);
%}
 
instruct membar_storestore() %{
  match(MemBarStoreStore);
  format %{ "MEMBAR-storestore (sync)" %}
  ins_encode %{
     __ sync();
  %}
  ins_cost(400);
  ins_pipe(pipe_slow);
%}

//----------Move Instructions--------------------------------------------------
instruct castX2P(mRegP dst, mRegL src) %{
  match(Set dst (CastX2P src));
  format %{ "castX2P  $dst, $src @ castX2P" %}
  ins_encode %{
    Register src = $src$$Register;
    Register dst = $dst$$Register;

	if(src != dst)
		__ move(dst, src);
  %}
  ins_cost(10);
  ins_pipe( ialu_regI_mov );
%}

instruct castP2X(mRegL dst, mRegP src ) %{
  match(Set dst (CastP2X src));

  format %{ "mov    $dst, $src\t  #@castP2X" %}
  ins_encode %{
    Register src = $src$$Register;
    Register dst = $dst$$Register;

	if(src != dst)
		__ move(dst, src);    
  %}
  ins_pipe( ialu_regI_mov );
%}

instruct MoveF2I_reg_reg(mRegI dst, regF src) %{
  match(Set dst (MoveF2I src));
  effect(DEF dst, USE src);
  ins_cost(85);
  format %{ "MoveF2I   $dst, $src @ MoveF2I_reg_reg" %}
  ins_encode %{
    Register dst = as_Register($dst$$reg);
    FloatRegister src = as_FloatRegister($src$$reg);

    __ mfc1(dst, src);
  %}
  ins_pipe( pipe_slow );
%}

instruct MoveI2F_reg_reg(regF dst, mRegI src) %{
  match(Set dst (MoveI2F src));
  effect(DEF dst, USE src);
  ins_cost(85);
  format %{ "MoveI2F   $dst, $src @ MoveI2F_reg_reg" %}
  ins_encode %{
    Register src = as_Register($src$$reg);
    FloatRegister dst = as_FloatRegister($dst$$reg);

    __ mtc1(src, dst);
  %}
  ins_pipe( pipe_slow );
%}

instruct MoveD2L_reg_reg(mRegL dst, regD src) %{
  match(Set dst (MoveD2L src));
  effect(DEF dst, USE src);
  ins_cost(85);
  format %{ "MoveD2L   $dst, $src @ MoveD2L_reg_reg" %}
  ins_encode %{
    Register dst = as_Register($dst$$reg);
    FloatRegister src = as_FloatRegister($src$$reg);

    __ dmfc1(dst, src);
  %}
  ins_pipe( pipe_slow );
%}

instruct MoveL2D_reg_reg(regD dst, mRegL src) %{
  match(Set dst (MoveL2D src));
  effect(DEF dst, USE src);
  ins_cost(85);
  format %{ "MoveL2D   $dst, $src @ MoveL2D_reg_reg" %}
  ins_encode %{
    FloatRegister dst = as_FloatRegister($dst$$reg);
    Register src = as_Register($src$$reg);

    __ dmtc1(src, dst);
  %}
  ins_pipe( pipe_slow );
%}

//----------Conditional Move---------------------------------------------------
// Conditional move
instruct cmovI_cmpI_reg_reg(mRegI dst, mRegI src, mRegI tmp1, mRegI tmp2, cmpOp cop ) %{
  match(Set dst (CMoveI (Binary cop (CmpI tmp1 tmp2)) (Binary dst src)));
  ins_cost(80);
  format %{
             "CMP$cop  $tmp1, $tmp2\t  @cmovI_cmpI_reg_reg\n"
             "\tCMOV  $dst,$src \t @cmovI_cmpI_reg_reg"
         %}

  ins_encode %{
    Register op1 = $tmp1$$Register;
    Register op2 = $tmp2$$Register;
    Register dst = $dst$$Register;
    Register src = $src$$Register;
    int     flag = $cop$$cmpcode;

    switch(flag)
    {
      case 0x01: //equal
        __ subu32(AT, op1, op2);
        __ movz(dst, src, AT);
        break;

      case 0x02: //not_equal
        __ subu32(AT, op1, op2);
        __ movn(dst, src, AT);
        break;

      case 0x03: //great
        __ slt(AT, op2, op1);
        __ movn(dst, src, AT);
        break;

      case 0x04: //great_equal
        __ slt(AT, op1, op2);
        __ movz(dst, src, AT);
        break;

      case 0x05: //less
        __ slt(AT, op1, op2);
        __ movn(dst, src, AT);
        break;

      case 0x06: //less_equal
        __ slt(AT, op2, op1);
        __ movz(dst, src, AT);
       break;

      default:
          Unimplemented();
    }  
  %}

  ins_pipe( pipe_slow );
%}

instruct cmovI_cmpP_reg_reg(mRegI dst, mRegI src, mRegP tmp1, mRegP tmp2, cmpOpU cop ) %{
  match(Set dst (CMoveI (Binary cop (CmpP tmp1 tmp2)) (Binary dst src)));
  ins_cost(80);
  format %{
             "CMPU$cop $tmp1,$tmp2\t @cmovI_cmpP_reg_reg\n\t"
             "CMOV $dst,$src\t @cmovI_cmpP_reg_reg"
         %}
  ins_encode %{
    Register op1 = $tmp1$$Register;
    Register op2 = $tmp2$$Register;
    Register dst = $dst$$Register;
    Register src = $src$$Register;
    int     flag = $cop$$cmpcode;

    switch(flag)
    {
      case 0x01: //equal
        __ subu(AT, op1, op2);
        __ movz(dst, src, AT);
        break;

      case 0x02: //not_equal
        __ subu(AT, op1, op2);
        __ movn(dst, src, AT);
        break;

      case 0x03: //above
        __ sltu(AT, op2, op1);
        __ movn(dst, src, AT);
        break;

      case 0x04: //above_equal
        __ sltu(AT, op1, op2);
        __ movz(dst, src, AT);
        break;

      case 0x05: //below
        __ sltu(AT, op1, op2);
        __ movn(dst, src, AT);
        break;

      case 0x06: //below_equal
        __ sltu(AT, op2, op1);
        __ movz(dst, src, AT);
       break;

      default:
          Unimplemented();
    }  
  %}

  ins_pipe( pipe_slow );
%}

instruct cmovI_cmpN_reg_reg(mRegI dst, mRegI src, mRegN tmp1, mRegN tmp2, cmpOpU cop ) %{
  match(Set dst (CMoveI (Binary cop (CmpN tmp1 tmp2)) (Binary dst src)));
  ins_cost(80);
  format %{
             "CMPU$cop $tmp1,$tmp2\t @cmovI_cmpN_reg_reg\n\t"
             "CMOV $dst,$src\t @cmovI_cmpN_reg_reg"
         %}
  ins_encode %{
    Register op1 = $tmp1$$Register;
    Register op2 = $tmp2$$Register;
    Register dst = $dst$$Register;
    Register src = $src$$Register;
    int     flag = $cop$$cmpcode;

    switch(flag)
    {
      case 0x01: //equal
        __ subu32(AT, op1, op2);
        __ movz(dst, src, AT);
        break;

      case 0x02: //not_equal
        __ subu32(AT, op1, op2);
        __ movn(dst, src, AT);
        break;

      case 0x03: //above
        __ sltu(AT, op2, op1);
        __ movn(dst, src, AT);
        break;

      case 0x04: //above_equal
        __ sltu(AT, op1, op2);
        __ movz(dst, src, AT);
        break;

      case 0x05: //below
        __ sltu(AT, op1, op2);
        __ movn(dst, src, AT);
        break;

      case 0x06: //below_equal
        __ sltu(AT, op2, op1);
        __ movz(dst, src, AT);
       break;

      default:
          Unimplemented();
    }  
  %}

  ins_pipe( pipe_slow );
%}

instruct cmovP_cmpN_reg_reg(mRegP dst, mRegP src, mRegN tmp1, mRegN tmp2, cmpOpU cop ) %{
  match(Set dst (CMoveP (Binary cop (CmpN tmp1 tmp2)) (Binary dst src)));
  ins_cost(80);
  format %{
             "CMPU$cop $tmp1,$tmp2\t @cmovP_cmpN_reg_reg\n\t"
             "CMOV $dst,$src\t @cmovP_cmpN_reg_reg"
         %}
  ins_encode %{
    Register op1 = $tmp1$$Register;
    Register op2 = $tmp2$$Register;
    Register dst = $dst$$Register;
    Register src = $src$$Register;
    int     flag = $cop$$cmpcode;

    switch(flag)
    {
      case 0x01: //equal
        __ subu32(AT, op1, op2);
        __ movz(dst, src, AT);
        break;

      case 0x02: //not_equal
        __ subu32(AT, op1, op2);
        __ movn(dst, src, AT);
        break;

      case 0x03: //above
        __ sltu(AT, op2, op1);
        __ movn(dst, src, AT);
        break;

      case 0x04: //above_equal
        __ sltu(AT, op1, op2);
        __ movz(dst, src, AT);
        break;

      case 0x05: //below
        __ sltu(AT, op1, op2);
        __ movn(dst, src, AT);
        break;

      case 0x06: //below_equal
        __ sltu(AT, op2, op1);
        __ movz(dst, src, AT);
       break;

      default:
          Unimplemented();
    }  
  %}

  ins_pipe( pipe_slow );
%}

instruct cmovN_cmpP_reg_reg(mRegN dst, mRegN src, mRegP tmp1, mRegP tmp2, cmpOpU cop ) %{
  match(Set dst (CMoveN (Binary cop (CmpP tmp1 tmp2)) (Binary dst src)));
  ins_cost(80);
  format %{
             "CMPU$cop $tmp1,$tmp2\t @cmovN_cmpP_reg_reg\n\t"
             "CMOV $dst,$src\t @cmovN_cmpP_reg_reg"
         %}
  ins_encode %{
    Register op1 = $tmp1$$Register;
    Register op2 = $tmp2$$Register;
    Register dst = $dst$$Register;
    Register src = $src$$Register;
    int     flag = $cop$$cmpcode;

    switch(flag)
    {
      case 0x01: //equal
        __ subu(AT, op1, op2);
        __ movz(dst, src, AT);
        break;

      case 0x02: //not_equal
        __ subu(AT, op1, op2);
        __ movn(dst, src, AT);
        break;

      case 0x03: //above
        __ sltu(AT, op2, op1);
        __ movn(dst, src, AT);
        break;

      case 0x04: //above_equal
        __ sltu(AT, op1, op2);
        __ movz(dst, src, AT);
        break;

      case 0x05: //below
        __ sltu(AT, op1, op2);
        __ movn(dst, src, AT);
        break;

      case 0x06: //below_equal
        __ sltu(AT, op2, op1);
        __ movz(dst, src, AT);
       break;

      default:
          Unimplemented();
    }  
  %}

  ins_pipe( pipe_slow );
%}

instruct cmovP_cmpD_reg_reg(mRegP dst, mRegP src, regD tmp1, regD tmp2, cmpOp cop ) %{
  match(Set dst (CMoveP (Binary cop (CmpD tmp1 tmp2)) (Binary dst src)));
  ins_cost(80);
  format %{
             "CMP$cop  $tmp1, $tmp2\t  @cmovP_cmpD_reg_reg\n"
             "\tCMOV  $dst,$src \t @cmovP_cmpD_reg_reg"
         %}
  ins_encode %{
    FloatRegister reg_op1 = as_FloatRegister($tmp1$$reg);
    FloatRegister reg_op2 = as_FloatRegister($tmp2$$reg);
    Register dst = as_Register($dst$$reg);
    Register src = as_Register($src$$reg);

    int     flag = $cop$$cmpcode;

    switch(flag)
    {
      case 0x01: //equal
        __ c_eq_d(reg_op1, reg_op2);
        __ movt(dst, src);
        break;
      case 0x02: //not_equal
        __ c_eq_d(reg_op1, reg_op2);
        __ movf(dst, src);
        break;
      case 0x03: //greater
        __ c_ole_d(reg_op1, reg_op2);
        __ movf(dst, src);
        break;
      case 0x04: //greater_equal
        __ c_olt_d(reg_op1, reg_op2);
        __ movf(dst, src);
        break;
      case 0x05: //less
        __ c_ult_d(reg_op1, reg_op2);
        __ movt(dst, src);
        break;
      case 0x06: //less_equal
        __ c_ule_d(reg_op1, reg_op2);
        __ movt(dst, src);
        break;
      default:
          Unimplemented();
    }  
  %}

  ins_pipe( pipe_slow );
%}


instruct cmovN_cmpN_reg_reg(mRegN dst, mRegN src, mRegN tmp1, mRegN tmp2, cmpOpU cop ) %{
  match(Set dst (CMoveN (Binary cop (CmpN tmp1 tmp2)) (Binary dst src)));
  ins_cost(80);
  format %{
             "CMPU$cop $tmp1,$tmp2\t @cmovN_cmpN_reg_reg\n\t"
             "CMOV $dst,$src\t @cmovN_cmpN_reg_reg"
         %}
  ins_encode %{
    Register op1 = $tmp1$$Register;
    Register op2 = $tmp2$$Register;
    Register dst = $dst$$Register;
    Register src = $src$$Register;
    int     flag = $cop$$cmpcode;

    switch(flag)
    {
      case 0x01: //equal
        __ subu32(AT, op1, op2);
        __ movz(dst, src, AT);
        break;

      case 0x02: //not_equal
        __ subu32(AT, op1, op2);
        __ movn(dst, src, AT);
        break;

      case 0x03: //above
        __ sltu(AT, op2, op1);
        __ movn(dst, src, AT);
        break;

      case 0x04: //above_equal
        __ sltu(AT, op1, op2);
        __ movz(dst, src, AT);
        break;

      case 0x05: //below
        __ sltu(AT, op1, op2);
        __ movn(dst, src, AT);
        break;

      case 0x06: //below_equal
        __ sltu(AT, op2, op1);
        __ movz(dst, src, AT);
       break;

      default:
          Unimplemented();
    }  
  %}

  ins_pipe( pipe_slow );
%}


instruct cmovI_cmpU_reg_reg(mRegI dst, mRegI src, mRegI tmp1, mRegI tmp2, cmpOpU cop ) %{
  match(Set dst (CMoveI (Binary cop (CmpU tmp1 tmp2)) (Binary dst src)));
  ins_cost(80);
  format %{
             "CMPU$cop $tmp1,$tmp2\t @cmovI_cmpU_reg_reg\n\t"
             "CMOV $dst,$src\t @cmovI_cmpU_reg_reg"
         %}
  ins_encode %{
    Register op1 = $tmp1$$Register;
    Register op2 = $tmp2$$Register;
    Register dst = $dst$$Register;
    Register src = $src$$Register;
    int     flag = $cop$$cmpcode;

    switch(flag)
    {
      case 0x01: //equal
        __ subu(AT, op1, op2);
        __ movz(dst, src, AT);
        break;

      case 0x02: //not_equal
        __ subu(AT, op1, op2);
        __ movn(dst, src, AT);
        break;

      case 0x03: //above
        __ sltu(AT, op2, op1);
        __ movn(dst, src, AT);
        break;

      case 0x04: //above_equal
        __ sltu(AT, op1, op2);
        __ movz(dst, src, AT);
        break;

      case 0x05: //below
        __ sltu(AT, op1, op2);
        __ movn(dst, src, AT);
        break;

      case 0x06: //below_equal
        __ sltu(AT, op2, op1);
        __ movz(dst, src, AT);
       break;

      default:
          Unimplemented();
    }  
  %}

  ins_pipe( pipe_slow );
%}

instruct cmovI_cmpL_reg_reg(mRegI dst, mRegI src, mRegL tmp1, mRegL tmp2, cmpOp cop ) %{
  match(Set dst (CMoveI (Binary cop (CmpL tmp1 tmp2)) (Binary dst src)));
  ins_cost(80);
  format %{
             "CMP$cop  $tmp1, $tmp2\t  @cmovI_cmpL_reg_reg\n"
             "\tCMOV  $dst,$src \t @cmovI_cmpL_reg_reg"
         %}
  ins_encode %{
    Register opr1 = as_Register($tmp1$$reg);
    Register opr2 = as_Register($tmp2$$reg);
    Register dst     = $dst$$Register;
    Register src     = $src$$Register;
    int     flag = $cop$$cmpcode;

    switch(flag)
    {
      case 0x01: //equal
        __ subu(AT, opr1, opr2);
        __ movz(dst, src, AT);
        break;

      case 0x02: //not_equal
        __ subu(AT, opr1, opr2);
        __ movn(dst, src, AT);
        break;

      case 0x03: //greater
	__ slt(AT, opr2, opr1);
        __ movn(dst, src, AT);
        break;

      case 0x04: //greater_equal
        __ slt(AT, opr1, opr2);
        __ movz(dst, src, AT);
        break;

      case 0x05: //less
        __ slt(AT, opr1, opr2);
        __ movn(dst, src, AT);
        break;

      case 0x06: //less_equal
        __ slt(AT, opr2, opr1);
        __ movz(dst, src, AT);
        break;

      default:
          Unimplemented();
    }  
  %}

  ins_pipe( pipe_slow );
%}

instruct cmovP_cmpL_reg_reg(mRegP dst, mRegP src, mRegL tmp1, mRegL tmp2, cmpOp cop ) %{
  match(Set dst (CMoveP (Binary cop (CmpL tmp1 tmp2)) (Binary dst src)));
  ins_cost(80);
  format %{
             "CMP$cop  $tmp1, $tmp2\t  @cmovP_cmpL_reg_reg\n"
             "\tCMOV  $dst,$src \t @cmovP_cmpL_reg_reg"
         %}
  ins_encode %{
    Register opr1 = as_Register($tmp1$$reg);
    Register opr2 = as_Register($tmp2$$reg);
    Register dst     = $dst$$Register;
    Register src     = $src$$Register;
    int     flag = $cop$$cmpcode;

    switch(flag)
    {
      case 0x01: //equal
        __ subu(AT, opr1, opr2);
        __ movz(dst, src, AT);
        break;

      case 0x02: //not_equal
        __ subu(AT, opr1, opr2);
        __ movn(dst, src, AT);
        break;

      case 0x03: //greater
        __ slt(AT, opr2, opr1);
        __ movn(dst, src, AT);
        break;

      case 0x04: //greater_equal
        __ slt(AT, opr1, opr2);
        __ movz(dst, src, AT);
        break;

      case 0x05: //less
        __ slt(AT, opr1, opr2);
        __ movn(dst, src, AT);
        break;

      case 0x06: //less_equal
        __ slt(AT, opr2, opr1);
        __ movz(dst, src, AT);
        break;

      default:
          Unimplemented();
    }  
  %}

  ins_pipe( pipe_slow );
%}

instruct cmovI_cmpD_reg_reg(mRegI dst, mRegI src, regD tmp1, regD tmp2, cmpOp cop ) %{
  match(Set dst (CMoveI (Binary cop (CmpD tmp1 tmp2)) (Binary dst src)));
  ins_cost(80);
  format %{
             "CMP$cop  $tmp1, $tmp2\t  @cmovI_cmpD_reg_reg\n"
             "\tCMOV  $dst,$src \t @cmovI_cmpD_reg_reg"
         %}
  ins_encode %{
    FloatRegister reg_op1 = as_FloatRegister($tmp1$$reg);
    FloatRegister reg_op2 = as_FloatRegister($tmp2$$reg);
    Register dst = as_Register($dst$$reg);
    Register src = as_Register($src$$reg);

    int     flag = $cop$$cmpcode;

    switch(flag)
    {
      case 0x01: //equal
        __ c_eq_d(reg_op1, reg_op2);
        __ movt(dst, src);
        break;
      case 0x02: //not_equal
//2016/4/19 aoqi: See instruct branchConD_reg_reg. The change in branchConD_reg_reg fixed a bug. It seems similar here, so I made thesame change.
        __ c_eq_d(reg_op1, reg_op2);
        __ movf(dst, src);
        break;
      case 0x03: //greater
        __ c_ole_d(reg_op1, reg_op2);
        __ movf(dst, src);
        break;
      case 0x04: //greater_equal
        __ c_olt_d(reg_op1, reg_op2);
        __ movf(dst, src);
        break;
      case 0x05: //less
        __ c_ult_d(reg_op1, reg_op2);
        __ movt(dst, src);
        break;
      case 0x06: //less_equal
        __ c_ule_d(reg_op1, reg_op2);
        __ movt(dst, src);
        break;
      default:
          Unimplemented();
    }  
  %}

  ins_pipe( pipe_slow );
%}


instruct cmovP_cmpP_reg_reg(mRegP dst, mRegP src, mRegP tmp1, mRegP tmp2, cmpOpU cop ) %{
  match(Set dst (CMoveP (Binary cop (CmpP tmp1 tmp2)) (Binary dst src)));
  ins_cost(80);
  format %{
             "CMPU$cop $tmp1,$tmp2\t @cmovP_cmpP_reg_reg\n\t"
             "CMOV $dst,$src\t @cmovP_cmpP_reg_reg"
         %}
  ins_encode %{
    Register op1 = $tmp1$$Register;
    Register op2 = $tmp2$$Register;
    Register dst = $dst$$Register;
    Register src = $src$$Register;
    int     flag = $cop$$cmpcode;

    switch(flag)
    {
      case 0x01: //equal
        __ subu(AT, op1, op2);
        __ movz(dst, src, AT);
        break;

      case 0x02: //not_equal
        __ subu(AT, op1, op2);
        __ movn(dst, src, AT);
        break;

      case 0x03: //above
        __ sltu(AT, op2, op1);
        __ movn(dst, src, AT);
        break;

      case 0x04: //above_equal
        __ sltu(AT, op1, op2);
        __ movz(dst, src, AT);
        break;

      case 0x05: //below
        __ sltu(AT, op1, op2);
        __ movn(dst, src, AT);
        break;

      case 0x06: //below_equal
        __ sltu(AT, op2, op1);
        __ movz(dst, src, AT);
       break;

      default:
          Unimplemented();
    }  
  %}

  ins_pipe( pipe_slow );
%}

instruct cmovP_cmpI_reg_reg(mRegP dst, mRegP src, mRegI tmp1, mRegI tmp2, cmpOp cop ) %{
  match(Set dst (CMoveP (Binary cop (CmpI tmp1 tmp2)) (Binary dst src)));
  ins_cost(80);
  format %{
             "CMP$cop $tmp1,$tmp2\t @cmovP_cmpI_reg_reg\n\t"
             "CMOV $dst,$src\t @cmovP_cmpI_reg_reg"
         %}
  ins_encode %{
    Register op1 = $tmp1$$Register;
    Register op2 = $tmp2$$Register;
    Register dst = $dst$$Register;
    Register src = $src$$Register;
    int     flag = $cop$$cmpcode;

    switch(flag)
    {
      case 0x01: //equal
        __ subu32(AT, op1, op2);
        __ movz(dst, src, AT);
        break;

      case 0x02: //not_equal
        __ subu32(AT, op1, op2);
        __ movn(dst, src, AT);
        break;

      case 0x03: //above
        __ slt(AT, op2, op1);
        __ movn(dst, src, AT);
        break;

      case 0x04: //above_equal
        __ slt(AT, op1, op2);
        __ movz(dst, src, AT);
        break;

      case 0x05: //below
        __ slt(AT, op1, op2);
        __ movn(dst, src, AT);
        break;

      case 0x06: //below_equal
        __ slt(AT, op2, op1);
        __ movz(dst, src, AT);
       break;

      default:
          Unimplemented();
    }  
  %}

  ins_pipe( pipe_slow );
%}

instruct cmovN_cmpI_reg_reg(mRegN dst, mRegN src, mRegI tmp1, mRegI tmp2, cmpOp cop ) %{
  match(Set dst (CMoveN (Binary cop (CmpI tmp1 tmp2)) (Binary dst src)));
  ins_cost(80);
  format %{
             "CMP$cop $tmp1,$tmp2\t @cmovN_cmpI_reg_reg\n\t"
             "CMOV $dst,$src\t @cmovN_cmpI_reg_reg"
         %}
  ins_encode %{
    Register op1 = $tmp1$$Register;
    Register op2 = $tmp2$$Register;
    Register dst = $dst$$Register;
    Register src = $src$$Register;
    int     flag = $cop$$cmpcode;

    switch(flag)
    {
      case 0x01: //equal
        __ subu32(AT, op1, op2);
        __ movz(dst, src, AT);
        break;

      case 0x02: //not_equal
        __ subu32(AT, op1, op2);
        __ movn(dst, src, AT);
        break;

      case 0x03: //above
        __ slt(AT, op2, op1);
        __ movn(dst, src, AT);
        break;

      case 0x04: //above_equal
        __ slt(AT, op1, op2);
        __ movz(dst, src, AT);
        break;

      case 0x05: //below
        __ slt(AT, op1, op2);
        __ movn(dst, src, AT);
        break;

      case 0x06: //below_equal
        __ slt(AT, op2, op1);
        __ movz(dst, src, AT);
       break;

      default:
          Unimplemented();
    }  
  %}

  ins_pipe( pipe_slow );
%}


instruct cmovL_cmpI_reg_reg(mRegL dst, mRegL src, mRegI tmp1, mRegI tmp2, cmpOp cop ) %{
  match(Set dst (CMoveL (Binary cop (CmpI tmp1 tmp2)) (Binary dst src)));
  ins_cost(80);
  format %{
             "CMP$cop  $tmp1, $tmp2\t  @cmovL_cmpI_reg_reg\n"
             "\tCMOV  $dst,$src \t @cmovL_cmpI_reg_reg"
         %}

  ins_encode %{
    Register op1 = $tmp1$$Register;
    Register op2 = $tmp2$$Register;
    Register dst = as_Register($dst$$reg);
    Register src = as_Register($src$$reg);
    int     flag = $cop$$cmpcode;

    switch(flag)
    {
      case 0x01: //equal
        __ subu32(AT, op1, op2);
        __ movz(dst, src, AT);
        break;

      case 0x02: //not_equal
        __ subu32(AT, op1, op2);
        __ movn(dst, src, AT);
        break;

      case 0x03: //great
        __ slt(AT, op2, op1);
        __ movn(dst, src, AT);
        break;

      case 0x04: //great_equal
        __ slt(AT, op1, op2);
        __ movz(dst, src, AT);
        break;

      case 0x05: //less
        __ slt(AT, op1, op2);
        __ movn(dst, src, AT);
        break;

      case 0x06: //less_equal
        __ slt(AT, op2, op1);
        __ movz(dst, src, AT);
       break;

      default:
          Unimplemented();
    }  
  %}

  ins_pipe( pipe_slow );
%}

instruct cmovL_cmpL_reg_reg(mRegL dst, mRegL src, mRegL tmp1, mRegL tmp2, cmpOp cop ) %{
  match(Set dst (CMoveL (Binary cop (CmpL tmp1 tmp2)) (Binary dst src)));
  ins_cost(80);
  format %{
             "CMP$cop  $tmp1, $tmp2\t  @cmovL_cmpL_reg_reg\n"
             "\tCMOV  $dst,$src \t @cmovL_cmpL_reg_reg"
         %}
  ins_encode %{
    Register opr1 = as_Register($tmp1$$reg);
    Register opr2 = as_Register($tmp2$$reg);
    Register dst  = as_Register($dst$$reg);
    Register src  = as_Register($src$$reg);
    int     flag = $cop$$cmpcode;

    switch(flag)
    {
      case 0x01: //equal
        __ subu(AT, opr1, opr2);
        __ movz(dst, src, AT);
        break;

      case 0x02: //not_equal
        __ subu(AT, opr1, opr2);
        __ movn(dst, src, AT);
        break;

      case 0x03: //greater
        __ slt(AT, opr2, opr1);
        __ movn(dst, src, AT);
        break;

      case 0x04: //greater_equal
        __ slt(AT, opr1, opr2);
        __ movz(dst, src, AT);
        break;

      case 0x05: //less
        __ slt(AT, opr1, opr2);
        __ movn(dst, src, AT);
        break;

      case 0x06: //less_equal
       __ slt(AT, opr2, opr1);
       __ movz(dst, src, AT);
       break;

      default:
          Unimplemented();
    }  
  %}

  ins_pipe( pipe_slow );
%}

instruct cmovL_cmpN_reg_reg(mRegL dst, mRegL src, mRegN tmp1, mRegN tmp2, cmpOpU cop ) %{
  match(Set dst (CMoveL (Binary cop (CmpN tmp1 tmp2)) (Binary dst src)));
  ins_cost(80);
  format %{
             "CMPU$cop $tmp1,$tmp2\t @cmovL_cmpN_reg_reg\n\t"
             "CMOV $dst,$src\t @cmovL_cmpN_reg_reg"
         %}
  ins_encode %{
    Register op1 = $tmp1$$Register;
    Register op2 = $tmp2$$Register;
    Register dst = $dst$$Register;
    Register src = $src$$Register;
    int     flag = $cop$$cmpcode;

    switch(flag)
    {
      case 0x01: //equal
        __ subu32(AT, op1, op2);
        __ movz(dst, src, AT);
        break;

      case 0x02: //not_equal
        __ subu32(AT, op1, op2);
        __ movn(dst, src, AT);
        break;

      case 0x03: //above
        __ sltu(AT, op2, op1);
        __ movn(dst, src, AT);
        break;

      case 0x04: //above_equal
        __ sltu(AT, op1, op2);
        __ movz(dst, src, AT);
        break;

      case 0x05: //below
        __ sltu(AT, op1, op2);
        __ movn(dst, src, AT);
        break;

      case 0x06: //below_equal
        __ sltu(AT, op2, op1);
        __ movz(dst, src, AT);
        break;

      default:
          Unimplemented();
    }  
  %}

  ins_pipe( pipe_slow );
%}


instruct cmovL_cmpD_reg_reg(mRegL dst, mRegL src, regD tmp1, regD tmp2, cmpOp cop ) %{
  match(Set dst (CMoveL (Binary cop (CmpD tmp1 tmp2)) (Binary dst src)));
  ins_cost(80);
  format %{
             "CMP$cop  $tmp1, $tmp2\t  @cmovL_cmpD_reg_reg\n"
             "\tCMOV  $dst,$src \t @cmovL_cmpD_reg_reg"
         %}
  ins_encode %{
    FloatRegister reg_op1 = as_FloatRegister($tmp1$$reg);
    FloatRegister reg_op2 = as_FloatRegister($tmp2$$reg);
    Register dst = as_Register($dst$$reg);
    Register src = as_Register($src$$reg);

    int     flag = $cop$$cmpcode;

    switch(flag)
    {
      case 0x01: //equal
        __ c_eq_d(reg_op1, reg_op2);
        __ movt(dst, src);
        break;
      case 0x02: //not_equal
        __ c_eq_d(reg_op1, reg_op2);
        __ movf(dst, src);
        break;
      case 0x03: //greater
        __ c_ole_d(reg_op1, reg_op2);
        __ movf(dst, src);
        break;
      case 0x04: //greater_equal
        __ c_olt_d(reg_op1, reg_op2);
        __ movf(dst, src);
        break;
      case 0x05: //less
        __ c_ult_d(reg_op1, reg_op2);
        __ movt(dst, src);
        break;
      case 0x06: //less_equal
        __ c_ule_d(reg_op1, reg_op2);
        __ movt(dst, src);
        break;
      default:
          Unimplemented();
    }  
  %}

  ins_pipe( pipe_slow );
%}

instruct cmovD_cmpD_reg_reg(regD dst, regD src, regD tmp1, regD tmp2, cmpOp cop ) %{
  match(Set dst (CMoveD (Binary cop (CmpD tmp1 tmp2)) (Binary dst src)));
  ins_cost(200);
  format %{
             "CMP$cop  $tmp1, $tmp2\t  @cmovD_cmpD_reg_reg\n"
             "\tCMOV  $dst,$src \t @cmovD_cmpD_reg_reg"
         %}
  ins_encode %{
    FloatRegister reg_op1 = as_FloatRegister($tmp1$$reg);
    FloatRegister reg_op2 = as_FloatRegister($tmp2$$reg);
    FloatRegister dst = as_FloatRegister($dst$$reg);
    FloatRegister src = as_FloatRegister($src$$reg);

    int     flag = $cop$$cmpcode;

    Label L;

    switch(flag)
    {
      case 0x01: //equal
        __ c_eq_d(reg_op1, reg_op2);
        __ bc1f(L);
        __ nop();
        __ mov_d(dst, src);
        __ bind(L); 
        break;
      case 0x02: //not_equal
//2016/4/19 aoqi: See instruct branchConD_reg_reg. The change in branchConD_reg_reg fixed a bug. It seems similar here, so I made thesame change.
        __ c_eq_d(reg_op1, reg_op2);
        __ bc1t(L);
        __ nop();
        __ mov_d(dst, src);
        __ bind(L); 
        break;
      case 0x03: //greater
        __ c_ole_d(reg_op1, reg_op2);
        __ bc1t(L);
        __ nop();
        __ mov_d(dst, src);
        __ bind(L); 
        break;
      case 0x04: //greater_equal
        __ c_olt_d(reg_op1, reg_op2);
        __ bc1t(L);
        __ nop();
        __ mov_d(dst, src);
        __ bind(L); 
        break;
      case 0x05: //less
        __ c_ult_d(reg_op1, reg_op2);
        __ bc1f(L);
        __ nop();
        __ mov_d(dst, src);
        __ bind(L); 
        break;
      case 0x06: //less_equal
        __ c_ule_d(reg_op1, reg_op2);
        __ bc1f(L);
        __ nop();
        __ mov_d(dst, src);
        __ bind(L); 
        break;
      default:
          Unimplemented();
    }  
  %}

  ins_pipe( pipe_slow );
%}

instruct cmovF_cmpI_reg_reg(regF dst, regF src, mRegI tmp1, mRegI tmp2, cmpOp cop ) %{
  match(Set dst (CMoveF (Binary cop (CmpI tmp1 tmp2)) (Binary dst src)));
  ins_cost(200);
  format %{
             "CMP$cop  $tmp1, $tmp2\t  @cmovF_cmpI_reg_reg\n"
             "\tCMOV  $dst, $src \t @cmovF_cmpI_reg_reg"
         %}

  ins_encode %{
    Register op1 = $tmp1$$Register;
    Register op2 = $tmp2$$Register;
    FloatRegister dst = as_FloatRegister($dst$$reg);
    FloatRegister src = as_FloatRegister($src$$reg);
    int     flag = $cop$$cmpcode;
    Label      L; 

    switch(flag)
    {
      case 0x01: //equal
       	__ bne(op1, op2, L); 
        __ nop();
        __ mov_s(dst, src);
        __ bind(L);
        break;
      case 0x02: //not_equal
       	__ beq(op1, op2, L); 
        __ nop();
        __ mov_s(dst, src);
        __ bind(L);
        break;
      case 0x03: //great
        __ slt(AT, op2, op1);
       	__ beq(AT, R0, L);
        __ nop();
        __ mov_s(dst, src);
        __ bind(L);
        break;
      case 0x04: //great_equal
        __ slt(AT, op1, op2);
        __ bne(AT, R0, L); 
        __ nop();
        __ mov_s(dst, src);
        __ bind(L);
        break;
      case 0x05: //less
        __ slt(AT, op1, op2);
       	__ beq(AT, R0, L);
        __ nop();
        __ mov_s(dst, src);
        __ bind(L);
        break;
      case 0x06: //less_equal
        __ slt(AT, op2, op1);
       	__ bne(AT, R0, L); 
        __ nop();
        __ mov_s(dst, src);
        __ bind(L);
       break;
      default:
          Unimplemented();
    }  
  %}

  ins_pipe( pipe_slow );
%}

instruct cmovD_cmpI_reg_reg(regD dst, regD src, mRegI tmp1, mRegI tmp2, cmpOp cop ) %{
  match(Set dst (CMoveD (Binary cop (CmpI tmp1 tmp2)) (Binary dst src)));
  ins_cost(200);
  format %{
             "CMP$cop  $tmp1, $tmp2\t  @cmovD_cmpI_reg_reg\n"
             "\tCMOV  $dst, $src \t @cmovD_cmpI_reg_reg"
         %}

  ins_encode %{
    Register op1 = $tmp1$$Register;
    Register op2 = $tmp2$$Register;
    FloatRegister dst = as_FloatRegister($dst$$reg);
    FloatRegister src = as_FloatRegister($src$$reg);
    int     flag = $cop$$cmpcode;
    Label      L; 

    switch(flag)
    {
      case 0x01: //equal
       	__ bne(op1, op2, L); 
        __ nop();
        __ mov_d(dst, src);
        __ bind(L);
        break;
      case 0x02: //not_equal
       	__ beq(op1, op2, L); 
        __ nop();
        __ mov_d(dst, src);
        __ bind(L);
        break;
      case 0x03: //great
        __ slt(AT, op2, op1);
       	__ beq(AT, R0, L);
        __ nop();
        __ mov_d(dst, src);
        __ bind(L);
        break;
      case 0x04: //great_equal
        __ slt(AT, op1, op2);
        __ bne(AT, R0, L); 
        __ nop();
        __ mov_d(dst, src);
        __ bind(L);
        break;
      case 0x05: //less
        __ slt(AT, op1, op2);
       	__ beq(AT, R0, L);
        __ nop();
        __ mov_d(dst, src);
        __ bind(L);
        break;
      case 0x06: //less_equal
        __ slt(AT, op2, op1);
       	__ bne(AT, R0, L); 
        __ nop();
        __ mov_d(dst, src);
        __ bind(L);
       break;
      default:
          Unimplemented();
    }  
  %}

  ins_pipe( pipe_slow );
%}

instruct cmovD_cmpP_reg_reg(regD dst, regD src, mRegP tmp1, mRegP tmp2, cmpOp cop ) %{
  match(Set dst (CMoveD (Binary cop (CmpP tmp1 tmp2)) (Binary dst src)));
  ins_cost(200);
  format %{
             "CMP$cop  $tmp1, $tmp2\t  @cmovD_cmpP_reg_reg\n"
             "\tCMOV  $dst, $src \t @cmovD_cmpP_reg_reg"
         %}

  ins_encode %{
    Register op1 = $tmp1$$Register;
    Register op2 = $tmp2$$Register;
    FloatRegister dst = as_FloatRegister($dst$$reg);
    FloatRegister src = as_FloatRegister($src$$reg);
    int     flag = $cop$$cmpcode;
    Label      L; 

    switch(flag)
    {
      case 0x01: //equal
       	__ bne(op1, op2, L); 
        __ nop();
        __ mov_d(dst, src);
        __ bind(L);
        break;
      case 0x02: //not_equal
       	__ beq(op1, op2, L); 
        __ nop();
        __ mov_d(dst, src);
        __ bind(L);
        break;
      case 0x03: //great
        __ slt(AT, op2, op1);
       	__ beq(AT, R0, L);
        __ nop();
        __ mov_d(dst, src);
        __ bind(L);
        break;
      case 0x04: //great_equal
        __ slt(AT, op1, op2);
        __ bne(AT, R0, L); 
        __ nop();
        __ mov_d(dst, src);
        __ bind(L);
        break;
      case 0x05: //less
        __ slt(AT, op1, op2);
       	__ beq(AT, R0, L);
        __ nop();
        __ mov_d(dst, src);
        __ bind(L);
        break;
      case 0x06: //less_equal
        __ slt(AT, op2, op1);
       	__ bne(AT, R0, L); 
        __ nop();
        __ mov_d(dst, src);
        __ bind(L);
       break;
      default:
          Unimplemented();
    }  
  %}

  ins_pipe( pipe_slow );
%}

//FIXME
instruct cmovI_cmpF_reg_reg(mRegI dst, mRegI src, regF tmp1, regF tmp2, cmpOp cop ) %{
  match(Set dst (CMoveI (Binary cop (CmpF tmp1 tmp2)) (Binary dst src)));
  ins_cost(80);
  format %{
             "CMP$cop  $tmp1, $tmp2\t  @cmovI_cmpF_reg_reg\n"
             "\tCMOV  $dst,$src \t @cmovI_cmpF_reg_reg"
         %}

  ins_encode %{
    FloatRegister reg_op1 = $tmp1$$FloatRegister;
    FloatRegister reg_op2 = $tmp2$$FloatRegister;
    Register dst = $dst$$Register;
    Register src = $src$$Register;
    int     flag = $cop$$cmpcode;

    switch(flag)
    {
      case 0x01: //equal
        __ c_ueq_s(reg_op1, reg_op2);
        __ movt(dst, src);
        break;
      case 0x02: //not_equal
        __ c_eq_s(reg_op1, reg_op2);
        __ movf(dst, src);
        break;
      case 0x03: //greater
        __ c_ole_s(reg_op1, reg_op2);
        __ movf(dst, src);
        break;
      case 0x04: //greater_equal
        __ c_olt_s(reg_op1, reg_op2);
        __ movf(dst, src);
        break;
      case 0x05: //less
        __ c_ult_s(reg_op1, reg_op2);
        __ movt(dst, src);
        break;
      case 0x06: //less_equal
        __ c_ule_s(reg_op1, reg_op2);
        __ movt(dst, src);
       break;
      default:
          Unimplemented();
    }  
  %}
  ins_pipe( pipe_slow );
%}

instruct cmovF_cmpF_reg_reg(regF dst, regF src, regF tmp1, regF tmp2, cmpOp cop ) %{
  match(Set dst (CMoveF (Binary cop (CmpF tmp1 tmp2)) (Binary dst src)));
  ins_cost(200);
  format %{
             "CMP$cop  $tmp1, $tmp2\t  @cmovF_cmpF_reg_reg\n"
             "\tCMOV  $dst,$src \t @cmovF_cmpF_reg_reg"
         %}

  ins_encode %{
    FloatRegister reg_op1 = $tmp1$$FloatRegister;
    FloatRegister reg_op2 = $tmp2$$FloatRegister;
    FloatRegister dst = $dst$$FloatRegister;
    FloatRegister src = $src$$FloatRegister;
    Label  L;
    int    flag = $cop$$cmpcode;

    switch(flag)
    {
      case 0x01: //equal
        __ c_ueq_s(reg_op1, reg_op2);
        __ bc1f(L);
        __ nop();
        __ mov_s(dst, src);
        __ bind(L);
        break;
      case 0x02: //not_equal
        __ c_eq_s(reg_op1, reg_op2);
        __ bc1t(L);
        __ nop();
        __ mov_s(dst, src);
        __ bind(L);
        break;
      case 0x03: //greater
        __ c_ole_s(reg_op1, reg_op2);
        __ bc1t(L);
        __ nop();
        __ mov_s(dst, src);
        __ bind(L);
        break;
      case 0x04: //greater_equal
        __ c_olt_s(reg_op1, reg_op2);
        __ bc1t(L);
        __ nop();
        __ mov_s(dst, src);
        __ bind(L);
        break;
      case 0x05: //less
        __ c_ult_s(reg_op1, reg_op2);
        __ bc1f(L);
        __ nop();
        __ mov_s(dst, src);
        __ bind(L);
        break;
      case 0x06: //less_equal
        __ c_ule_s(reg_op1, reg_op2);
        __ bc1f(L);
        __ nop();
        __ mov_s(dst, src);
        __ bind(L);
       break;
      default:
          Unimplemented();
    }  
  %}
  ins_pipe( pipe_slow );
%}

// Manifest a CmpL result in an integer register.  Very painful.
// This is the test to avoid.
instruct cmpL3_reg_reg(mRegI dst, mRegL src1, mRegL src2) %{
  match(Set dst (CmpL3 src1 src2));
  ins_cost(1000);
  format %{ "cmpL3  $dst, $src1, $src2 @ cmpL3_reg_reg" %}
  ins_encode %{
    Register opr1 = as_Register($src1$$reg);
    Register opr2 = as_Register($src2$$reg);
    Register dst  = as_Register($dst$$reg);

    Label p_one,  done;

    __ subu(dst, opr1, opr2);

    __ beq(dst, R0, done);
    __ nop();

    __ bgtz(dst, done);
    __ delayed()->addiu32(dst, R0, 1);

    __ addiu32(dst, R0, -1);

    __ bind(done);
  %}
  ins_pipe( pipe_slow );
%}

//
// less_rsult     =  1 
// greater_result = -1
// equal_result   =  0 
// nan_result     = -1
//
instruct cmpF3_reg_reg(mRegI dst, regF src1, regF src2) %{
  match(Set dst (CmpF3 src1 src2));
  ins_cost(1000);
  format %{ "cmpF3  $dst, $src1, $src2 @ cmpF3_reg_reg" %}
  ins_encode %{
    FloatRegister src1 = as_FloatRegister($src1$$reg);
    FloatRegister src2 = as_FloatRegister($src2$$reg);
    Register dst = as_Register($dst$$reg);

    Label EQU, LESS, DONE;

    __ move(dst, -1);
    __ c_eq_s(src1, src2);
    __ bc1t(EQU);
    __ nop();
    __ c_olt_s(src1, src2);
    __ bc1t(LESS);
    __ nop();
    __ beq(R0, R0, DONE);
    __ nop();
    __ bind(EQU);
    __ move(dst, 0);
    __ beq(R0, R0, DONE);
    __ nop();
    __ bind(LESS);
    __ move(dst, 1);
    __ bind(DONE);
  %}
  ins_pipe( pipe_slow );
%}

instruct cmpD3_reg_reg(mRegI dst, regD src1, regD src2) %{
  match(Set dst (CmpD3 src1 src2));
  ins_cost(1000);
  format %{ "cmpD3  $dst, $src1, $src2 @ cmpD3_reg_reg" %}
  ins_encode %{
    FloatRegister src1 = as_FloatRegister($src1$$reg);
    FloatRegister src2 = as_FloatRegister($src2$$reg);
    Register dst = as_Register($dst$$reg);

    Label EQU, LESS, DONE;

    __ move(dst, -1);
    __ c_eq_d(src1, src2);
    __ bc1t(EQU);
    __ nop();
    __ c_olt_d(src1, src2);
    __ bc1t(LESS);
    __ nop();
    __ beq(R0, R0, DONE);
    __ nop();
    __ bind(EQU);
    __ move(dst, 0);
    __ beq(R0, R0, DONE);
    __ nop();
    __ bind(LESS);
    __ move(dst, 1);
    __ bind(DONE);
  %}
  ins_pipe( pipe_slow );
%}

instruct clear_array(mRegL cnt, mRegP base, Universe dummy) %{
  match(Set dummy (ClearArray cnt base));
  format %{ "CLEAR_ARRAY base = $base, cnt = $cnt # Clear doublewords" %}
  ins_encode %{
    //Assume cnt is the number of bytes in an array to be cleared,
    //and base points to the starting address of the array.
    Register base = $base$$Register;
    Register num  = $cnt$$Register;
    Label Loop, done;

    /* 2012/9/21 Jin: according to X86, $cnt is caculated by doublewords(8 bytes) */
    __ move(T9, num);	/* T9 = words */
    __ beq(T9, R0, done);
    __ nop();
    __ move(AT, base);

    __ bind(Loop);
    __ sd(R0, Address(AT, 0));
    __ daddi(AT, AT, wordSize);
    __ daddi(T9, T9, -1);
    __ bne(T9, R0, Loop);
    __ delayed()->nop();
    __ bind(done);
  %}
  ins_pipe( pipe_slow );
%}

instruct string_compare(mRegP str1, mRegI cnt1, mRegP str2, mRegI cnt2, mRegI result) %{
  match(Set result (StrComp (Binary str1 cnt1) (Binary str2 cnt2)));

  format %{ "String Compare $str1[len: $cnt1], $str2[len: $cnt2] -> $result  @ string_compare" %}
  ins_encode %{
    // Get the first character position in both strings
    //         [8] char array, [12] offset, [16] count 
    Register str1   = $str1$$Register;
    Register str2   = $str2$$Register;
    Register cnt1   = $cnt1$$Register;
    Register cnt2   = $cnt2$$Register;
    Register result = $result$$Register;

    Register tmp1   = T8;
    Register tmp2   = T9;
    Register tmp3   = S7;

    Label L, Loop, haveResult, LoopEnd, done;

    /* 2013/7/9 Jin: StrComp is totally redefined in OpenJDK 8 */

   // Let tmp1 point to the first character of str1 (if str1 is not empty).
   __ move(tmp1, str1);

   // Let tmp2 point to the first character of str2 (if str2 is not empty).
   __ move(tmp2, str2);

   // compute the shorter length (in tmp3) and difference of lengths (in result)
   __ move(tmp3, cnt1);
   __ slt(AT, cnt1, cnt2);
   __ bne(AT, R0, L);
   __ nop(); 
   __ move(tmp3, cnt2);  //Now the shorter length is in tmp3.
   __ bind(L);

   if ($str1$$Register != $result$$Register) __ push(str1);
   __ subu(result, cnt1, cnt2);
   __ push(result);  // result holds the difference of two lengths 

   //Begin to compare str1 and str2.
   __ bind(Loop);
   __ beq(tmp3, R0, LoopEnd);
   __ nop();

   // compare current character
   __ lhu(AT, tmp1, 0);
   __ lhu(str1, tmp2, 0);       
   __ bne(AT, str1, haveResult);
   __ nop();
   __ addi(tmp1, tmp1, 2);
   __ addi(tmp2, tmp2, 2);
   __ b(Loop);
   __ delayed()->addi(tmp3, tmp3, -1);

   __ bind(LoopEnd);
   __ pop(result);
   __ beq(R0, R0, done);
   __ nop(); 
   
   __ bind(haveResult);
   __ subu(result, AT, str1);
   __ pop(AT);

   __ bind(done);
   if ($str1$$Register != $result$$Register) __ pop(str1);
  %}

  ins_pipe( pipe_slow );
%}

//----------Arithmetic Instructions-------------------------------------------
//----------Addition Instructions---------------------------------------------
instruct addI_Reg_Reg(mRegI dst, mRegI src1, mRegI src2) %{
  match(Set dst (AddI src1 src2));

  format %{ "add   $dst, $src1, $src2 #@addI_Reg_Reg" %}
  ins_encode %{
    Register  dst = $dst$$Register;
    Register src1 = $src1$$Register;
    Register src2 = $src2$$Register;
    __ addu32(dst, src1, src2);
  %}
  ins_pipe( ialu_regI_regI );
%}

instruct addI_Reg_imm(mRegI dst, mRegI src1,  immI src2) %{
  match(Set dst (AddI src1 src2));

  format %{ "add    $dst, $src1, $src2 #@addI_Reg_imm" %}
  ins_encode %{
    Register  dst = $dst$$Register;
    Register src1 = $src1$$Register;
    int       imm = $src2$$constant;

    if(Assembler::is_simm16(imm)) {
       __ addiu32(dst, src1, imm);
    } else {
       __ move(AT, imm);
       __ addu32(dst, src1, AT);
    }
  %}
  ins_pipe( ialu_regI_regI );
%}

instruct addP_reg_reg(mRegP dst, mRegP src1, mRegL src2) %{
  match(Set dst (AddP src1 src2));

  format %{ "dadd    $dst, $src1, $src2 #@addP_reg_reg" %}

  ins_encode %{
    Register  dst = $dst$$Register;
    Register src1 = $src1$$Register;
    Register src2 = $src2$$Register;
    __ daddu(dst, src1, src2);  
  %}

  ins_pipe( ialu_regI_regI );
%}

instruct addP_reg_imm(mRegP dst, mRegP src1,  immL32 src2) %{
  match(Set dst (AddP src1 src2));
//  effect(KILL cr);

  format %{ "daddi   $dst, $src1, $src2 #@addP_reg_imm" %}
  ins_encode %{
    Register src1 = $src1$$Register;
    long      src2 = $src2$$constant;
    Register  dst = $dst$$Register;

    if(Assembler::is_simm16(src2)) {
       __ daddiu(dst, src1, src2);
    } else {
       __ li(AT, src2);
       __ daddu(dst, src1, AT);
    }
  %}
  ins_pipe( ialu_regI_imm16 );
%}

// Add Long Register with Register
instruct addL_Reg_Reg(mRegL dst, mRegL src1, mRegL src2) %{
  match(Set dst (AddL src1 src2));
  ins_cost(200);
  format %{ "ADD    $dst, $src1, $src2 #@addL_Reg_Reg\t" %}

  ins_encode %{
    Register dst_reg = as_Register($dst$$reg);
    Register src1_reg = as_Register($src1$$reg);
    Register src2_reg = as_Register($src2$$reg);

    __ daddu(dst_reg, src1_reg, src2_reg);
  %}

  ins_pipe( ialu_regL_regL );
%}

instruct addL_RegI2L_Reg(mRegL dst, mRegI src1, mRegL src2) %{
  match(Set dst (AddL (ConvI2L src1) src2));
  ins_cost(200);
  format %{ "ADD    $dst, $src1, $src2 #@addL_RegI2L_Reg\t" %}

  ins_encode %{
    Register dst_reg = as_Register($dst$$reg);
    Register src1_reg = as_Register($src1$$reg);
    Register src2_reg = as_Register($src2$$reg);

    __ daddu(dst_reg, src1_reg, src2_reg);
  %}

  ins_pipe( ialu_regL_regL );
%}

instruct addL_Reg_RegI2L(mRegL dst, mRegL src1, mRegI src2) %{
  match(Set dst (AddL src1 (ConvI2L src2)));
  ins_cost(200);
  format %{ "ADD    $dst, $src1, $src2 #@addL_Reg_RegI2L\t" %}

  ins_encode %{
    Register dst_reg = as_Register($dst$$reg);
    Register src1_reg = as_Register($src1$$reg);
    Register src2_reg = as_Register($src2$$reg);

    __ daddu(dst_reg, src1_reg, src2_reg);
  %}

  ins_pipe( ialu_regL_regL );
%}

//----------Subtraction Instructions-------------------------------------------
// Integer Subtraction Instructions
instruct subI_Reg_Reg(mRegI dst, mRegI src1, mRegI src2) %{
  match(Set dst (SubI src1 src2));

  format %{ "sub    $dst, $src1, $src2 #@subI_Reg_Reg" %}
  ins_encode %{
    Register  dst = $dst$$Register;
    Register src1 = $src1$$Register;
    Register src2 = $src2$$Register;
    __ subu32(dst, src1, src2);
  %}
  ins_pipe( ialu_regI_regI );
%}

instruct subI_Reg_imm(mRegI dst, mRegI src1,  immI src2) %{
  match(Set dst (SubI src1 src2));

  format %{ "sub    $dst, $src1, $src2 #@subI_Reg_imm" %}
  ins_encode %{
    Register  dst = $dst$$Register;
    Register src1 = $src1$$Register;
    __ move(AT, -1 * $src2$$constant);
    __ addu32(dst, src1, AT);
  %}
  ins_pipe( ialu_regI_regI );
%}

// Subtract Long Register with Register.
instruct subL_Reg_Reg(mRegL dst, mRegL src1, mRegL src2) %{
  match(Set dst (SubL src1 src2));
  ins_cost(200);
  format %{ "SubL    $dst, $src1, $src2 @ subL_Reg_Reg" %}
  ins_encode %{
    Register dst  = as_Register($dst$$reg);
    Register src1 = as_Register($src1$$reg);
    Register src2 = as_Register($src2$$reg);

    __ subu(dst, src1, src2);
  %}
  ins_pipe( ialu_regL_regL );
%}

instruct subL_Reg_RegI2L(mRegL dst, mRegL src1, mRegI src2) %{
  match(Set dst (SubL src1 (ConvI2L src2)));
  ins_cost(200);
  format %{ "SubL    $dst, $src1, $src2 @ subL_Reg_RegI2L" %}
  ins_encode %{
    Register dst  = as_Register($dst$$reg);
    Register src1 = as_Register($src1$$reg);
    Register src2 = as_Register($src2$$reg);

    __ subu(dst, src1, src2);
  %}
  ins_pipe( ialu_regL_regL );
%}

instruct subL_RegI2L_Reg(mRegL dst, mRegI src1, mRegL src2) %{
  match(Set dst (SubL (ConvI2L src1) src2));
  ins_cost(200);
  format %{ "SubL    $dst, $src1, $src2 @ subL_RegI2L_Reg" %}
  ins_encode %{
    Register dst  = as_Register($dst$$reg);
    Register src1 = as_Register($src1$$reg);
    Register src2 = as_Register($src2$$reg);

    __ subu(dst, src1, src2);
  %}
  ins_pipe( ialu_regL_regL );
%}

// Integer MOD with Register
instruct modI_Reg_Reg(mRegI dst, mRegI src1, mRegI src2) %{
  match(Set dst (ModI src1 src2));
  ins_cost(300);
  format %{ "modi   $dst, $src1, $src2 @ modI_Reg_Reg" %}
  ins_encode %{
    Register  dst = $dst$$Register;
    Register src1 = $src1$$Register;
    Register src2 = $src2$$Register;

    //if (UseLoongsonISA) {
    if (0) {
      // 2016.08.10 
      // Experiments show that gsmod is slower that div+mfhi.
      // So I just disable it here.
      __ gsmod(dst, src1, src2);
    } else {
      __ div(src1, src2); 
      __ mfhi(dst);  
    }
  %}

  //ins_pipe( ialu_mod );
  ins_pipe( ialu_regI_regI );
%}

instruct modL_reg_reg(mRegL dst, mRegL src1, mRegL src2) %{
  match(Set dst (ModL src1 src2));
  format %{ "modL  $dst, $src1, $src2 @modL_reg_reg" %}

  ins_encode %{
    Register dst = as_Register($dst$$reg);
    Register op1 = as_Register($src1$$reg);
    Register op2 = as_Register($src2$$reg);

    if (UseLoongsonISA) {
      __ gsdmod(dst, op1, op2);
    } else {
      __ ddiv(op1, op2);
      __ mfhi(dst);
    }
  %}
  ins_pipe( pipe_slow );
%}

instruct mulI_Reg_Reg(mRegI dst, mRegI src1, mRegI src2) %{
  match(Set dst (MulI src1 src2));

  ins_cost(300);
  format %{ "mul   $dst, $src1, $src2 @ mulI_Reg_Reg" %}
  ins_encode %{
     Register src1 = $src1$$Register;
     Register src2 = $src2$$Register;
     Register dst  = $dst$$Register;
         
     __ mul(dst, src1, src2);
  %}
  ins_pipe( ialu_mult );
%}

instruct maddI_Reg_Reg(mRegI dst, mRegI src1, mRegI src2, mRegI src3) %{
  match(Set dst (AddI (MulI src1 src2) src3));

  ins_cost(999);
  format %{ "madd   $dst, $src1 * $src2 + $src3 #@maddI_Reg_Reg" %}
  ins_encode %{
     Register src1 = $src1$$Register;
     Register src2 = $src2$$Register;
     Register src3 = $src3$$Register;
     Register dst  = $dst$$Register;
         
     __ mtlo(src3);
     __ madd(src1, src2);
     __ mflo(dst);
  %}
  ins_pipe( ialu_mult );
%}

instruct divI_Reg_Reg(mRegI dst, mRegI src1, mRegI src2) %{
  match(Set dst (DivI src1 src2));

  ins_cost(300);
  format %{ "div   $dst, $src1, $src2 @ divI_Reg_Reg" %}
  ins_encode %{
     Register src1 = $src1$$Register;
     Register src2 = $src2$$Register;
     Register dst  = $dst$$Register;

    /* 2012/4/21 Jin: In MIPS, div does not cause exception.
       We must trap an exception manually. */   
    __ teq(R0, src2, 0x7);

    if (UseLoongsonISA) {
      __ gsdiv(dst, src1, src2);
    } else {
      __ div(src1, src2);

      __ nop();
      __ nop();
      __ mflo(dst);
    }
  %}
  ins_pipe( ialu_mod );
%}

instruct divF_Reg_Reg(regF dst, regF src1, regF src2) %{
  match(Set dst (DivF src1 src2));

  ins_cost(300);
  format %{ "divF   $dst, $src1, $src2 @ divF_Reg_Reg" %}
  ins_encode %{
     FloatRegister src1 = $src1$$FloatRegister;
     FloatRegister src2 = $src2$$FloatRegister;
     FloatRegister dst  = $dst$$FloatRegister;

    /* Here do we need to trap an exception manually ? */   
    __ div_s(dst, src1, src2);
  %}
  ins_pipe( pipe_slow );
%}

instruct divD_Reg_Reg(regD dst, regD src1, regD src2) %{
  match(Set dst (DivD src1 src2));

  ins_cost(300);
  format %{ "divD   $dst, $src1, $src2 @ divD_Reg_Reg" %}
  ins_encode %{
     FloatRegister src1 = $src1$$FloatRegister;
     FloatRegister src2 = $src2$$FloatRegister;
     FloatRegister dst  = $dst$$FloatRegister;

    /* Here do we need to trap an exception manually ? */   
    __ div_d(dst, src1, src2);
  %}
  ins_pipe( pipe_slow );
%}

instruct divF_Reg_immF(regF dst, regF src1, immF src2, regF tmp) %{
  match(Set dst (DivF src1 src2));
  effect(TEMP tmp);

  ins_cost(300);
  format %{ "divF   $dst, $src1, $src2  [tmp = $tmp] @ divF_Reg_immF" %}
  ins_encode %{
     FloatRegister src1 = $src1$$FloatRegister;
     FloatRegister tmp  = $tmp$$FloatRegister;
     FloatRegister dst  = $dst$$FloatRegister;

    jfloat     jf = $src2$$constant;
    address const_addr = __ float_constant(jf);
    assert (const_addr != NULL, "must create float constant in the constant table");

    __ relocate(relocInfo::internal_pc_type);
    __ li(AT, const_addr);
    __ lwc1(tmp, AT, 0);

    __ div_s(dst, src1, tmp);
  %}
  ins_pipe( pipe_slow );
%}


instruct mulL_reg_reg(mRegL dst, mRegL src1, mRegL src2) %{
  match(Set dst (MulL src1 src2));
  format %{ "mulL  $dst, $src1, $src2 @mulL_reg_reg" %}
  ins_encode %{
    Register dst = as_Register($dst$$reg);
    Register op1 = as_Register($src1$$reg);
    Register op2 = as_Register($src2$$reg);

    if (UseLoongsonISA) {
      __ gsdmult(dst, op1, op2);
    } else {
      __ dmult(op1, op2);
      __ mflo(dst);
    }
  %}
  ins_pipe( pipe_slow );
%}

instruct divL_reg_reg(mRegL dst, mRegL src1, mRegL src2) %{
  match(Set dst (DivL src1 src2));
  format %{ "divL  $dst, $src1, $src2 @divL_reg_reg" %}

  ins_encode %{
    Register dst = as_Register($dst$$reg);
    Register op1 = as_Register($src1$$reg);
    Register op2 = as_Register($src2$$reg);

    if (UseLoongsonISA) {
      __ gsddiv(dst, op1, op2);
    } else {
      __ ddiv(op1, op2);
      __ mflo(dst);
    }
  %}
  ins_pipe( pipe_slow );
%}

instruct addF_reg_reg(regF dst, regF src1, regF src2) %{
  match(Set dst (AddF src1 src2));
  format %{ "AddF  $dst, $src1, $src2 @addF_reg_reg" %}
  ins_encode %{
    FloatRegister src1 = as_FloatRegister($src1$$reg);
    FloatRegister src2 = as_FloatRegister($src2$$reg);
    FloatRegister dst  = as_FloatRegister($dst$$reg);

    __ add_s(dst, src1, src2);  
  %}
  ins_pipe( fpu_regF_regF );
%}

instruct subF_reg_reg(regF dst, regF src1, regF src2) %{
  match(Set dst (SubF src1 src2));
  format %{ "SubF  $dst, $src1, $src2 @subF_reg_reg" %}
  ins_encode %{
    FloatRegister src1 = as_FloatRegister($src1$$reg);
    FloatRegister src2 = as_FloatRegister($src2$$reg);
    FloatRegister dst  = as_FloatRegister($dst$$reg);

    __ sub_s(dst, src1, src2);  
  %}
  ins_pipe( fpu_regF_regF );
%}
instruct addD_reg_reg(regD dst, regD src1, regD src2) %{
  match(Set dst (AddD src1 src2));
  format %{ "AddD  $dst, $src1, $src2 @addD_reg_reg" %}
  ins_encode %{
    FloatRegister src1 = as_FloatRegister($src1$$reg);
    FloatRegister src2 = as_FloatRegister($src2$$reg);
    FloatRegister dst  = as_FloatRegister($dst$$reg);

    __ add_d(dst, src1, src2);  
  %}
  ins_pipe( fpu_regF_regF );
%}

instruct subD_reg_reg(regD dst, regD src1, regD src2) %{
  match(Set dst (SubD src1 src2));
  format %{ "SubD  $dst, $src1, $src2 @subD_reg_reg" %}
  ins_encode %{
    FloatRegister src1 = as_FloatRegister($src1$$reg);
    FloatRegister src2 = as_FloatRegister($src2$$reg);
    FloatRegister dst  = as_FloatRegister($dst$$reg);

    __ sub_d(dst, src1, src2);  
  %}
  ins_pipe( fpu_regF_regF );
%}

instruct negF_reg(regF dst, regF src) %{
  match(Set dst (NegF src));
  format %{ "negF  $dst, $src @negF_reg" %}
  ins_encode %{
    FloatRegister src = as_FloatRegister($src$$reg);
    FloatRegister dst = as_FloatRegister($dst$$reg);

    __ neg_s(dst, src);
  %}
  ins_pipe( fpu_regF_regF );
%}

instruct negD_reg(regD dst, regD src) %{
  match(Set dst (NegD src));
  format %{ "negD  $dst, $src @negD_reg" %}
  ins_encode %{
    FloatRegister src = as_FloatRegister($src$$reg);
    FloatRegister dst = as_FloatRegister($dst$$reg);

    __ neg_d(dst, src);  
  %}
  ins_pipe( fpu_regF_regF );
%}


instruct mulF_reg_reg(regF dst, regF src1, regF src2) %{
  match(Set dst (MulF src1 src2));
  format %{ "MULF  $dst, $src1, $src2 @mulF_reg_reg" %}
  ins_encode %{
    FloatRegister src1 = $src1$$FloatRegister;
    FloatRegister src2 = $src2$$FloatRegister;
    FloatRegister dst  = $dst$$FloatRegister;

    __ mul_s(dst, src1, src2);  
  %}
  ins_pipe( fpu_regF_regF );
%}

// Mul two double precision floating piont number
instruct mulD_reg_reg(regD dst, regD src1, regD src2) %{
  match(Set dst (MulD src1 src2));
  format %{ "MULD  $dst, $src1, $src2 @mulD_reg_reg" %}
  ins_encode %{
    FloatRegister src1 = $src1$$FloatRegister;
    FloatRegister src2 = $src2$$FloatRegister;
    FloatRegister dst  = $dst$$FloatRegister;

    __ mul_d(dst, src1, src2);  
  %}
  ins_pipe( fpu_regF_regF );
%}

instruct absF_reg(regF dst, regF src) %{
  match(Set dst (AbsF src));
  ins_cost(100);
  format %{ "absF  $dst, $src @absF_reg" %}
  ins_encode %{
    FloatRegister src = as_FloatRegister($src$$reg);
    FloatRegister dst = as_FloatRegister($dst$$reg);

    __ abs_s(dst, src);  
  %}
  ins_pipe( fpu_regF_regF );
%}


// intrinsics for math_native.
// AbsD  SqrtD  CosD  SinD  TanD  LogD  Log10D

instruct absD_reg(regD dst, regD src) %{
  match(Set dst (AbsD src));
  ins_cost(100);
  format %{ "absD  $dst, $src @absD_reg" %}
  ins_encode %{
    FloatRegister src = as_FloatRegister($src$$reg);
    FloatRegister dst = as_FloatRegister($dst$$reg);

    __ abs_d(dst, src);  
  %}
  ins_pipe( fpu_regF_regF );
%}

instruct sqrtD_reg(regD dst, regD src) %{
  match(Set dst (SqrtD src));
  ins_cost(100);
  format %{ "SqrtD  $dst, $src @sqrtD_reg" %}
  ins_encode %{
    FloatRegister src = as_FloatRegister($src$$reg);
    FloatRegister dst = as_FloatRegister($dst$$reg);

    __ sqrt_d(dst, src);  
  %}
  ins_pipe( fpu_regF_regF );
%}

//----------------------------------Logical Instructions----------------------
//__________________________________Integer Logical Instructions-------------

//And Instuctions
// And Register with Immediate
instruct andI_Reg_imm(mRegI dst, mRegI src1,  immI src2) %{
  match(Set dst (AndI src1 src2));

  format %{ "and  $dst, $src1, $src2 #@andI_Reg_imm" %}
  ins_encode %{
    Register dst = $dst$$Register;
    Register src = $src1$$Register;
    int      val = $src2$$constant;
    
       __ move(AT, val);
       __ andr(dst, src, AT);
  %}
  ins_pipe( ialu_regI_regI );
%}

instruct andI_Reg_imm_0_65535(mRegI dst, mRegI src1,  immI_0_65535 src2) %{
  match(Set dst (AndI src1 src2));
  ins_cost(60);

  format %{ "and  $dst, $src1, $src2 #@andI_Reg_imm_0_65535" %}
  ins_encode %{
    Register dst = $dst$$Register;
    Register src = $src1$$Register;
    int      val = $src2$$constant;
    
       __ andi(dst, src, val);
  %}
  ins_pipe( ialu_regI_regI );
%}

instruct andI_Reg_Reg(mRegI dst, mRegI src1,  mRegI src2) %{
  match(Set dst (AndI src1 src2));

  format %{ "and    $dst, $src1, $src2 #@andI_Reg_Reg" %}
  ins_encode %{
    Register dst = $dst$$Register;
    Register src1 = $src1$$Register;
    Register src2 = $src2$$Register;
    __ andr(dst, src1, src2);
  %}
  ins_pipe( ialu_regI_regI );
%}

// And Long Register with Register
instruct andL_Reg_Reg(mRegL dst, mRegL src1, mRegL src2) %{
  match(Set dst (AndL src1 src2));
  format %{ "AND    $dst, $src1, $src2 @ andL_Reg_Reg\n\t" %}
  ins_encode %{
    Register dst_reg = as_Register($dst$$reg);
    Register src1_reg = as_Register($src1$$reg);
    Register src2_reg = as_Register($src2$$reg);

    __ andr(dst_reg, src1_reg, src2_reg);
  %}
  ins_pipe( ialu_regL_regL );
%}

// Or Long Register with Register
instruct orL_Reg_Reg(mRegL dst, mRegL src1, mRegL src2) %{
  match(Set dst (OrL src1 src2));
  format %{ "OR    $dst, $src1, $src2 @ orL_Reg_Reg\t" %}
  ins_encode %{
    Register dst_reg  = $dst$$Register;
    Register src1_reg = $src1$$Register;
    Register src2_reg = $src2$$Register;

    __ orr(dst_reg, src1_reg, src2_reg);
  %}
  ins_pipe( ialu_regL_regL );
%}

// Xor Long Register with Register
instruct xorL_Reg_Reg(mRegL dst, mRegL src1, mRegL src2) %{
  match(Set dst (XorL src1 src2));
  format %{ "XOR    $dst, $src1, $src2 @ xorL_Reg_Reg\t" %}
  ins_encode %{
    Register dst_reg = as_Register($dst$$reg);
    Register src1_reg = as_Register($src1$$reg);
    Register src2_reg = as_Register($src2$$reg);

    __ xorr(dst_reg, src1_reg, src2_reg);
  %}
  ins_pipe( ialu_regL_regL );
%}

// Shift Left by 8-bit immediate
instruct salI_Reg_imm(mRegI dst, mRegI src, immI8 shift) %{
  match(Set dst (LShiftI src shift));

  format %{ "SHL    $dst, $src, $shift #@salI_Reg_imm" %}
  ins_encode %{
    Register src = $src$$Register;
    Register dst = $dst$$Register;
    int    shamt = $shift$$constant;

/*
     094     SHL    S0, S0, #-7 #@salI_Reg_imm    
     static int insn_RRSO(int rt, int rd, int sa,   int op) { return (rt<<16) | (rd<<11) | (sa<<6)   | op; }
     void sll  (Register rd, Register rt ,  int sa) { 
         emit_long(insn_RRSO((int)rt->encoding(), (int)rd->encoding(), sa, sll_op));
     }
*/

    if(0 <= shamt && shamt < 32) __ sll(dst, src, shamt);
    else {
       __ move(AT, shamt);
       __ sllv(dst, src, AT);
    }
  %}
  ins_pipe( ialu_regI_regI );
%}

// Shift Left by 8-bit immediate
instruct salI_Reg_Reg(mRegI dst, mRegI src, mRegI shift) %{
  match(Set dst (LShiftI src shift));

  format %{ "SHL    $dst, $src, $shift #@salI_Reg_Reg" %}
  ins_encode %{
    Register src = $src$$Register;
    Register dst = $dst$$Register;
    Register shamt = $shift$$Register;
    __ sllv(dst, src, shamt);
  %}
  ins_pipe( ialu_regI_regI );
%}


// Shift Left Long 
instruct salL_Reg_imm(mRegL dst, mRegL src, immI8 shift) %{
  //predicate(UseNewLongLShift);
  match(Set dst (LShiftL src shift));
  ins_cost(100);
  format %{ "salL    $dst, $src, $shift @ salL_Reg_imm" %}
  ins_encode %{
    Register src_reg = as_Register($src$$reg);
    Register dst_reg = as_Register($dst$$reg);
    int      shamt = $shift$$constant;

    if (__ is_simm(shamt, 5))
        __ dsll(dst_reg, src_reg, shamt);
    else
    {
       __ move(AT, shamt);
       __ dsllv(dst_reg, src_reg, AT);
    }
  %}
  ins_pipe( ialu_regL_regL );
%}


// Shift Left Long 
instruct salL_Reg_Reg(mRegL dst, mRegL src, mRegI shift) %{
  //predicate(UseNewLongLShift);
  match(Set dst (LShiftL src shift));
  ins_cost(100);
  format %{ "salL    $dst, $src, $shift @ salL_Reg_Reg" %}
  ins_encode %{
    Register creg = T9;
    Register src_reg = as_Register($src$$reg);
    Register dst_reg = as_Register($dst$$reg);
                 
    __ move(creg, $shift$$Register);
    __ andi(creg, creg, 0x3f);
	__ dsllv(dst_reg, src_reg, creg);
  %}
  ins_pipe( ialu_regL_regL );
%}

instruct salL_convI2L_Reg_imm(mRegL dst, mRegI src, immI8 shift) %{
  match(Set dst (LShiftL (ConvI2L src) shift));
  ins_cost(100);
  format %{ "salL    $dst, $src, $shift @ salL_convI2L_Reg_imm" %}
  ins_encode %{
    Register src_reg = as_Register($src$$reg);
    Register dst_reg = as_Register($dst$$reg);
    int      shamt = $shift$$constant;

    if (__ is_simm(shamt, 5)) {
        __ dsll(dst_reg, src_reg, shamt);
    } else {
       __ move(AT, shamt);
       __ dsllv(dst_reg, src_reg, AT);
    }
  %}
  ins_pipe( ialu_regL_regL );
%}

// Shift Right Long 
instruct sarL_Reg_imm(mRegL dst, mRegL src, immI8 shift) %{
  //predicate(UseNewLongLShift);
  match(Set dst (RShiftL src shift));
  ins_cost(100);
  format %{ "sarL    $dst, $src, $shift @ sarL_Reg_imm" %}
  ins_encode %{
    Register src_reg = as_Register($src$$reg);
    Register dst_reg = as_Register($dst$$reg);
    int      shamt = ($shift$$constant & 0x3f);
    if (__  is_simm(shamt, 5))
	__ dsra(dst_reg, src_reg, shamt);
    else
    {
	__ move(AT, shamt);
	__ dsrav(dst_reg, src_reg, AT);
    }
  %}
  ins_pipe( ialu_regL_regL );
%}

// Shift Right Long arithmetically
instruct sarL_Reg_Reg(mRegL dst, mRegL src, mRegI shift) %{
  //predicate(UseNewLongLShift);
  match(Set dst (RShiftL src shift));
  ins_cost(100);
  format %{ "sarL    $dst, $src, $shift @ sarL_Reg_Reg" %}
  ins_encode %{
    Register creg = T9;
    Register src_reg = as_Register($src$$reg);
    Register dst_reg = as_Register($dst$$reg);

    __ move(creg, $shift$$Register);
    __ andi(creg, creg, 0x3f);
	__ dsrav(dst_reg, src_reg, creg);
  %}
  ins_pipe( ialu_regL_regL );
%}

// Shift Right Long logically
instruct slrL_Reg_Reg(mRegL dst, mRegL src, mRegI shift) %{
  match(Set dst (URShiftL src shift));
  ins_cost(100);
  format %{ "slrL    $dst, $src, $shift @ slrL_Reg_Reg" %}
  ins_encode %{
    Register creg = T9;
    Register src_reg = as_Register($src$$reg);
    Register dst_reg = as_Register($dst$$reg);
    Label normal, done, notZero;

    __ move(creg, $shift$$Register);
    __ andi(creg, creg, 0x3f); 
	__ dsrlv(dst_reg, src_reg, creg);
  %}
  ins_pipe( ialu_regL_regL );
%}


// Xor Instructions
// Xor Register with Register
instruct xorI_Reg_Reg(mRegI dst, mRegI src1, mRegI src2) %{
  match(Set dst (XorI src1 src2));

  format %{ "XOR    $dst, $src1, $src2 #@xorI_Reg_Reg" %}

  ins_encode %{
    Register  dst = $dst$$Register;
    Register src1 = $src1$$Register;
    Register src2 = $src2$$Register;
    __ xorr(dst, src1, src2);
    __ sll(dst, dst, 0); /* long -> int */
  %}

  ins_pipe( ialu_regI_regI );
%}

// Or Instructions
// Or Register with Register
instruct orI_Reg_Reg(mRegI dst, mRegI src1, mRegI src2) %{
  match(Set dst (OrI src1 src2));

  format %{ "OR     $dst, $src1, $src2 #@orI_Reg_Reg" %}
  ins_encode %{
    Register  dst = $dst$$Register;
    Register src1 = $src1$$Register;
    Register src2 = $src2$$Register;
    __ orr(dst, src1, src2);
  %}

  ins_pipe( ialu_regI_regI );
%}

instruct orI_Reg_castP2X(mRegL dst, mRegL src1, mRegP src2) %{
  match(Set dst (OrI src1 (CastP2X src2)));

  format %{ "OR     $dst, $src1, $src2 #@orI_Reg_castP2X" %}
  ins_encode %{
    Register  dst = $dst$$Register;
    Register src1 = $src1$$Register;
    Register src2 = $src2$$Register;
    __ orr(dst, src1, src2);
  %}

  ins_pipe( ialu_regI_regI );
%}

// Logical Shift Right by 8-bit immediate
instruct shr_logical_Reg_imm(mRegI dst, mRegI src, immI8 shift) %{
  match(Set dst (URShiftI src shift));
 // effect(KILL cr);

  format %{ "SRL    $dst, $src, $shift #@shr_logical_Reg_imm" %}
  ins_encode %{
    Register src = $src$$Register;
    Register dst = $dst$$Register;
    int    shift = $shift$$constant;
    if (shift > 0)
      __ srl(dst, src, shift);
    else
    {
      __ move(AT, shift);
      __ srlv(dst, src, AT);
    }
  %}
  ins_pipe( ialu_regI_regI );
%}

// Logical Shift Right 
instruct shr_logical_Reg_Reg(mRegI dst, mRegI src, mRegI shift) %{
  match(Set dst (URShiftI src shift));

  format %{ "SRL    $dst, $src, $shift #@shr_logical_Reg_Reg" %}
  ins_encode %{
    Register src = $src$$Register;
    Register dst = $dst$$Register;
    Register shift = $shift$$Register;
    __ srlv(dst, src, shift);
  %}
  ins_pipe( ialu_regI_regI );
%}


instruct shr_arith_Reg_imm(mRegI dst, mRegI src, immI8 shift) %{
  match(Set dst (RShiftI src shift));
 // effect(KILL cr);

  format %{ "SRA    $dst, $src, $shift #@shr_arith_Reg_imm" %}
  ins_encode %{
    Register src = $src$$Register;
    Register dst = $dst$$Register;
    int    shift = $shift$$constant;
    __ sra(dst, src, shift);
  %}
  ins_pipe( ialu_regI_regI );
%}

instruct shr_arith_Reg_Reg(mRegI dst, mRegI src, mRegI shift) %{
  match(Set dst (RShiftI src shift));
 // effect(KILL cr);

  format %{ "SRA    $dst, $src, $shift #@shr_arith_Reg_Reg" %}
  ins_encode %{
    Register src = $src$$Register;
    Register dst = $dst$$Register;
    Register shift = $shift$$Register;
    __ srav(dst, src, shift);
  %}
  ins_pipe( ialu_regI_regI );
%}

//----------Convert Int to Boolean---------------------------------------------

instruct movI_nocopy(mRegI dst, mRegI src) %{
  effect( DEF dst, USE src );
  format %{ "MOV    $dst,  $src @ movI_nocopy" %}
  ins_encode %{
    Register  dst = $dst$$Register;
    Register  src = $src$$Register;
    __ move(dst, src);
  %}
  ins_pipe( ialu_regI_regI );
%}

instruct ci2b(mRegI dst, mRegI src) %{
  effect( USE_DEF dst, USE src );

  format %{ "NEG    $dst @ ci2b\n\t"
            "ADC    $dst,$src @ ci2b" %}
  ins_encode %{
    Register  dst = $dst$$Register;
    Register  src = $src$$Register;
    Label L;
//If ( dst != 0 ) CF = 1;
    guarantee(dst != src, "in ci2b");
    __ move(AT, src);
    __ beq(dst, R0, L);
    __ nop();
    __ addiu(AT, AT, 1);
    __ bind(L);
    __ neg(dst);
    __ addu(dst, dst, AT);
  %}

  ins_pipe( ialu_regL_regL );
%}


instruct convI2B(mRegI dst, mRegI src) %{
  match(Set dst (Conv2B src));

  expand %{
    movI_nocopy(dst,src);
    ci2b(dst,src);
  %}
%}

instruct convI2L_reg( mRegL dst, mRegI src) %{
  match(Set dst (ConvI2L src));

  ins_cost(50);
  format %{ "SLL    $dst, $src @ convI2L_reg\t"  %}
  ins_encode %{
    Register dst = as_Register($dst$$reg);
    Register src = as_Register($src$$reg);

    if(dst != src) __ sll(dst, src, 0);
  %}
  ins_pipe( ialu_regL_regL );
%}


instruct convL2I_reg( mRegI dst, mRegL src ) %{
  match(Set dst (ConvL2I src));
  effect( DEF dst, USE src );
  format %{ "MOV    $dst, $src @ convL2I_reg" %}
  ins_encode %{
    Register dst = as_Register($dst$$reg);
    Register src = as_Register($src$$reg);

    __ dsll32(dst, src, 0);
    __ dsra32(dst, dst, 0);
  %}

  ins_pipe( ialu_regI_regI );
%}

instruct convL2D_reg( regD dst, mRegL src ) %{
  match(Set dst (ConvL2D src));
  effect( DEF dst, USE src );
  format %{ "convL2D    $dst, $src @ convL2D_reg" %}
  ins_encode %{
    Register src = as_Register($src$$reg);
    FloatRegister dst = as_FloatRegister($dst$$reg);

    __ dmtc1(src, dst);
    __ cvt_d_l(dst, dst);
  %}

  ins_pipe( pipe_slow );
%}

instruct convD2L_reg( mRegL dst, regD src ) %{
  match(Set dst (ConvD2L src));
  effect( DEF dst, USE src );
  format %{ "convD2L    $dst, $src @ convD2L_reg" %}
  ins_encode %{
    Register dst = as_Register($dst$$reg);
    FloatRegister src = as_FloatRegister($src$$reg);

    Label L;
    
    __ c_un_d(src, src);    //NaN?
    __ bc1t(L);
    __ delayed();
    __ move(dst, R0);

    __ trunc_l_d(F30, src);
    __ cfc1(AT, 31);
    __ li(T9, 0x10000);
    __ andr(AT, AT, T9);
    __ beq(AT, R0, L);
    __ delayed()->dmfc1(dst, F30);

    __ mov_d(F12, src);
    __ call_VM_leaf(CAST_FROM_FN_PTR(address, SharedRuntime::d2l), 1);
    __ move(dst, V0);
    __ bind(L);
  %}

  ins_pipe( pipe_slow );
%}

instruct convF2I_reg( mRegI dst, regF src ) %{
  match(Set dst (ConvF2I src));
  effect( DEF dst, USE src );
  format %{ "convf2i    $dst, $src @ convF2I_reg" %}
  ins_encode %{
    Register      dreg = $dst$$Register;
    FloatRegister fval = $src$$FloatRegister;
    Label L;

    __ c_un_s(fval, fval);    //NaN?
    __ bc1t(L);
    __ delayed();
    __ move(dreg, R0);

    __ trunc_w_s(F30, fval);

    /* Call SharedRuntime:f2i() to do valid convention */
    __ cfc1(AT, 31);
    __ li(T9, 0x10000);
    __ andr(AT, AT, T9);
    __ beq(AT, R0, L);
    __ delayed()->mfc1(dreg, F30);

    __ mov_s(F12, fval);

    /* 2014/01/08 Fu : This bug was found when running ezDS's control-panel.
     *    J 982 C2 javax.swing.text.BoxView.layoutMajorAxis(II[I[I)V (283 bytes) @ 0x000000555c46aa74
     *
     * An interger array index has been assigned to V0, and then changed from 1 to Integer.MAX_VALUE. 
     * V0 is corrupted during call_VM_leaf(), and should be preserved.
     */
    if(dreg != V0) {
      __ push(V0); 
    }
    __ call_VM_leaf(CAST_FROM_FN_PTR(address, SharedRuntime::f2i), 1);
    if(dreg != V0) {
      __ move(dreg, V0);
      __ pop(V0);
    }
    __ bind(L);
  %}

  ins_pipe( pipe_slow );
%}

instruct convF2L_reg( mRegL dst, regF src ) %{
  match(Set dst (ConvF2L src));
  effect( DEF dst, USE src );
  format %{ "convf2l    $dst, $src @ convF2L_reg" %}
  ins_encode %{
    Register dst = as_Register($dst$$reg);
    FloatRegister fval = $src$$FloatRegister;
    Label L;

    __ c_un_s(fval, fval);    //NaN?
    __ bc1t(L);
    __ delayed();
    __ move(dst, R0);

    __ trunc_l_s(F30, fval);
    __ cfc1(AT, 31);
    __ li(T9, 0x10000);
    __ andr(AT, AT, T9);
    __ beq(AT, R0, L);
    __ delayed()->dmfc1(dst, F30);

    __ mov_s(F12, fval);
    __ call_VM_leaf(CAST_FROM_FN_PTR(address, SharedRuntime::f2l), 1);
    __ move(dst, V0);
    __ bind(L);
  %}

  ins_pipe( pipe_slow );
%}

instruct convL2F_reg( regF dst, mRegL src ) %{
  match(Set dst (ConvL2F src));
  effect( DEF dst, USE src );
  format %{ "convl2f    $dst, $src @ convL2F_reg" %}
  ins_encode %{
    FloatRegister dst = $dst$$FloatRegister;
    Register src = as_Register($src$$reg);
    Label L;

    __ dmtc1(src, dst);
    __ cvt_s_l(dst, dst);
  %}

  ins_pipe( pipe_slow );
%}

instruct convI2F_reg( regF dst, mRegI src ) %{
  match(Set dst (ConvI2F src));
  effect( DEF dst, USE src );
  format %{ "convi2f    $dst, $src @ convI2F_reg" %}
  ins_encode %{
    Register      src = $src$$Register;
    FloatRegister dst = $dst$$FloatRegister;

    __ mtc1(src, dst);
    __ cvt_s_w(dst, dst);
  %}

  ins_pipe( fpu_regF_regF );
%}

instruct cmpLTMask( mRegI dst, mRegI p, mRegI q ) %{
  match(Set dst (CmpLTMask p q));
  ins_cost(400);

  format %{ "cmpLTMask    $dst, $p, $q @ cmpLTMask" %}
    ins_encode %{
       Register p   = $p$$Register;
       Register q   = $q$$Register;
       Register dst = $dst$$Register;

       __ slt(dst, p, q);
       __ subu(dst, R0, dst);
    %}
    ins_pipe( pipe_slow );
%}

instruct movP_nocopy(mRegI dst, mRegP src) %{
  effect( DEF dst, USE src );
  format %{ "MOV    $dst,$src @ movP_nocopy" %}
  ins_encode %{
    Register  dst = $dst$$Register;
    Register  src = $src$$Register;
    __ addu(dst, src, R0);
  %}
//  ins_encode( enc_Copy( dst, src) );
  ins_pipe( ialu_regI_regI );
%}

//FIXME
//instruct cp2b( mRegI dst, mRegP src, eFlagsReg cr ) %{
instruct cp2b( mRegI dst, mRegP src ) %{
  effect( USE_DEF dst, USE src );
  format %{ "NEG    $dst\n\t @cp2b"
            "ADC    $dst,$src @cp2b" %}
  ins_encode %{
    Register  dst = $dst$$Register;
    Register  src = $src$$Register;
    Label L;
//If ( dst != 0 ) CF = 1;
    __ move(AT, src);
    __ beq(dst, R0, L);
    __ nop();
    __ addiu(AT, AT, 1);
    __ bind(L);
    __ neg(dst);
    __ addu(dst, dst, AT);
  %}

  ins_pipe( ialu_regL_regL );
%}

instruct convP2B( mRegI dst, mRegP src ) %{
  match(Set dst (Conv2B src));

  expand %{
    movP_nocopy(dst,src);
    cp2b(dst,src);
  %}
%}

instruct convI2D_reg_reg(regD dst, mRegI src) %{
  match(Set dst (ConvI2D src));
  format %{ "conI2D $dst, $src @convI2D_reg" %}
  ins_encode %{
     Register      src = $src$$Register;
     FloatRegister dst = $dst$$FloatRegister;
     __ mtc1(src, dst);
     __ cvt_d_w(dst, dst);
  %}
  ins_pipe( fpu_regF_regF );
%}

instruct convF2I_reg_reg(mRegI dst, regF src) %{
  match(Set dst (ConvF2I src));
  format %{ "convF2I  $dst, $src\t# @convF2D_reg_reg" %}
  ins_encode %{
    FloatRegister dst = $dst$$FloatRegister;
    FloatRegister src = $src$$FloatRegister;

    __ cvt_d_s(dst, src);
  %}
  ins_pipe( fpu_regF_regF );
%}

instruct convF2D_reg_reg(regD dst, regF src) %{
  match(Set dst (ConvF2D src));
  format %{ "convF2D  $dst, $src\t# @convF2D_reg_reg" %}
  ins_encode %{
    FloatRegister dst = $dst$$FloatRegister;
    FloatRegister src = $src$$FloatRegister;

    __ cvt_d_s(dst, src);
  %}
  ins_pipe( fpu_regF_regF );
%}

instruct convD2F_reg_reg(regF dst, regD src) %{
  match(Set dst (ConvD2F src));
  format %{ "convD2F  $dst, $src\t# @convD2F_reg_reg" %}
  ins_encode %{
    FloatRegister dst = $dst$$FloatRegister;
    FloatRegister src = $src$$FloatRegister;

    __ cvt_s_d(dst, src);
  %}
  ins_pipe( fpu_regF_regF );
%}

// Convert a double to an int.  If the double is a NAN, stuff a zero in instead.
instruct convD2I_reg_reg( mRegI dst, regD src ) %{
  match(Set dst (ConvD2I src));
//  effect( KILL tmp, KILL cr );//after this instruction, it will release register tmp and cr

  format %{ "convD2I $dst, $src\t# @ convD2I_reg_reg \n\t" %}

  ins_encode %{
      FloatRegister src = $src$$FloatRegister;
      Register      dst = $dst$$Register;
      Label L;

      __ trunc_w_d(F30, src);
      __ cfc1(AT, 31);
      __ li(T9, 0x10000);
      __ andr(AT, AT, T9);
      __ beq(AT, R0, L);
      __ delayed()->mfc1(dst, F30);

      __ mov_d(F12, src);
      __ call_VM_leaf(CAST_FROM_FN_PTR(address, SharedRuntime::d2i), 1);
      __ move(dst, V0);
      __ bind(L);
 
  %}
  ins_pipe( pipe_slow );
%}

// Convert oop pointer into compressed form
instruct encodeHeapOop(mRegN dst, mRegP src, FlagsReg cr) %{
  predicate(n->bottom_type()->make_ptr()->ptr() != TypePtr::NotNull);
  match(Set dst (EncodeP src));
  effect(KILL cr);
  format %{ "encode_heap_oop $dst,$src" %}
  ins_encode %{
    Register src = $src$$Register;
    Register dst = $dst$$Register;
    if (src != dst) {
      __ move(dst, src);
    }
    __ encode_heap_oop(dst);
  %}
  ins_pipe( ialu_regL_regL );
%}

instruct encodeHeapOop_not_null(mRegN dst, mRegP src, FlagsReg cr) %{
  predicate(n->bottom_type()->make_ptr()->ptr() == TypePtr::NotNull);
  match(Set dst (EncodeP src));
  effect(KILL cr);
  format %{ "encode_heap_oop_not_null $dst,$src @ encodeHeapOop_not_null" %}
  ins_encode %{
    __ encode_heap_oop_not_null($dst$$Register, $src$$Register);
  %}
  ins_pipe( ialu_regL_regL );
%}

instruct decodeHeapOop(mRegP dst, mRegN src) %{
  predicate(n->bottom_type()->is_ptr()->ptr() != TypePtr::NotNull &&
            n->bottom_type()->is_ptr()->ptr() != TypePtr::Constant);
  match(Set dst (DecodeN src));
  format %{ "decode_heap_oop $dst,$src @ decodeHeapOop" %}
  ins_encode %{
    Register s = $src$$Register;
    Register d = $dst$$Register;
    if (s != d) {
      __ move(d, s);
    }
    __ decode_heap_oop(d);
  %}
  ins_pipe( ialu_regL_regL );
%}

instruct decodeHeapOop_not_null(mRegP dst, mRegN src) %{
  predicate(n->bottom_type()->is_ptr()->ptr() == TypePtr::NotNull ||
            n->bottom_type()->is_ptr()->ptr() == TypePtr::Constant);
  match(Set dst (DecodeN src));
  format %{ "decode_heap_oop_not_null $dst,$src @ decodeHeapOop_not_null" %}
  ins_encode %{
    Register s = $src$$Register;
    Register d = $dst$$Register;
    if (s != d) {
      __ decode_heap_oop_not_null(d, s);
    } else {
      __ decode_heap_oop_not_null(d);
    }
  %}
  ins_pipe( ialu_regL_regL );
%}

instruct encodeKlass_not_null(mRegN dst, mRegP src, FlagsReg cr) %{
  match(Set dst (EncodePKlass src));
  effect(KILL cr);
  format %{ "encode_heap_oop_not_null $dst,$src @ encodeKlass_not_null" %}
  ins_encode %{
    __ encode_klass_not_null($dst$$Register, $src$$Register);
  %}
  ins_pipe( ialu_regL_regL );
%}

instruct decodeKlass_not_null(mRegP dst, mRegN src, FlagsReg cr) %{
  match(Set dst (DecodeNKlass src));
  effect(KILL cr);
  format %{ "decode_heap_klass_not_null $dst,$src" %}
  ins_encode %{
    Register s = $src$$Register;
    Register d = $dst$$Register;
    if (s != d) {
      __ decode_klass_not_null(d, s);
    } else {
      __ decode_klass_not_null(d);
    }
  %}
  ins_pipe( ialu_regL_regL );
%}

//FIXME
instruct tlsLoadP(mRegP dst) %{
  match(Set dst (ThreadLocal));

  ins_cost(0);
  format %{ " get_thread in $dst #@tlsLoadP" %}
  ins_encode %{
    Register dst = $dst$$Register;
#ifdef OPT_THREAD
    __ move(dst, TREG);
#else
    __ get_thread(dst);
#endif
  %}

  ins_pipe( ialu_loadI );
%}


instruct checkCastPP( mRegP dst ) %{
  match(Set dst (CheckCastPP dst));

  format %{ "#checkcastPP of $dst (empty encoding) #@chekCastPP" %}
  ins_encode( /*empty encoding*/ );
  ins_pipe( empty );
%}

instruct castPP(mRegP dst)
%{
  match(Set dst (CastPP dst));

  size(0);
  format %{ "# castPP of $dst" %}
  ins_encode(/* empty encoding */);
  ins_pipe(empty);
%}

instruct castII( mRegI dst ) %{
  match(Set dst (CastII dst));
  format %{ "#castII of $dst  empty encoding" %}
  ins_encode( /*empty encoding*/ );
  ins_cost(0);
  ins_pipe( empty );
%}

// Return Instruction
// Remove the return address & jump to it.
instruct Ret() %{
  match(Return);
  format %{ "RET #@Ret" %}

  ins_encode %{
   __ jr(RA); 
   __ nop();
  %}

  ins_pipe( pipe_jump );
%}


// Jump Direct - Label defines a relative address from JMP
instruct jmpDir(label labl) %{
  match(Goto);
  effect(USE labl);

  ins_cost(300);
  format %{ "JMP    $labl #@jmpDir" %}

  ins_encode %{
    Label &L = *($labl$$label);
    if(&L)
    	 __ b(L);
    else
         __ b(int(0));
    __ nop();
  %}

    ins_pipe( pipe_jump );
    ins_pc_relative(1);
%}



// Tail Jump; remove the return address; jump to target.
// TailCall above leaves the return address around.
// TailJump is used in only one place, the rethrow_Java stub (fancy_jump=2).
// ex_oop (Exception Oop) is needed in %o0 at the jump. As there would be a
// "restore" before this instruction (in Epilogue), we need to materialize it
// in %i0.
//FIXME
instruct tailjmpInd(mRegP jump_target,mRegP ex_oop) %{
  match( TailJump jump_target ex_oop );
  ins_cost(200);
  format %{ "Jmp     $jump_target  ; ex_oop = $ex_oop #@tailjmpInd" %}
  ins_encode %{
    Register target = $jump_target$$Register;

    /* 2012/9/14 Jin: V0, V1 are indicated in:
     *      [stubGenerator_mips.cpp] generate_forward_exception()
     *      [runtime_mips.cpp] OptoRuntime::generate_exception_blob()
     */
    Register oop  = $ex_oop$$Register;
    Register exception_oop = V0;
    Register exception_pc = V1;

    __ move(exception_pc, RA);
    __ move(exception_oop, oop);

    __ jr(target);  
    __ nop();
  %}
  ins_pipe( pipe_jump ); 
%}

// ============================================================================
// Procedure Call/Return Instructions
// Call Java Static Instruction
// Note: If this code changes, the corresponding ret_addr_offset() and
//       compute_padding() functions will have to be adjusted.
instruct CallStaticJavaDirect(method meth) %{
  match(CallStaticJava);
  effect(USE meth);

  ins_cost(300);
  format %{ "CALL,static #@CallStaticJavaDirect " %}
  ins_encode( Java_Static_Call( meth ) );
  ins_pipe( pipe_slow );
  ins_pc_relative(1);
  ins_alignment(16);
%}

// Call Java Dynamic Instruction
// Note: If this code changes, the corresponding ret_addr_offset() and
//       compute_padding() functions will have to be adjusted.
instruct CallDynamicJavaDirect(method meth) %{
  match(CallDynamicJava);
  effect(USE meth);

  ins_cost(300);
  format %{"MOV IC_Klass, (oop)-1 @ CallDynamicJavaDirect\n\t"
           "CallDynamic @ CallDynamicJavaDirect" %}
  ins_encode( Java_Dynamic_Call( meth ) );
  ins_pipe( pipe_slow );
  ins_pc_relative(1);
  ins_alignment(16);
%}

instruct CallLeafNoFPDirect(method meth) %{
  match(CallLeafNoFP);
  effect(USE meth);

  ins_cost(300);
  format %{ "CALL_LEAF_NOFP,runtime " %}
  ins_encode(Java_To_Runtime(meth));
  ins_pipe( pipe_slow );
  ins_pc_relative(1);
  ins_alignment(16);
%}


instruct prefetchw0( memory mem ) %{
//  predicate(UseSSE==0 && !VM_Version::supports_3dnow());
  match(PrefetchWrite mem);
  format %{ "Prefetch (sync) #@prefetchw0" %}
  ins_encode %{
     __ sync();
  %}
  ins_pipe(pipe_slow);
%}


// Call runtime without safepoint
instruct CallLeafDirect(method meth) %{
  match(CallLeaf);
  effect(USE meth);

  ins_cost(300);
  format %{ "CALL_LEAF,runtime #@CallLeafDirect " %}
  ins_encode(Java_To_Runtime(meth));
  ins_pipe( pipe_slow );
  ins_pc_relative(1);
  ins_alignment(16);
%}

// Load Char (16bit unsigned)
instruct loadUS(mRegI dst, memory mem) %{
  match(Set dst (LoadUS mem));

  ins_cost(125);
  format %{ "loadUS  $dst,$mem @ loadC" %}
  // opcode(0xB7, 0x0F);
  // ins_encode( OpcS, OpcP, RegMem(dst,mem));
  ins_encode(load_C_enc(dst, mem));
  ins_pipe( ialu_loadI );
%}

// Store Char (16bit unsigned)
instruct storeC(memory mem, mRegI src) %{
  match(Set mem (StoreC mem src));

  ins_cost(125);
  format %{ "storeC  $src,$mem @ storeC" %}
  ins_encode(store_C_reg_enc(mem, src));
  ins_pipe( ialu_loadI );
%}


instruct loadConF0(regF dst, immF0 zero) %{
  match(Set dst zero);
  ins_cost(100);

  format %{ "mov  $dst, zero @ loadConF0\n"%}
  ins_encode %{
    FloatRegister dst = $dst$$FloatRegister;

    __ mtc1(R0, dst);
  %}
  ins_pipe( fpu_loadF );
%}


instruct loadConF(regF dst, immF src) %{
  match(Set dst src);
  ins_cost(125);

  format %{ "mov  $dst, $src @ loadConF"%}
  ins_encode %{
    FloatRegister dst = $dst$$FloatRegister;
    jfloat     jf = $src$$constant;
    address const_addr = __ float_constant(jf);
    assert (const_addr != NULL, "must create float constant in the constant table");

    __ relocate(relocInfo::internal_pc_type);
    __ li(AT, const_addr);
    __ lwc1(dst, AT, 0);
  %}
  ins_pipe( fpu_loadF );
%}


instruct loadConD0(regD dst, immD0 zero) %{
  match(Set dst zero);
  ins_cost(100);

  format %{ "mov  $dst, zero @ loadConD0\n"%}
  ins_encode %{
    FloatRegister dst = as_FloatRegister($dst$$reg);

      __ dmtc1(R0, dst);
  %}
  ins_pipe( fpu_loadF );
%}

instruct loadConD(regD dst, immD src) %{
  match(Set dst src);
  ins_cost(125);

  format %{ "mov  $dst, $src @ loadConD\n"%}
  ins_encode %{
    FloatRegister dst_reg = as_FloatRegister($dst$$reg);

    jdouble     jd = $src$$constant;
    address const_addr = __ double_constant(jd);
    assert (const_addr != NULL, "must create double constant in the constant table");

    __ relocate(relocInfo::internal_pc_type);
    __ li(AT, const_addr);
    __ ldc1(dst_reg, AT, 0);
  %}
  ins_pipe( fpu_loadF );
%}

// Store register Float value (it is faster than store from FPU register)
instruct storeF_reg( memory mem, regF src) %{
  match(Set mem (StoreF mem src));

  ins_cost(50);
  format %{ "store   $mem, $src\t# store float @ storeF_reg" %}
  ins_encode(store_F_reg_enc(mem, src));
  ins_pipe( fpu_storeF );
%}


// Store immediate Float value (it is faster than store from FPU register)
// The instruction usage is guarded by predicate in operand immF().
instruct storeF_imm( memory mem, immF src) %{
  match(Set mem (StoreF mem src));

  ins_cost(50);
  format %{ "store   $mem, $src\t# store float @ storeF_imm" %}
  ins_encode %{
    jfloat     jf = $src$$constant;
    int      base = $mem$$base;
    int     index = $mem$$index;
    int     scale = $mem$$scale;
    int      disp = $mem$$disp;
    address const_addr = __ float_constant(jf);
    assert (const_addr != NULL, "must create float constant in the constant table");

    __ relocate(relocInfo::internal_pc_type);
    __ li(AT, const_addr);
    __ lwc1(F30, AT, 0);

    if( scale != 0 ) Unimplemented();
    if( index != 0 ) {
       if( Assembler::is_simm16(disp) ) { 
          __ addu(AT, as_Register(base), as_Register(index));
          __ swc1(F30, AT, disp);
       } else {
          __ addu(AT, as_Register(base), as_Register(index));
          __ move(T9, disp);
          __ addu(AT, AT, T9);
          __ swc1(F30, AT, 0);
       }

    } else {
       if( Assembler::is_simm16(disp) ) { 
          __ swc1(F30, as_Register(base), disp);
       } else {
          __ move(T9, disp);
          __ addu(AT, as_Register(base), T9);
          __ swc1(F30, AT, 0);
       }
    }
  %}
  ins_pipe( ialu_storeI );
%}

instruct storeF_imm0( memory mem, immF0 zero) %{
  match(Set mem (StoreF mem zero));

  ins_cost(40);
  format %{ "store   $mem, zero\t# store float @ storeF_imm0" %}
  ins_encode %{
    int      base = $mem$$base;
    int     index = $mem$$index;
    int     scale = $mem$$scale;
    int      disp = $mem$$disp;

    if( index != 0 ) {
        if(scale != 0) {
           __ dsll(T9, as_Register(index), scale);
           __ addu(AT, as_Register(base), T9);
        } else {
           __ daddu(AT, as_Register(base), as_Register(index));
        }
       if( Assembler::is_simm16(disp) ) { 
          __ sw(R0, AT, disp);
       } else {
          __ move(T9, disp);
          __ addu(AT, AT, T9);
          __ sw(R0, AT, 0);
       }

    } else {
       if( Assembler::is_simm16(disp) ) { 
          __ sw(R0, as_Register(base), disp);
       } else {
          __ move(T9, disp);
          __ addu(AT, as_Register(base), T9);
          __ sw(R0, AT, 0);
       }
    }
  %}
  ins_pipe( ialu_storeI );
%}

// Load Double
instruct loadD(regD dst, memory mem) %{
  match(Set dst (LoadD mem));

  ins_cost(150);
  format %{ "loadD   $dst, $mem #@loadD" %}
  ins_encode(load_D_enc(dst, mem));
  ins_pipe( ialu_loadI );
%}

// Load Double - UNaligned
instruct loadD_unaligned(regD dst, memory mem ) %{
  match(Set dst (LoadD_unaligned mem));
  ins_cost(250);
  // FIXME: Jin: Need more effective ldl/ldr
  format %{ "loadD_unaligned   $dst, $mem #@loadD_unaligned" %}
  ins_encode(load_D_enc(dst, mem));
  ins_pipe( ialu_loadI );
%}

instruct storeD_reg( memory mem, regD src) %{
  match(Set mem (StoreD mem src));

  ins_cost(50);
  format %{ "store   $mem, $src\t# store float @ storeD_reg" %}
  ins_encode(store_D_reg_enc(mem, src));
  ins_pipe( fpu_storeF );
%}

instruct storeD_imm0( memory mem, immD0 zero) %{
  match(Set mem (StoreD mem zero));

  ins_cost(40);
  format %{ "store   $mem, zero\t# store float @ storeD_imm0" %}
  ins_encode %{
    int      base = $mem$$base;
    int     index = $mem$$index;
    int     scale = $mem$$scale;
    int      disp = $mem$$disp;

    __ mtc1(R0, F30);
    __ cvt_d_w(F30, F30);

    if( index != 0 ) {
        if(scale != 0) {
           __ dsll(T9, as_Register(index), scale);
           __ addu(AT, as_Register(base), T9);
        } else {
           __ daddu(AT, as_Register(base), as_Register(index));
        }
       if( Assembler::is_simm16(disp) ) { 
          __ sdc1(F30, AT, disp);
       } else {
          __ move(T9, disp);
          __ addu(AT, AT, T9);
          __ sdc1(F30, AT, 0);
       }

    } else {
       if( Assembler::is_simm16(disp) ) { 
          __ sdc1(F30, as_Register(base), disp);
       } else {
          __ move(T9, disp);
          __ addu(AT, as_Register(base), T9);
          __ sdc1(F30, AT, 0);
       }
    }
  %}
  ins_pipe( ialu_storeI );
%}

instruct cmpFastLock( FlagsReg cr, mRegP object, mRegP box, mRegI tmp, mRegP scr) %{
  match( Set cr (FastLock object box) );
  effect( TEMP tmp, TEMP scr );
  ins_cost(300);
  format %{ "FASTLOCK $cr $object, $box, $tmp #@ cmpFastLock" %}
  ins_encode %{
    __ fast_lock($object$$Register, $box$$Register, $tmp$$Register, $scr$$Register);
  %}

  ins_pipe( pipe_slow );
  ins_pc_relative(1);
%}

instruct cmpFastUnlock( FlagsReg cr, mRegP object, mRegP box, mRegP tmp ) %{
  match( Set cr (FastUnlock object box) );
  effect( TEMP tmp );
  ins_cost(300);
  format %{ "FASTUNLOCK $object, $box, $tmp #@cmpFastUnlock" %}
  ins_encode %{
    __ fast_unlock($object$$Register, $box$$Register, $tmp$$Register);
  %}

  ins_pipe( pipe_slow );
  ins_pc_relative(1);
%}

// Store CMS card-mark Immediate
instruct storeImmCM(memory mem, immI8 src) %{
  match(Set mem (StoreCM mem src));

  ins_cost(150);
  format %{ "MOV8   $mem,$src\t! CMS card-mark imm0" %}
//  opcode(0xC6);
  ins_encode(store_B_immI_enc_sync(mem, src));
  ins_pipe( ialu_storeI );
%}

// Die now
instruct ShouldNotReachHere( )
%{
  match(Halt);
  ins_cost(300);

  // Use the following format syntax
  format %{ "ILLTRAP   ;#@ShouldNotReachHere" %}
  ins_encode %{
    // Here we should emit illtrap !

    __ stop("in ShoudNotReachHere");

  %}
  ins_pipe( pipe_jump );
%}


// Jump Direct Conditional - Label defines a relative address from Jcc+1
instruct  jmpLoopEnd(cmpOp cop, mRegI src1, mRegI src2, label labl) %{
  match(CountedLoopEnd cop (CmpI src1 src2));
  effect(USE labl);
  
  ins_cost(300);
  format %{ "J$cop  $src1, $src2,  $labl\t# Loop end @ jmpLoopEnd" %}
  ins_encode %{
    Register op1 = $src1$$Register;
    Register op2 = $src2$$Register;
    Label     &L = *($labl$$label);
    int     flag = $cop$$cmpcode;

    switch(flag)
    {
      case 0x01: //equal
	if (&L)
        	__ beq(op1, op2, L); 
	else 
        	__ beq(op1, op2, (int)0); 
        break;
      case 0x02: //not_equal
	if (&L)
        	__ bne(op1, op2, L); 
	else
        	__ bne(op1, op2, (int)0); 
        break;
      case 0x03: //above
        __ slt(AT, op2, op1);
        if(&L)
        	__ bne(AT, R0, L); 
        else
                __ bne(AT, R0, (int)0);
        break;
      case 0x04: //above_equal
        __ slt(AT, op1, op2);
        if(&L)
        	__ beq(AT, R0, L);
        else
                __ beq(AT, R0, (int)0);
        break;
      case 0x05: //below
        __ slt(AT, op1, op2);
        if(&L)
      		 __ bne(AT, R0, L); 
        else
        	 __ bne(AT, R0, (int)0);
        break;
      case 0x06: //below_equal
        __ slt(AT, op2, op1);
        if(&L)
        	__ beq(AT, R0, L);
        else
        	__ beq(AT, R0, (int)0);
       break;
      default:
          Unimplemented();
    }  
    __ nop();
  %}
  ins_pipe( pipe_jump );
  ins_pc_relative(1);
%}


 instruct  jmpLoopEnd_reg_imm16_sub(cmpOp cop, mRegI src1, immI16_sub src2, label labl) %{
  match(CountedLoopEnd cop (CmpI src1 src2));
  effect(USE labl);
  
  ins_cost(250);
  format %{ "J$cop  $src1, $src2,  $labl\t# Loop end @ jmpLoopEnd_reg_imm16_sub" %}
  ins_encode %{
    Register op1 = $src1$$Register;
    int      op2 = $src2$$constant;
    Label     &L = *($labl$$label);
    int     flag = $cop$$cmpcode;

    __ addiu32(AT, op1, -1 * op2);

    switch(flag)
    {
      case 0x01: //equal
       if (&L)
               __ beq(AT, R0, L); 
       else 
               __ beq(AT, R0, (int)0); 
        break;
      case 0x02: //not_equal
       if (&L)
               __ bne(AT, R0, L); 
       else
               __ bne(AT, R0, (int)0); 
        break;
      case 0x03: //above
        if(&L)
               __ bgtz(AT, L); 
        else
                __ bgtz(AT, (int)0);
        break;
      case 0x04: //above_equal
        if(&L)
               __ bgez(AT, L);
        else
                __ bgez(AT,(int)0);
        break;
      case 0x05: //below
        if(&L)
                __ bltz(AT, L); 
        else
                __ bltz(AT, (int)0);
        break;
      case 0x06: //below_equal
        if(&L)
               __ blez(AT, L);
        else
               __ blez(AT, (int)0);
       break;
      default:
          Unimplemented();
    }  
    __ nop();
  %}
  ins_pipe( pipe_jump );
  ins_pc_relative(1);
%}
 
          
/*  
// Jump Direct Conditional - Label defines a relative address from Jcc+1
instruct jmpLoopEndU(cmpOpU cop, eFlagsRegU cmp, label labl) %{
  match(CountedLoopEnd cop cmp);
  effect(USE labl);

  ins_cost(300);
  format %{ "J$cop,u  $labl\t# Loop end" %}
  size(6);
  opcode(0x0F, 0x80);
  ins_encode( Jcc( cop, labl) );
  ins_pipe( pipe_jump );
  ins_pc_relative(1);
%}

instruct jmpLoopEndUCF(cmpOpUCF cop, eFlagsRegUCF cmp, label labl) %{
  match(CountedLoopEnd cop cmp);
  effect(USE labl);
  
  ins_cost(200);
  format %{ "J$cop,u  $labl\t# Loop end" %}
  opcode(0x0F, 0x80);
  ins_encode( Jcc( cop, labl) );
  ins_pipe( pipe_jump );
  ins_pc_relative(1);
%}
*/

// This match pattern is created for StoreIConditional since I cannot match IfNode without a RegFlags! fujie 2012/07/17
instruct jmpCon_flags(cmpOp cop, FlagsReg cr, label labl) %{
  match(If cop cr);
  effect(USE labl);

  ins_cost(300);
  format %{ "J$cop    $labl  #mips uses AT as eflag @jmpCon_flags" %}

  ins_encode %{
    Label    &L =  *($labl$$label);
    switch($cop$$cmpcode)
    {
      case 0x01: //equal
	if (&L)
        	__ bne(AT, R0, L); 
	else 
        	__ bne(AT, R0, (int)0); 
        break;
      case 0x02: //not equal
	if (&L)
        	__ beq(AT, R0, L); 
	else 
        	__ beq(AT, R0, (int)0); 
        break;
      default:
         Unimplemented(); 
    }
    __ nop();
  %}

  ins_pipe( pipe_jump );
  ins_pc_relative(1);
%}


// ============================================================================
// The 2nd slow-half of a subtype check.  Scan the subklass's 2ndary superklass
// array for an instance of the superklass.  Set a hidden internal cache on a
// hit (cache is checked with exposed code in gen_subtype_check()).  Return
// NZ for a miss or zero for a hit.  The encoding ALSO sets flags.
instruct partialSubtypeCheck( mRegP result, mRegP sub, mRegP super ) %{
  match(Set result (PartialSubtypeCheck sub super));
  ins_cost(1100);  // slightly larger than the next version
  format %{ "partialSubtypeCheck result=$result, sub=$sub, super=$super " %}

  ins_encode( enc_PartialSubtypeCheck(result, sub, super) );
  ins_pipe( pipe_slow );
%}


// Conditional-store of an int value.
// ZF flag is set on success, reset otherwise.  Implemented with a CMPXCHG on Intel.
instruct storeIConditional( memory mem, mRegI oldval, mRegI newval, FlagsReg cr ) %{
  match(Set cr (StoreIConditional mem (Binary oldval newval)));
//  effect(KILL oldval);
  format %{ "CMPXCHG  $newval, $mem, $oldval \t# @storeIConditional" %}

  ins_encode %{
    Register oldval = $oldval$$Register;
    Register newval = $newval$$Register;
    Address  addr(as_Register($mem$$base), $mem$$disp);
    Label    again, failure;

//    int      base = $mem$$base;
    int     index = $mem$$index;
    int     scale = $mem$$scale;
    int      disp = $mem$$disp;
    
    guarantee(Assembler::is_simm16(disp), ""); 

    if( scale != 0 ) Unimplemented();
    if( index != 0 ) {
       __ stop("in storeIConditional: index != 0");
    } else {
       __ bind(again);
       __ sync();
       __ ll(AT, addr);
       __ bne(AT, oldval, failure);
       __ delayed()->addu(AT, R0, R0);

       __ addu(AT, newval, R0);
       __ sc(AT, addr);
       __ beq(AT, R0, again);
       __ delayed()->addiu(AT, R0, 0xFF);
       __ bind(failure);
       __ sync();
    }
%}

  ins_pipe( long_memory_op );
%}

// Conditional-store of a long value.
// ZF flag is set on success, reset otherwise.  Implemented with a CMPXCHG.
instruct storeLConditional(memory mem, t2RegL oldval, mRegL newval, FlagsReg cr )
%{
  match(Set cr (StoreLConditional mem (Binary oldval newval)));
  effect(KILL oldval);

  format %{ "cmpxchg $mem, $newval\t# If $oldval == $mem then store $newval into $mem" %}
  ins_encode%{
		Register oldval = $oldval$$Register;
		Register newval = $newval$$Register;
		Address addr((Register)$mem$$base, $mem$$disp);  

		int     index = $mem$$index;
		int     scale = $mem$$scale;
		int      disp = $mem$$disp;

		guarantee(Assembler::is_simm16(disp), ""); 

		if( scale != 0 ) Unimplemented(); 
		if( index != 0 ) {
			__ stop("in storeIConditional: index != 0");
		} else {
			__ cmpxchg(newval, addr, oldval);
		}
  %}
  ins_pipe( long_memory_op );
%}


instruct compareAndSwapI( mRegI res, mRegP mem_ptr, mS2RegI oldval, mRegI newval) %{
  match(Set res (CompareAndSwapI mem_ptr (Binary oldval newval)));
  effect(KILL oldval);
//  match(CompareAndSwapI mem_ptr (Binary oldval newval));
  format %{ "CMPXCHG $newval, [$mem_ptr], $oldval @ compareAndSwapI\n\t"
            "MOV    $res, 1 @ compareAndSwapI\n\t"
            "BNE    AT, R0 @ compareAndSwapI\n\t"
            "MOV    $res, 0 @ compareAndSwapI\n"
          "L:" %}
  ins_encode %{
    Register newval = $newval$$Register;
    Register oldval = $oldval$$Register;
    Register res    = $res$$Register;
    Address  addr($mem_ptr$$Register, 0);    
    Label L;

    __ cmpxchg32(newval, addr, oldval);
    __ move(res, AT);
  %}
  ins_pipe( long_memory_op );
%}

//FIXME:
instruct compareAndSwapP( mRegI res, mRegP mem_ptr, s2_RegP oldval, mRegP newval) %{
  match(Set res (CompareAndSwapP mem_ptr (Binary oldval newval)));
  effect(KILL oldval);
  format %{ "CMPXCHG $newval, [$mem_ptr], $oldval @ compareAndSwapP\n\t"
            "MOV    $res, AT @ compareAndSwapP\n\t"
          "L:" %}
  ins_encode %{
    Register newval = $newval$$Register;
    Register oldval = $oldval$$Register;
    Register res    = $res$$Register;
    Address  addr($mem_ptr$$Register, 0);    
    Label L;

    __ cmpxchg(newval, addr, oldval);
    __ move(res, AT);
  %}
  ins_pipe( long_memory_op );
%}

instruct compareAndSwapN( mRegI res, mRegP mem_ptr, t2_RegN oldval, mRegN newval) %{
  match(Set res (CompareAndSwapN mem_ptr (Binary oldval newval)));
  effect(KILL oldval);
  format %{ "CMPXCHG $newval, [$mem_ptr], $oldval @ compareAndSwapN\n\t"
            "MOV    $res, AT @ compareAndSwapN\n\t"
          "L:" %}
  ins_encode %{
    Register newval = $newval$$Register;
    Register oldval = $oldval$$Register;
    Register res    = $res$$Register;
    Address  addr($mem_ptr$$Register, 0);    
    Label L;

    /* 2013/7/19 Jin: cmpxchg32 is implemented with ll/sc, which will do sign extension.
     *      Thus, we should extend oldval's sign for correct comparision.
     */
    __ sll(oldval, oldval, 0);

    __ cmpxchg32(newval, addr, oldval);
    __ move(res, AT);
  %}
  ins_pipe( long_memory_op );
%}

//----------Max and Min--------------------------------------------------------
// Min Instructions
////
//   *** Min and Max using the conditional move are slower than the
//   *** branch version on a Pentium III.
// // Conditional move for min
//instruct cmovI_reg_lt( eRegI op2, eRegI op1, eFlagsReg cr ) %{
//  effect( USE_DEF op2, USE op1, USE cr );
//  format %{ "CMOVlt $op2,$op1\t! min" %}
//  opcode(0x4C,0x0F);
//  ins_encode( OpcS, OpcP, RegReg( op2, op1 ) );
//  ins_pipe( pipe_cmov_reg );
//%}
//
//// Min Register with Register (P6 version)
//instruct minI_eReg_p6( eRegI op1, eRegI op2 ) %{
//  predicate(VM_Version::supports_cmov() );
//  match(Set op2 (MinI op1 op2));
//  ins_cost(200);
//  expand %{
//    eFlagsReg cr;
//    compI_eReg(cr,op1,op2);
//    cmovI_reg_lt(op2,op1,cr);
//  %}
//%}

// Min Register with Register (generic version)
instruct minI_Reg_Reg(mRegI dst, mRegI src) %{
  match(Set dst (MinI dst src));
  //effect(KILL flags);
  ins_cost(80);

  format %{ "MIN    $dst, $src @minI_Reg_Reg" %}
  ins_encode %{
    Register dst   = $dst$$Register;
    Register src   = $src$$Register;

    __ slt(AT, src, dst);
    __ movn(dst, src, AT);
 
  %}

  ins_pipe( pipe_slow );
%}

// Max Register with Register
//   *** Min and Max using the conditional move are slower than the
//   *** branch version on a Pentium III.
// // Conditional move for max
//instruct cmovI_reg_gt( eRegI op2, eRegI op1, eFlagsReg cr ) %{
//  effect( USE_DEF op2, USE op1, USE cr );
//  format %{ "CMOVgt $op2,$op1\t! max" %}
//  opcode(0x4F,0x0F);
//  ins_encode( OpcS, OpcP, RegReg( op2, op1 ) );
//  ins_pipe( pipe_cmov_reg );
//%}
//
// // Max Register with Register (P6 version)
//instruct maxI_eReg_p6( eRegI op1, eRegI op2 ) %{
//  predicate(VM_Version::supports_cmov() );
//  match(Set op2 (MaxI op1 op2));
//  ins_cost(200);
//  expand %{
//    eFlagsReg cr;
//    compI_eReg(cr,op1,op2);
//    cmovI_reg_gt(op2,op1,cr);
//  %}
//%}

// Max Register with Register (generic version)
instruct maxI_Reg_Reg(mRegI dst, mRegI src) %{
  match(Set dst (MaxI dst src));
  ins_cost(80);

  format %{ "MAX    $dst, $src @maxI_Reg_Reg" %}

  ins_encode %{
    Register dst   = $dst$$Register;
    Register src   = $src$$Register;

    __ slt(AT, dst, src);
    __ movn(dst, src, AT);

  %}

  ins_pipe( pipe_slow );
%}


// ============================================================================
// Safepoint Instruction
instruct safePoint_poll() %{
  match(SafePoint);

  ins_cost(125);
  format %{ "lui  at, HI(polling_page)]\t! Safepoint: poll for GC @ safePoint_poll \n\t"
            "lw   at, LO(polling_page)]\n " %}

  ins_encode %{
  __ block_comment("Safepoint:");
#ifndef OPT_SAFEPOINT
  __ li48(S7, (long)os::get_polling_page());
  __ relocate(relocInfo::poll_type);
  __ lw(AT, S7, 0);
#else
  __ lui(S7, Assembler::split_high((intptr_t)os::get_polling_page()));
  __ relocate(relocInfo::poll_type);
  __ lw(AT, S7, Assembler::split_low((intptr_t)os::get_polling_page()));
#endif
  %}

  ins_pipe( ialu_storeI );
%}

//----------PEEPHOLE RULES-----------------------------------------------------
// These must follow all instruction definitions as they use the names
// defined in the instructions definitions.
// 
// peepmatch ( root_instr_name [preceeding_instruction]* );
//
// peepconstraint %{
// (instruction_number.operand_name relational_op instruction_number.operand_name
//  [, ...] );
// // instruction numbers are zero-based using left to right order in peepmatch
//
// peepreplace ( instr_name  ( [instruction_number.operand_name]* ) );
// // provide an instruction_number.operand_name for each operand that appears
// // in the replacement instruction's match rule
//
// ---------VM FLAGS---------------------------------------------------------
// 
// All peephole optimizations can be turned off using -XX:-OptoPeephole
// 
// Each peephole rule is given an identifying number starting with zero and
// increasing by one in the order seen by the parser.  An individual peephole
// can be enabled, and all others disabled, by using -XX:OptoPeepholeAt=#
// on the command-line.
// 
// ---------CURRENT LIMITATIONS----------------------------------------------
// 
// Only match adjacent instructions in same basic block
// Only equality constraints
// Only constraints between operands, not (0.dest_reg == EAX_enc)
// Only one replacement instruction
//
// ---------EXAMPLE----------------------------------------------------------
//
// // pertinent parts of existing instructions in architecture description
// instruct movI(eRegI dst, eRegI src) %{
//   match(Set dst (CopyI src));
// %}
// 
// instruct incI_eReg(eRegI dst, immI1 src, eFlagsReg cr) %{
//   match(Set dst (AddI dst src));
//   effect(KILL cr);
// %}
// 
// // Change (inc mov) to lea
// peephole %{
//   // increment preceeded by register-register move
//   peepmatch ( incI_eReg movI );
//   // require that the destination register of the increment 
//   // match the destination register of the move
//   peepconstraint ( 0.dst == 1.dst );
//   // construct a replacement instruction that sets
//   // the destination to ( move's source register + one )
//   peepreplace ( leaI_eReg_immI( 0.dst 1.src 0.src ) );
// %}
// 
// Implementation no longer uses movX instructions since 
// machine-independent system no longer uses CopyX nodes.
// 
// peephole %{
//   peepmatch ( incI_eReg movI );
//   peepconstraint ( 0.dst == 1.dst );
//   peepreplace ( leaI_eReg_immI( 0.dst 1.src 0.src ) );
// %}
// 
// peephole %{
//   peepmatch ( decI_eReg movI );
//   peepconstraint ( 0.dst == 1.dst );
//   peepreplace ( leaI_eReg_immI( 0.dst 1.src 0.src ) );
// %}
// 
// peephole %{
//   peepmatch ( addI_eReg_imm movI );
//   peepconstraint ( 0.dst == 1.dst );
//   peepreplace ( leaI_eReg_immI( 0.dst 1.src 0.src ) );
// %}
// 
// peephole %{
//   peepmatch ( addP_eReg_imm movP );
//   peepconstraint ( 0.dst == 1.dst );
//   peepreplace ( leaP_eReg_immI( 0.dst 1.src 0.src ) );
// %}

// // Change load of spilled value to only a spill
// instruct storeI(memory mem, eRegI src) %{
//   match(Set mem (StoreI mem src));
// %}
// 
// instruct loadI(eRegI dst, memory mem) %{
//   match(Set dst (LoadI mem));
// %}
// 
//peephole %{
//  peepmatch ( loadI storeI );
//  peepconstraint ( 1.src == 0.dst, 1.mem == 0.mem );
//  peepreplace ( storeI( 1.mem 1.mem 1.src ) );
//%}

//----------SMARTSPILL RULES---------------------------------------------------
// These must follow all instruction definitions as they use the names
// defined in the instructions definitions.

